

% This is "sig-alternate.tex" V1.9 April 2009
% This file should be compiled with V2.4 of "sig-alternate.cls" April 2009
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.4 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.4) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V1.9 - April 2009

\documentclass{sig-alternate}
  \pdfpagewidth=8.5truein
  \pdfpageheight=11truein

\usepackage{epstopdf}
\usepackage{bussproofs}
\usepackage[usenames,dvipsnames]{color} % Required for specifying custom colors and referring to colors by name
\usepackage{listings}
\usepackage{xcolor}
\usepackage{verbatim}
\usepackage{multirow}
\usepackage{array}
\EnableBpAbbreviations
\input{macros.tex}

\newcommand\BeraMonottfamily{%
  \def\fvm@Scale{0.85}% scales the font down
  \fontfamily{fvm}\selectfont% selects the Bera Mono font
}

\lstdefinestyle{wyvern}{
%backgroundcolor=\color{highlight}, % Set the background color for the snippet - useful for highlighting
basicstyle=\scriptsize\BeraMonottfamily, % The default font size and style of the code
breakatwhitespace=false, % If true, only allows line breaks at white space
breaklines=true, % Automatic line breaking (prevents code from protruding outside the box)
captionpos=b, % Sets the caption position: b for bottom; t for top
morecomment=[s]{(*}{*)},
commentstyle=\fontshape{it}\color{Gray}\selectfont, % Style of comments within the code - dark green courier font
deletekeywords={}, % If you want to delete any keywords from the current language separate them by commas
%escapeinside={\%}, % This allows you to escape to LaTeX using the character in the bracket
firstnumber=1, % Line numbers begin at line 1
frame=lines, % Frame around the code box, value can be: none, leftline, topline, bottomline, lines, single, shadowbox
frameround=tttt, % Rounds the corners of the frame for the top left, top right, bottom left and bottom right positions
keywords=[1]{new, objtype, type, casetype, val, def, metadata, syntax, of, fn, with, let},
keywordstyle={[1]\bfseries},
keywordstyle={[3]\color{red!80!orange}},
morekeywords={}, % Add any functions no included by default here separated by commas
numbers=left, % Location of line numbers, can take the values of: none, left, right
numbersep=8pt, % Distance of line numbers from the code box
numberstyle=\tiny\color{Gray}, % Style used for line numbers
rulecolor=\color{black}, % Frame border color
showstringspaces=false, % Don't put marks in string spaces
showtabs=false, % Display tabs in the code as lines
stepnumber=1, % The step distance between line numbers, i.e. how often will lines be numbered
tabsize=4, % Number of spaces per tab in the code
}

\lstdefinestyle{tempwyvern}{
basicstyle=\scriptsize\BeraMonottfamily, % The default font size and style of the code
breakatwhitespace=false, % If true, only allows line breaks at white space
breaklines=true, % Automatic line breaking (prevents code from protruding outside the box)
captionpos=b, % Sets the caption position: b for bottom; t for top
morecomment=[s]{(*}{*)},
commentstyle=\fontshape{it}\color{Gray}\selectfont, % Style of comments within the code - dark green courier font
deletekeywords={}, % If you want to delete any keywords from the current language separate them by commas
%escapeinside={\%}, % This allows you to escape to LaTeX using the character in the bracket
firstnumber=1, % Line numbers begin at line 1
frame=lines, % Frame around the code box, value can be: none, leftline, topline, bottomline, lines, single, shadowbox
frameround=tttt, % Rounds the corners of the frame for the top left, top right, bottom left and bottom right positions
keywords=[1]{new, objtype, type, casetype, val, def, metadata, expkw, of, fn, with, typekw, let},
keywordstyle={[1]\bfseries},
keywordstyle={[3]\color{red!80!orange}},
morekeywords={}, % Add any functions no included by default here separated by commas
numbers=left, % Location of line numbers, can take the values of: none, left, right
numbersep=8pt, % Distance of line numbers from the code box
numberstyle=\tiny\color{Gray}, % Style used for line numbers
rulecolor=\color{black}, % Frame border color
showstringspaces=false, % Don't put marks in string spaces
showtabs=false, % Display tabs in the code as lines
tabsize=4, % Number of spaces per tab in the code
}
\lstset{basicstyle=\footnotesize,breaklines=true}
\lstset{escapeinside={@}{@}}
\newcommand{\htmlcolor}[1]{\textcolor[HTML]{339933}{#1}}
\newcommand{\expkwparsercolor}[1]{\textcolor[HTML]{336699}{#1}}
\newcommand{\typekwparsercolor}[1]{\textcolor[HTML]{7C803E}{#1}}
\newcommand{\urlcolor}[1]{\textcolor[HTML]{FFCC33}{#1}}
\newcommand{\expcolor}[1]{\textcolor[HTML]{FF0033}{#1}}
\newcommand{\membercolor}[1]{\textcolor[HTML]{FF6600}{#1}}
\newcommand{\typecolor}[1]{\textcolor[HTML]{660066}{#1}}
\newcommand{\dbcolor}[1]{\textcolor[HTML]{FF47FF}{#1}}
\newcommand{\hastslcolor}[1]{\textcolor[HTML]{002FC9}{#1}}
\newcommand{\simpleHTMLcolor}[1]{\textcolor[HTML]{7D5100}{#1}}
\newcommand{\boolIfcolor}[1]{\textcolor[HTML]{5E0C0C}{#1}}
\newcommand{\dbshcemacolor}[1]{\textcolor[HTML]{5AC3D1}{#1}}

\newcommand{\flyingbox}[1]{\begin{flushleft}\fbox{{#1}}\end{flushleft}}
\newcommand{\myvdash}{\vdash_{\Theta}^{\Delta}}
\newcommand{\textcd}[1]{\textbf{\scriptsize\BeraMonottfamily{#1}}}
\newcommand{\textsp}[1]{\text{\footnotesize\BeraMonottfamily{#1}}}
\newcommand{\mycaption}[1]{\vspace{-4px}\caption{#1}\vspace{-2px}}
\newcommand{\tabularspace}{~~~~~~~}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{property}{Property}

\begin{document}

%
% --- Author Metadata here ---
\conferenceinfo{SAC'15}{April 13-17, 2015, Salamanca, Spain.}
\CopyrightYear{2015} % Allows default copyright year (2002) to be over-ridden - IF NEED BE.
\crdata{978-1-4503-3196-8/15/04}  % Allows default copyright data (X-XXXXX-XX-X/XX/XX) to be over-ridden.
% --- End of Author Metadata ---

\title{Composable and Hygienic Typed Syntax Macros}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{1} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Chenglong Wang ~~~~~~~~ Cyrus Omar ~~~~~~~~ Jonathan Aldrich \\ Carnegie Mellon University \\ \email{\{stwong, comar, aldrich\}@cs.cmu.edu}
% 2nd. author
}
%\and  % use '\and' if you need 'another row' of author names

% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
Syntax extension mechanisms can be powerful, but ensuring that extensions are individually well-behaved and that they can be unambiguously composed is difficult. Recent work on \emph{type-specific languages (TSLs)} addressed these problems in the specific setting of literal forms. We supplement TSLs with \emph{typed syntax macros (TSMs)}: explicitly invoked delimited syntax extensions at both the level of terms and types. To maintain a strong typing discipline, we describe two flavors of term-level TSMs: synthetic TSMs specify the type of term that they elaborate to, while analytic TSMs can elaborate to arbitrary type, but can only be used in positions where the type is known (like TSLs). Type-level TSMs generate both a type declaration and its corresponding TSL, so the two mechanisms can operate in concert. To support conventional syntactic idioms, we supplement the previous set of delimiters with a new \emph{multipart} delimited form. We specify TSMs by extending  the bidirectionally typed elaboration semantics previously given for TSLs, leveraging the same hygiene mechanism and internal language. Taken together, TSLs and TSMs provide significant expressive power without compromising composability, hygiene and typing.
\end{abstract}

% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]
%\terms{Delphi theory}
%\keywords{ACM proceedings, \LaTeX, text tagging}

\section{Introduction}
One way programming languages evolve is by introducing \emph{syntactic sugar} that captures common idioms more concisely and naturally. In most contemporary languages, this is the  responsibility of a language's designers. Unfortunately, the designers of general-purpose languages do not have strong incentives to capture idioms that arise only situationally. This has motivated research into mechanisms that might decentralize control over syntax by allowing the users of a language to extend it with new syntactic sugar themselves.%, freeing designers from this responsibility.%, to varying degrees. 

Designing a useful syntax extension mechanism is non-trivial, however, because the designer can no longer  directly ensure that no parsing ambiguities have arisen and that the desugaring logic is semantically well-behaved. Instead, the mechanism must consider several important issues:

\noindent
\textbf{Composability} The mechanism cannot simply allow the base language's syntax to  be modified arbitrarily due to the potential for ambiguities. Critically, even separately defined fragments of syntax that are known not to cause parsing ambiguities individually can, if left unconstrained, lead to ambiguities when they are composed by interfering directly with one another (e.g. extensions adding support for XML and HTML). To avoid this issue, extensions must be kept delimited from the base language and from one another. 

\noindent
\textbf{Hygiene} User-defined desugaring logic must be constrained to ensure that the meaning of a term cannot change simply because some of the surrounding variables have been renamed (manually or by a refactoring tool). It should also be possible to identify the binding site of a variable, even if there are intervening uses of sugar. These two situations correspond to inadvertent variable capture and shadowing. 

\noindent
\textbf{Typing Discipline} In a statically typed setting, which will be our focus in this work, a \emph{typing discipline} is also desirable: determining the type a term will have should be possible without requiring that the desugaring be performed, to aid both programmers and tools. 

Most prior approaches to syntax extension, discussed in Sec. \ref{related}, fail to provide all of these guarantees. Recent work on \emph{type-specific languages  (TSLs)} makes these guarantees, but only in a limited setting: library providers can define new syntax only for introducing values of a type (i.e. \emph{literal forms}), associating it as metadata with the type when it is declared \cite{TSLs}. Local type inference, specified as a bidirectional type system \cite{Pierce:2000:LTI:345099.345100}, controls which TSL is used to parse delimited pieces of syntax, so TSLs are composable and maintain the typing discipline. The semantics also guarantees that hygiene is maintained. We will review TSLs in Sec. \ref{background}. 

Many forms of syntactic sugar can be implemented as TSLs, but there are situations where TSLs do not suffice: 1) only a single TSL can be associated with a type, and only when it is declared, so alternative syntax for a type or syntax for a type not under a user's control cannot be defined; 2) idioms other than those that arise when introducing a value of a type (e.g. those related to control flow or API protocols) cannot be captured; and 3) types cannot themselves be declared using specialized syntax. In this paper, we introduce \emph{typed syntax macros (TSMs)}, which supplement TSLs to support these scenarios while maintaining the strong guarantees above.% A TSM is invoked explicitly but otherwise benefits from the same mechanisms developed for TSLs. 

We introduce TSMs at the term level in Sec. \ref{tsms-term}.  To maintain a typing discipline, there are two flavors of term-level TSMs: \emph{synthetic TSMs} can be used anywhere, while \emph{analytic TSMs} can only be used where the expected type of the term is otherwise known. Both TSLs and TSMs leverage a common set of  ligthweight delimited forms to separate syntax extensions from the host language. To support ``multi-argument'' TSMs (and TSLs), we supplement those previously defined with \emph{multipart delimited forms}. 

We next turn to the level of type declarations  in Sec. \ref{tsm-type}. Type-level TSMs generate not just a type declaration but also the TSL associated with it, allowing TSLs and TSMs to operate in concert, as we will show. 

In Sec. \ref{theory}, we give a minimal type-theoretic account of these mechanisms by extending the bidirectionally typed elaboration semantics for TSLs given previously by Omar et al., leveraging the same underlying hygiene mechanism and internal language.% (emphasizing the cohesion of these mechanisms). %   mechanism to support efforts to  decentralize control over the concrete syntax of a typed programming language. 

Taken together, TSLs and TSMs represent what we see as a new ``high water mark'' in expressive power, particularly within the space of systems providing the strong guarantees described above. We more specifically compare our work to related work in Sec. \ref{related}. 

\section{Background}\label{background}
\subsection{Wyvern}

\begin{figure}[t!]
\begin{lstlisting}[style=wyvern]
type @\htmlcolor{HTML}@ = casetype 
  Empty
  Seq of HTML * HTML 
  Text of String
  BodyElement of Attributes * HTML
  H1Element of Attributes * HTML
  StyleElement  of Attributes * CSS
  (* ... *)
  metadata = new : HasTSL
    val parser = ~
      @\expkwparsercolor{start <- '<body' attributes '>' start '</body>'}@
        fn attrs, e => '@\expcolor{BodyElement((\$}@attrs@\expcolor{, \$}@e@\expcolor{))}@'
      @\expkwparsercolor{start <- '<\{' EXP '\}>'}@
        fn e => e
      (* ... *)

val heading : HTML = H1Element({}, Text("My Heading"))
serve(~) (* serve : HTML -> Unit *)
  @\htmlcolor{<body id="doc1">
    <\{}@heading@\htmlcolor{\}>}@
  @\htmlcolor{<p>My first paragraph.</p>
  </body>}@
\end{lstlisting}
\mycaption{A case type with an associated TSL.}
\label{f-htmltype}
\end{figure}
We will present TSMs in the context of a simplified variant of the Wyvern programming language introduced previously to describe TSLs  \cite{TSLs}, making only minor changes that we will note as they come up. Wyvern is a simply-typed  language with features from both the functional and object-oriented traditions and has a layout-sensitive concrete syntax. An example of a type encoding the tree structure of HTML is declared in Figure \ref{f-htmltype}. The named type \verb|HTML| is a \emph{case type}, with cases for each HTML tag and additional cases for an empty document, a sequence of nodes and a text node. Case types are similar to datatypes in an ML-like language (in type-theoretic terms, recursive labeled sum types). 
We can introduce a value of type \verb|HTML| by naming a case and providing data of the type that case declares,  line 12.

Note that type declarations are generative: the type \verb|HTML| is distinct from any other type, including other case types with the same cases, also as in ML. Unlike in ML and the previous variant of Wyvern, we do not combine type generativity and case types into a single construct. Instead, a named type is declared by deferring semantically to any other type underneath. For the purposes of this paper, this includes case types, tuple types, e.g., \verb|HTML * HTML|, function types, e.g., \verb|HTML -> Unit|, and simple object types. 


Object types in Wyvern are structural (not class-based) and can declare fields (via \texttt{val}) and methods (via \texttt{def}). Two object types are shown in Figure \ref{exp-prelude}, described further below. The introductory form for an object type is \verb|new|, and it can only be used in an \emph{analytic position}, i.e. where the expected type is known (e.g. via an explicit type ascription or as an argument to a function). The keyword \verb|new| serves as a syntactic \emph{forward reference}: it can appear once per line, and the next indented block must give values for all the fields and implementations for all the methods specified by the type.

We also assume that parameterized types can be defined, written e.g. \verb|List(T)|, where \verb|T| is another type, and that the definitions of standard  types like strings, lists and options are ambiently available via the \emph{prelude}, a collection of type declarations loaded before all others. 

All named types can be equipped with \emph{metadata}: a value constructed at compile-time and available for use by the language itself (in particular, the TSL mechanism) as well as other tools. Metadata is analagous to class annotations in Java, or class attributes in .NET languages, but unlike in these languages, it can be any Wyvern value (typically an object, see below).% Here, we will use metadata to associate a TSL with \verb|HTML|. 

\subsection{Type-Specific Languages (TSLs)}


\begin{figure}[t!]
\begin{lstlisting}[style=wyvern]
type HasTSL = objtype
  val parser : Parser(Exp)

type @\expkwparsercolor{Parser}@(T) = objtype
  def parse(ps : ParseStream) : Result(T)
  metadata = new : HasTSL
    val parser = (* ... parser generator ... *)

type @\expcolor{Exp}@ = casetype
  Var of ID
  Lam of ID * Exp
  Ap of Exp * Exp
  Ascription of Exp * Type
  CaseIntro of Case * Exp
  (* ... *)
  metadata = new : HasTSL
    val parser = (* ... exp quasiquotes ... *)

type @\typecolor{Type}@ = casetype
  Named of ID
  Objtype of List(MemberDecl)
  Casetype of List(CaseDecl)
  Arrow of Type * Type
  metadata : HasTSL = new
    val parser = (* ... type quasiquotes ... *)

type Result(T) = casetype
  OK of T
  Error of String * Location
\end{lstlisting}
\mycaption{A portion of the Wyvern prelude relevant to TSLs and TSMs.}
\label{exp-prelude}
\end{figure}
\begin{figure}[t]
\begin{lstlisting}[style=tempwyvern]
'@\htmlcolor{body here, '{}'inner single quotes'{}' must be doubled}@'
{@\htmlcolor{body here, \{inner curly braces\} must be balanced}@}
[@\htmlcolor{body here, [inner braces] must be balanced}@]
<@\htmlcolor{body here, <inner angle brackets> must be balanced}@>
~ (* can appear at any expression position *)
  @\htmlcolor{body here, leading indentation will be removed}@
[@\htmlcolor{adjacent}@] {@\htmlcolor{delimited forms}@} @\htmlcolor{or}@ [@\htmlcolor{those}@] @\htmlcolor{separated}@ ~ @\htmlcolor{form}@
  @\htmlcolor{by identifiers create a single multipart delimited}@
\end{lstlisting}
\mycaption{Available delimited forms. The multipart delimited form is shown being used in Sec. \ref{tsms-term}.}
\label{f-delimited}
\end{figure}

Directly introducing a term of a type like \verb|HTML| using general-purpose syntax like that shown on line 12 can be tedious. Moreover, there is standard concrete syntax for HTML that might be preferable for reasons of familiarity or compatibility. To allow for this, we associate a \emph{type-specific language} with the \verb|HTML| type by setting the metadata to a value of type \verb|HasTSL|, an object type with one field, \verb|parser|. The declarations of \verb|HasTSL| and other types in the prelude relevant to it are shown in Figure \ref{exp-prelude}. 
 %We omit the implementation of the \verb|HTML| type's TSL \verb|parse| method here for concision. 

The TSL for \verb|HTML| is shown being used on lines 13-15 of Figure \ref{f-htmltype}. On line 13, we wish to call a function \verb|serve| of type \verb|HTML -> Unit|. Rather than explicitly constructing a term of type \verb|HTML| as the argument, however, we use the \emph{forward referenced literal form} \lstinline[style=wyvern]{~}. The \emph{body} of the literal consists of the text in the indented block beginning on the next line, stripped of the leading indentation. In effect, whitespace is serving as a delimiter for the literal. We could equivalently have used other \emph{inline delimiters}, e.g. curly braces or single quotes, which restrict what can appear inside them, as described in Figure \ref{f-delimited}. For example, we could have written line 12 equivalently as:
\begin{lstlisting}[style=wyvern, numbers=none, frame=none]
  val heading : HTML = '@\htmlcolor{<h1>My Heading</h1>}@'
\end{lstlisting}

When the type system encounters literal forms like this, it defers to the parser defining the TSL of the type the literal is being analyzed against, here \verb|HTML| because it is the argument type of \verb|serve|. As suggested by the definitions in Figure \ref{exp-prelude}, the TSL is responsible for transforming a \verb|ParseStream| based on the body to a \verb|Result(Exp)|, which is either an \verb|Exp| or a parse error. The case type \verb|Exp| simply encodes the abstract syntax of Wyvern, so the TSL is defined as a desugaring. 

The \verb|parse| method can request that some portion of the parse stream be treated as a \emph{spliced} host language term. For example, the TSL for \verb|HTML| specifies the delimiters \verb|<{| and \verb|}>| to mean ``insert the enclosed term, of type \verb|HTML|, here''. For clarity in this paper, we will color host language terms, including those spliced in this way, black. Portions of TSL (and TSM) bodies that are not spliced host language terms will be colored a unique color corresponding to the TSL or TSM being used, identified when declared. Note that the prelude types \verb|Parser| and \verb|Exp| each have TSLs associated with them, which provide a \emph{grammar-based parser generator} and \emph{quasiquote} facilities, respectively. We see them being used in Figure \ref{f-htmltype}. We refer the reader to \cite{TSLs} for further details on the TSL mechanism.

\section{Syntax macros in Wyvern}
In this section, we employ several examples of syntax macros in Wyvern to illustrate how they are used to solve the problems mentioned in the last section. Syntax macros can be divided into two kinds based on their role in a Wyvern program: syntax macros equivalent to a Wyvern expression, and others equivalent to a Wyvern type declaration. As syntax macros are always associated with a keyword, we use the term ``expression keyword'' and ``type keyword'' to refer to these two kinds of syntax macros.

\subsection{Expression Keyword}
An expression keyword is a keyword associated with a parser to transform DSL literals into a Wyvern expression. Depending on whether a return type is provided in the keyword declaration, expression keywords can be further divided into black-box keyword and white-box keyword (This terminology is borrowed from Scala's macro system). 

\paragraph{Black-box keyword ``simpleHTML''}
We start with an example showing the use of the expression keyword \verb|simpleHTML| to construct a value of type \verb|HTML|. The expression keyword \verb|simpleHTML| provides an alternative syntax to construct the HTML value. The \verb|simpleHTML| syntax is an abbreviate representation of HTML using whitespace to close tags rather than explicit closing tags. The syntax is declared using a parser TSL in line 2-10 in figure \ref{f-simplehtml}.

\begin{figure}[ht]
>>>>>>> 091d797989b8f217204c18fad06a5ea651f88ded
\begin{lstlisting}[style=wyvern]
syntax @\simpleHTMLcolor{simpleHTML}@ : HTML = ~ (* : Parser(Exp) *)
  @\expkwparsercolor{start <- '>body'= attributes> start>}@
    fn attrs, child => "@\expcolor{BodyElement((\$}@attrs@\expcolor{, \$}@child@\expcolor{))}@"
  @\expkwparsercolor{start <- '>p'= attributes> start>}@
    fn attrs, child => "@\expcolor{PElement((\$}@attrs@\expcolor{, \$}@ child@\expcolor{))}@"
  @\expkwparsercolor{start <- text}@
    fn text => "@\expcolor{Text(\$}@text@\expcolor{)}@"
  @\expkwparsercolor{start <- '<'= EXP>}@
    fn e => '@\expcolor{\$}@e'
val y = simpleHTML ~
  @\simpleHTMLcolor{>body[id="doc1"]}@
    @\simpleHTMLcolor{>h1 <\{}@heading_text@\simpleHTMLcolor{\}}@
    @\simpleHTMLcolor{>p My first paragraph}@
\end{lstlisting}
\mycaption{The `simpleHTML' keyword example.}
\label{f-simplehtml}
\end{figure}

In the keyword declaration part, besides the parser definition, a return type (\verb|HTML|) is also provided, which indicates that the DSL literals will elaborate to an expression of type \verb|HTML|. The use of the keyword is presented in line 10-13: the keyword \verb|SimpleHTML| is call in line 10, followed by DSL literals on the next indent level (colored brown). The variable \verb|heading_text| (colored black, in line 12), a \verb|String| variable defined in line 10 of figure \ref{f-htmltype}, is inserted into \verb|SimpleHTML| literals using curly braces, which is used to switch between \verb|SimpleHTML| syntax and original Wyvern syntax.

\todo{Should we add a summary here like ``In this way we can solve the first problem mentioned in the last section''? }

\paragraph{White-box keyword ``if''}
Differently, white-box keywords are defined without specifying the return type. Here we use the key word \verb|if| as an example. The keyword \verb|if| is declared in the type \verb|Bool| which is a casetype with two cases: \verb|True| and \verb|False|. As no return type is declared with \verb|if|, a type should be provided when the keyword is used and the type checker will analyze the expression type against the provided type (e.g. a type \verb|T| is provided in line 10 of figure \ref{if-example} for type analysis). Besides type analysis, we may allow type synthesis on the elaborated Wyvern expression to synthesize the return type of the syntax macro. But considering a stronger type preserving property, we only use type analysis in this case for a white-box keyword, which will be discussed in Sec[\todo{Metatheory Section}].

\begin{figure}[ht]
\begin{lstlisting}[style=wyvern]
type Bool = casetype 
  True
  False
  expkw @\boolIfcolor{if}@ = fn self (* : Exp *) => ~ (* : ExpParser *)
    @\expkwparsercolor{EXP BOUNDARY `else' BOUNDARY EXP}@
      fn e1 (* : Exp *), e2 (* : Exp *) => ~ (* : Exp *)
        @\expcolor{case \$}@self
          @\expcolor{True => \$}@e1
          @\expcolor{False => \$}@e2
def f(x : Bool) : T
  x.if {branch_1} @\boolIfcolor{else}@ {branch_2}
\end{lstlisting}
\mycaption{The black-box keyword `if' example.}
\label{if-example}
\end{figure}

The syntax for \verb|if| is defined on line 5: starting with an expression, followed by an identifier \verb|else| and then another expression. Here we use the parsing mechanism in TSL to support multi-part body parsing: any delimited forms appeared next to each other or delimited by a keyword. Different delimited forms can be referred to figure \ref{f-delimited}. The parser will identify the delimited form and insert a \verb|BOUNDRY| between different delimited forms and the keywords. 

An using example is presented in line 11: the variable \verb|x| (of type \verb|Bool|) invoke the keyword \verb|if| and DSL literals are right next to the keyword. The Wyvern type checker will look up the parser in the definition of \verb|if| in the type \verb|Bool|, and the return type of the keyword invocation expression will be checked against $\verb|T|$, which is provided in the function definition.  

\begin{figure}[ht!]
\begin{lstlisting}[style=wyvern]
type @\expkwparsercolor{ExpParser}@ = objtype
  def parse(ps : ParseStream) : Result(Exp)
  metadata : HasTSL = new 
    val parser = (* parser generator *)

type @\expcolor{Exp}@ = casetype
  Var of ID
  Lam of ID * Exp
  Ap of Exp * Exp
  (* ... *)
  metadata : HasTSL = new
    val parser = (* exp quasiquotes *)

type Result(T) = casetype
  OK of T * ParseStream
  Error of String * Location
\end{lstlisting}
\mycaption{Wyvern prelude for expression keywords extension}
\label{exp-prelude}
\end{figure}

\subsection{Type Keyword}
Besides using expression keywords and TSLs to extend the host language with new syntax in expressions, constructing a type with external syntax can be useful in object-relational mapping (ORM). Although data schema already exists, declaring a type with fields to represent the data structure still require users to create them manually in Wyvern syntax. Type keywords make this process easier by allowing users to generate type declarations directly using the data schema syntax, and furthermore, a metadata will be generated for initializing the value of that type. The following example shows how we construct a type using database schema.
>>>>>>> 091d797989b8f217204c18fad06a5ea651f88ded

\begin{figure}
\begin{lstlisting}[style=wyvern]
type @\dbcolor{EmployeesDB}@ = DBSchema ~
  @\dbshcemacolor{*ID   int}@
  @\dbshcemacolor{Name  varchar}@

val db : EmployeeDB = ~
  @\dbcolor{connect to}@ ~
    @\urlcolor{mysql://localhost:3306}@
  @\dbcolor{username: }@"user1"
  @\dbcolor{password: }@"001"
  @\dbcolor{table: Employees}@
\end{lstlisting}
\mycaption{The usage of the type keyword ``DBTable''}
\label{f-tykwexample}
\end{figure}

\begin{figure}[ht]
\begin{lstlisting}[style=wyvern]
type EmployeesDB = objtype
  type Entry = objtype
    val ID : Int
    val Name : String 
  val connection : URL
  val username : String
  val password : String
  ...
  def getById (x:Int) : Option(Entry)
  def getByName (x : String) : List(Entry)
  metadata = new : HasTSL
    val parser = ~
      ... (* TSL parser generated by type constructor *)

val db : EmployeesDB = new
  val connection = new
    val domain = "localhost"
    ...
  val username = "user1"
  val password = "001"
  ... (* Other fields *)
  def getByID(x:Int) : List(Entry)
    ...
\end{lstlisting}
\mycaption{The elaborated type declaration}
\label{typekw-example-2}
\end{figure}

\begin{figure}[ht]
\begin{lstlisting}[style=wyvern]
typekw @\dbshcemacolor{DBSchema}@ with metadata:HasTSL = ~ (*:TypeParser*)
  @\typekwparsercolor{start <- pairs}@
    fn pairs =>
      let ty : Type = ~
        @\typecolor{objtype}@
          @\typecolor{type Entry = objtype}@
            @\typecolor{\{}@map(pairs, Nil, 
              fn ((p, lbl, ty), l) => Cons(~, l))
                @\membercolor{val \$}@lbl @\membercolor{:  \$}@ty
            @\typecolor{\}}@
          @\typecolor{val connection : URL}@
          @\typecolor{val username : String}@
          @\typecolor{val password : String}@
          @\typecolor{...}@
          @\typecolor{\{}@map(pairs, Nil, 
            (fn ((p, lbl, ty), l) => Cons(~, l)))
              @\membercolor{def getBy\$}@lbl @\membercolor{(\$}@ty@\membercolor{)}@
          @\typecolor{\}}@
      let md : HasTSL = new 
        val parser = ~
          @\hastslcolor{start <- ("connect to "= EXP>}@
                    @\hastslcolor{"username:"= EXP>}@
                    @\hastslcolor{"password:"= EXP>}@
                    @\hastslcolor{"table:" EXP>)}@
            fn url, un, pw, table => ~
              @\expcolor{new}@ 
                @\expcolor{val connection = \$}@url
                @\expcolor{val username = \$}@un
                @\expcolor{val password = \$}@pw
                @\expcolor{...}@
                @\expcolor{\{}@map(pairs, Nil, 
                  (fn ((p, lbl, ty), l) => Cons(~, l)))
                    @\membercolor{def getBy}@$lbl @\membercolor{(x)}@ 
                      @\membercolor{...}@(* implementation *)
                @\expcolor{\}}@
      (ty, md, Nil)
  @\typekwparsercolor{pairs <- ()}@
    fn () => Nil 
  @\typekwparsercolor{pairs <- pair= pairs=}@
    fn hd, tl => Cons(hd, tl)
  @\typekwparsercolor{pair <- "*"? ID ID}@
    fn is_primary, colid, tyid => (
      is_primary, colid, ty_from_sqlty(tyid))
\end{lstlisting}
\mycaption{The declaration the type keyword ``DBTable''}
\label{typekw-example-1}
\end{figure}

In figure \ref{f-tykwexample}, we present an example of constructing the type \verb|EmployeeDB| using the type keyword \verb|DBSchema|. By defining the type \verb|EmployeeDB| using a type keyword, the type \verb|EmployeeDB| will be provided with the following fields/methods after elaboration (line 1-13 in figure \ref{typekw-example-2}):
\begin{itemize}\setlength{\itemsep}{0pt}
\item Fields and method declarations based on the data schema. (e.g. \verb|employee|, \verb|getByName|)
\item Common fields and method declarations provided for all types using the type keyword, and they don't depend on a certain schema. (e.g. \verb|connection| and \verb|stmts|)
\item A TSL metadata for value initialization using the DSL syntax.
\end{itemize}

Line 1-3 in figure \ref{f-tykwexample} shows the declaration of the type \verb|EmployeeDB| using database schema syntax. And a value \verb|db| (line 5-10) is defined using the syntax provided by the generated TSL metadata. 

The elaborated version of the type \verb|Employee| and the value \verb|db| is presented in figure \ref{typekw-example-2}: a type member \verb|Entry| is declared in the type to represent a data table entry, and methods like \verb|getById| are generated for database access. The elaborated value \verb|db| (line 15) is initialized with fields and methods.

The definition of the type keyword \verb|DBSchema| can be referred to figure \ref{typekw-example-1}. A type keyword itself is a parser for DSL literals: it is a value of type \verb|TypeParser|, which takes in a parsestream and returns a parsing result (of type \verb|Result|, which is a casetype defined in figure \ref{exp-prelude}). When there is no parsing error, a tuple \verb|(t:Type, e:Exp, k:List(KwMember))| will be returned for type construction: the type structure stored in \verb|t|, metadata in \verb|e|, and expression keywords defined by \verb|k|. \verb|DBSchema| will construct an object type with fields specified in line 5-18, and it will provide a TSL metadata for value initialization (line 20-35). The type of the metadata is provided on the first line of keyword declaration with keyword \verb|with metadata|, which is used by the type checker to analyze the metadata type.

\begin{figure}
\begin{lstlisting}[style=wyvern]
type @\typekwparsercolor{TypeParser}@ = objtype
  def parse(ps : ParseStream) : Result(Type * Exp * List(KwMember))
  metadata : HasTSL = new 
    val parser = (* parser generator *)

type @\typecolor{Type}@ = casetype
  Named of ID
  Objtype of List(MemberDecl)
  Casetype of List(CaseDecl)
  Arrow of Type * Type
  metadata : HasTSL = new
    val parser = (* type quasiquotes *)

type KwMember = casetype
  Whitebox of Label * ExpKw
  Blackbox of Label * ExpKw * Type
\end{lstlisting}
\mycaption{Wyvern prelude for type keywords}
\end{figure}



\section{Syntax}
We start our formal presentation by introducing the abstract syntax built upon pure functional Wyvern, together with their concrete forms. For simplicity consideration, we omit some of the syntax not directly related to composable syntax macros, which can be referred to \todo{TSL paper}.

A Wyvern program ($\rho$) consists of three parts: type keyword declarations ($\eta$), named-type declarations ($\theta$) and an expression ($e$) representing the program body.
>>>>>>> 091d797989b8f217204c18fad06a5ea651f88ded

\todo{Stop here, continue working later}

\begin{figure}[ht]
\hspace{-5px}\begin{tabular}{ l l l l l }
 \multicolumn{1}{l}{\textbf{Abstract Forms}} & \multicolumn{1}{l}{\textbf{Concrete Forms}}\\
 \multicolumn{3}{l}{Programs}\\
$\rho$~::=~$\eta;\theta;e$\\
\multicolumn{3}{l}{Type Keywords}\\
$\eta$~::=~$\emptyset$\\
\tabularspace$\eta;k[e,\tau]$ & \textcd{typekw} $k$ \textcd{with metadata:}$\tau$ \textcd{=} $e$ \\
\multicolumn{3}{l}{Expression Keywords}\\
$\kappa$~::=~$\emptyset$                        & \\
\tabularspace$\kappa;k[\mathbf{bk}(\tau),e]$    & \textcd{expkw} $k$ : $\tau$ \textcd{=} $e$\\
\tabularspace$\kappa;k[\mathbf{wk},e]$          & \textcd{expkw} $k$ \textcd{=} $e$\\
\multicolumn{3}{l}{Type Declarations}\\
$\theta$~::=~$\emptyset$                        & \\
\tabularspace$\theta; T[\mathbf{explicit},\tau, e, \kappa]$  & \textcd{type} $T$ \textcd{=} $\tau$\\
&~~~\textcd{metadata = }$e$\\
&~~~$\kappa$\\
\tabularspace$\theta; T[\mathbf{tykw},k, body, e, \kappa]$   & \textcd{type} $T$ \textcd{=} $k$ $delims$\\
                                                          & ~~~\textcd{metadata = }$e$\\
                                                          & ~~~$\kappa$\\
\multicolumn{3}{l}{Types}\\
$\tau$~::=~$\mathbf{named}[T]$              & $T$\\
\tabularspace$\mathbf{objtype}[\omega]$       & \textcd{objtype} $\omega$ \\
\tabularspace$\mathbf{casetype}[\chi]$        & \textcd{casetype} $\chi$\\
\tabularspace$\mathbf{arrow}[\tau, \tau]$     & $\tau$ \textcd{->} $\tau$\\
\multicolumn{3}{l}{Object Fields}\\       
$\omega$~::=~$\emptyset$                      \\
\tabularspace$l[\mathbf{val},\tau];\omega$                 & \textcd{val} $l$ : $\tau$\\
\tabularspace$l[\mathbf{def},\tau];\omega$                 & \textcd{def} $l$ : $\tau$\\
\multicolumn{3}{l}{Casetype Cases}\\
$\chi$~::=~$\emptyset$                      \\                 
\tabularspace$C[\tau];\chi$                   & $C$~\textcd{of}~$\tau$\\
\multicolumn{3}{l}{External Term}\\
 $e$~::=~...                              & \\
\tabularspace$\mathbf{lit}[body]$             & $delims$\\
\tabularspace$\mathbf{ekey}[k,body](e)$       & $e.k$ $delims$\\
\multicolumn{3}{l}{Translational Terms}\\
$\hat{e}$~::=~...                              & \\
\tabularspace$\mathbf{spliced}[e]$            & \\
\multicolumn{3}{l}{Internal Terms}\\
$i$~::=~...                                                     
\end{tabular}
\mycaption{Abstract and Concrete Forms}
\label{formal-syntax}
\end{figure}


\paragraph{Type-keyword Declaration}
Users define type keywords in the type-keyword declaration section ($\eta$). The declaration of a keyword includes an expression $e$ and a metadata type $\tau$. The expression $e$ is the parser to parse the DSL literals used in a type keyword invocation, and the type $\tau$ is the type of the metadata which will be generated by the parser. The type keyword declaration is supposed to belong to a module, but as module is not defined in our language formal, it is presented at the top level of the program.

\paragraph{Named type declaration}
Named type declarations is the declaration of types associated with their names, and according to the way to declare, there are two kinds of type declarations: an explicit type declaration with their structure and metadata directly specified, or a type keyword based declaration, whose structure, metadata and keywords are defined using a type keyword.

An explicit type declaration ($T[\mathbf{explicit}, \tau,e,\kappa]$) consists of four parts: $T$ as the type name, $\tau$ as the structure of the type, (which can be one of $\mathbf{objtype}$, $\mathbf{casetype}$, $\mathbf{arrowtype}$ or a copy of named type $\mathbf{named}[T']$),  $e$ as the metadata associated with the type and $\kappa$ as the expression keywords associated with the type. 

The second kind ($T[\mathbf{tykw},k,body,e,\kappa]$) is a type declared using a type keyword $k$, with DSL literals specified by $body$. Metadata ($e$) and expression keywords ($\kappa$) can be defined as an extension of metadata and keywords generated by the type keyword $k$, the details for this extension mechanism will be presented in the next section.

\paragraph{External Expressions}
Our extensions on external terms to support syntax macros including a keyword invocation expression ($\mathbf{ekey}[k,body](e)$) and several expression for parser access at run-time (omitted here, can be referred to \todo{TR}). The keyword invocation expression includes the following parts: an expression $e$, a keyword $k$ and the delimited DSL literals $body$.

Note that there is no extension on the translational expressions and inner expressions, as keywords invocation and parser access will be transformed to inner Wyvern expressions and no DSL literals will exist after elaboration.

\section{Bidirectional Typechecking and Elaboration}
Both expression keywords and type keywords are used in external Wyvern languages, so an elaboration phase is required to parse a type keyword defined type into type context and transform the external term into internal Wyvern terms. 
>>>>>>> 091d797989b8f217204c18fad06a5ea651f88ded

Bidirectional typechecking is used here as type can be clearly specified as input or output during typechecking process. In bidirectional type system, a type judgment is written as $\Gamma\vdash_{\Theta} e\Leftarrow(\Rightarrow)\tau$ instead of $\Gamma\vdash_{\Theta} e:\tau$ in a traditional type system, where $\Gamma$ is the typing context, $\Theta$ is the declaration context, and the type $\tau$ is specified as input ($\Leftarrow$) or output ($\Rightarrow$) according to the arrow direction. 

The type checking process also involves the elaboration of an external expression, written as $\Gamma\vdash_{\Theta} e\rightsquigarrow i \Leftarrow(\Rightarrow) \tau$. It indicates that an external expression will be elaborates to an internal expression and synthesize to (or analyze against) the type $\tau$. The arrow ($\rightsquigarrow$) is used to represent the elaboration process, including literal elimination and hygiene process, which is part of the type checking rules.

\subsection{ Definition}
\todo{Type environment or type context or typing context?}
The type context (figure \ref{typechecking-environment}) contains the context for type keywords and named type declarations, which will be used during elaboration and type checking. The type context 

\begin{figure}[ht]
\begin{center}
\begin{tabular}{r r c l}
Type Keyword Context & $\Delta$ & ::= & $\emptyset$\\
              &                 &  |  & $\Delta;k[i,\tau]$\\
Named Type Context  & $\Theta$        & ::= & $\emptyset$\\
              &                 &  |  & $\Theta,T[\delta,\mu,\zeta]$\\
              & $\delta$        & ::= & $?$ ~ | ~ $\tau$\\
   & $\mu$           & ::= & $?$ ~ | ~ $i:\tau$\\
   & $\zeta$         & ::= & $?$ ~ | ~ $\dot\kappa$\\
Keyword Members & $\dot\kappa$    & ::= & $\emptyset$\\
            &                 &   |  & $\dot\kappa;k[\mathbf{bk}(\tau),i]$\\
            &                 &   |  & $\dot\kappa;k[\mathbf{wk},i]$\\
Typing Context & $\Gamma$ &   ::=  & $\emptyset$\\
                 &          &     |  & $\Gamma,x:\tau$
\end{tabular}
\end{center}
\mycaption{Definition of type context}
\label{typechecking-environment}
\end{figure}

The elaboration rules for type declarations includes 

To support mutually recursive type declaration, we split the checking rules for type declarations into three steps: 1) Add the type name into the type environment. 2) Add the type structure into the environment. 3) Check the type extensions (i.e. TSL or expression keywords) and add them into the environment. A type can refer to another one in the field or type extensions. But the extension in a type cannot refer to that from a type defined after it, as using extension syntax recursively can make the program too complicated.

For a normal named type declaration, we have rules type-name, type-defs, type-exts to add the type into the environment. The rule type-name will check that the name has not yet appeared in the previous environment to avoid conflicts while the rule type-defs checks the formation of the type structure, i.e. whether fields in a objtype or cases in a casetype is well formed. And the last rule type-exts will add the metadata and the expression keywords declaration into the environment, where the external representation of the metadata ($e_m$) will be transformed into a inner Wyvern expression of type $\tau_m$ ($i_m:\tau_m$) and the keywords declaration ($\kappa$) will be transformed to $\dot\kappa$. 

In the transformation of $\kappa\rightsquigarrow\dot\kappa$, two rules exists to deal with both black-box keywords and white-box keywords. Both of the two rules will check there is no name conflicts in a type keyword. And the parser expression ($e_k$) should elaborates to an Wyvern expression ($i_m$) and checks against $TypeKw$, which is a standard type saved in the prelude environment for the keyword parser type. The difference between black-box and white-box keywords lies in the fact that a return type is presented in the declaration of a black-box keyword while a white-box one doesn't.

The type environment $\Theta$ is finished once $\Theta_{names}, \Theta_{defs}$ and $\Theta_{exts}$ are processed.

\subsection{External Type Literals}
In the type environment, there is no difference between the two types of type declaration mentioned in the syntax as all types defined using type keywords elaborates to a type with concrete structure during type checking process.

The type checking rules for type keywords usage is labeled as type-name-2, type-defs-2 and type-exts-2. The rule type-name-2 simply adds the type name into the environment for other types to refer to.

The rule type-name-2 present the type elaboration process, and the external syntax used in type keyword will be transformed to a normalized type structure. The process consists of the following steps:
\begin{enumerate}\setlength{\itemsep}{0pt}
\item Check if the environment prelude is in the type environment. The prelude environment consists of necessary types and parser definition. 
\item Look up the keyword in $\Delta$. This requires a valid parser defined in the type keyword environment for parsing the literals later.
\item Invoke the parser to parse the DSL literal body ($i_{ps}$, as an expression the parser parsed to). In the rule kw-env, the parser is already checked against type $TypeKw$, so the parser is of type $PasrseStream->DeclResult$. So a return type ($i_{type}$) and an type metadata ($i_{exp}$) will be provided by the parser.
\item The type expression ($i_{type}$) will be transformed to a Wyvern type structure (i.e. objtype or casetype) using type dereification rules (marked as `$\uparrow$'). And the type will be checked to guarantee the formation of its structure.
\item The metadata expression will be reconstructed, it will be reificate to a spliced expression and then transform to an inner Wyvern expression of type $\tau_m$. 
\end{enumerate} 
After these steps, the type structure as well as the TSL metadata associated with the type is generated, and no more external type syntax exists.

The rule type-exts-2 stands for the rule to resolve the metadata conflict between the metadata generated by type keyword ($i_m$) and that defined in the named type declaration ($i_w$). In the rule type-exts for normal named type declaration, the metadata will be directly added into the environment, but in this case, we require $i_w$ to be a metadata resolver: it should be a function of type $\tau_m\rightarrow\tau'_m$, as it will take in $i_m$ and return a modified metadata $i'_m$ ($\mathbf{iap}(i_w, i_m)\Downarrow i'_m$ presents the process). The expression keywords part is the same as that in a normal named type declaration.
\input{kw-elaboration.tex}

\subsection{Expression Keywords Literals}
Besides type keywords and TSLs, another usage of the DSL literals is in expression keywords. The different rules to process keywords invocation includes three situations: Using DSL literals in a black-box keyword, using DSL literals in a white-box keyword with type analysis and using DSL literals in a white-box keyword with type synthesis. Their difference only lies in the inference of the return type so we only explain the rule using the rule T-wk-syn. Processing literals in an expression keyword invocation includes the following steps:
\begin{enumerate}\setlength{\itemsep}{0pt}
\item Check that the prelude environment $\Theta_0$ is in the current environment. 
\item The target term ($e_0$) elaborates into an inner Wyvern term ($i_0:T$), and then check that the type $T$ is declared in the type environment with an keyword environment $\dot\kappa$ inside it.
\item Look up the expression keyword inside the keyword declarations, as checked in the rule expkw-bk and expkw-wk, the parser should be of type $ExprKw$ (The parser type for expression keyword presented in Wyvern prelude).
\item Transform the target expression into an reified elaboration form ($i_0\downarrow i'_0$), this will transform the target expression into an \verb|Exp| expression, which will be used in the parsing process of literal elaboration.
\item The parser takes in two expressions: the reified target expression and the parsestream of the literals, then generate an expression of type $Result$, which will be used to build the return expression.
\item The expression is dereified into an translational term of $\hat{e}$, which is used to mirror an external term but transform the representation of DSL literals into $\mathbf{spliced}[e]$, as a middle representation before elaborates to an external term.
\item The last step is type checking. It checks the term $i$ which will synthesize to type $\tau$ (For black-box keyword or white-box under analysis, it will be replaced by a type analysis against $\tau$). The expression the keyword invocation elaborates to should be the expression $i$ of type $\tau$, which is an inner Wyvern term used to compile and execute at run time. 
\end{enumerate}
\input{kw-statics.tex}

\subsection{Hygiene}
\todo{Do we need to do it here?}

\subsection{Metatheory}
\paragraph{Reification and Dereification}
For each type and expression, we have the following properties to support converting a type to an expression of type \textbf{named}[$Type$] and an expression to an expression of type \textbf{named}[$Exp$] (Property 1, 2). And reversely, converting an inner term to an Wyvern expression $i$ of type $\mathbf{named}[Exp]$ (Property 3). These properties are used to construct a type $\tau$ or an expression $\hat{e}$ from parsing results (an expression of type $Exp$ or $Type$) in the elaboration rule. 
\begin{property}If $\emptyset\vdash_{\Theta} i:\mathbf{named}[Type]$ then there exists a corresponding $\tau$ s.t. $i\uparrow\tau$. 
\end{property}
\begin{property}
If $\emptyset\vdash_{\Theta} i:\mathbf{named}[Exp]$ then there exists an translational term $\hat{e}$, s.t. $i\uparrow\hat{e}$.
\end{property}

\begin{property}
For any $i$, these exists an inner term $i'$, s.t. $i\downarrow i'$ and $\emptyset\vdash_{\Theta_0} i':\mathbf{named}[Exp]$.
\end{property}
The rules for these properties can be referred to \todo{TR}.

\paragraph{Type Safety and Preservation}
Extension of the TSL Wyvern semantics with keywords mechanism still constitutes a type safe language. We will outline the key theorems and lemmas here presenting the properties a type safe language has: 1) internal type safety 2) type preservation. 

To formalize the type safety property, we defined the judgments for context formation, type formation and bidirectional typing judgment. \todo{Refer to TSL as well as TR}

\begin{theorem}[Internal Type Safety]
If ~$\vdash_{\Theta_0}\Delta$, $\vdash_{\Theta_0}\Theta$~ and $\emptyset\vdash_{\Theta}i\Leftarrow\tau$ or $\vdash_{\Theta}i\Rightarrow\tau$, then either $i~\texttt{val}$ or $i\mapsto i'$ such that $\emptyset\vdash_{\Theta}i'\Leftarrow\tau$.
\end{theorem}
\begin{proof}
As the keyword extension on TSL framework does not extend inner Wyvern expressions, the proof for this theorem is directly from TSL proof. 
\end{proof}

\begin{theorem}[External Type Preservation]
If ~$\vdash_{\Theta_0}\Delta$, $\vdash_{\Theta_0}\Theta$, $\vdash_{\Theta}\Gamma$, and $\Gamma\myvdash e\rightsquigarrow i\Leftarrow\tau$ or $\Gamma\myvdash e\rightsquigarrow i\Rightarrow\tau$ then $\Gamma\myvdash i\Leftarrow\tau$.
\end{theorem}
\begin{proof}
Based on TSL proof of the external type preservation, we need to proof the following cases on keywords extension (Expressions for parser access is presented in the \todo{TR}, thus the corresponding proofs of the case for the expression is omitted here. ):
\begin{itemize}
\item $e=\mathbf{ekey}[k,body](e)$. According to the rule T-bk and T-wk, $\Gamma\vdash_{\Theta}\mathbf{ekey}[k,body](e_0) \rightsquigarrow i \Rightarrow \tau \Longrightarrow \Gamma;\emptyset\myvdash \hat{e} \rightsquigarrow i \Rightarrow \tau$. According to Lemma 1, $\Gamma;\emptyset\myvdash \hat{e} \rightsquigarrow i \Rightarrow \tau \Longrightarrow \Gamma;\emptyset\vdash_{\Theta} i\Rightarrow\tau$.
\end{itemize}
\end{proof}

\begin{lemma}[Translational Type Preservation]
If \\$\vdash_{\Theta_0}\Theta$, $\vdash_{\Theta_0}\Delta$ and $\vdash_{\Theta}\Gamma_{out}$ and $\vdash_{\Theta}\Gamma$ and $dom(\Gamma_{out})\cap dom(\Gamma)=\emptyset$ and $\Gamma_{out};\Gamma\vdash_{\Theta}^{\Delta}\hat{e}\rightsquigarrow i\Leftarrow\tau$ or $\Gamma_{out};\Gamma\vdash_{\Theta}^{\Delta}\hat{e}\rightsquigarrow i\Rightarrow \tau$ then $\Gamma_{out}\Gamma\vdash_{\Theta}i\Leftarrow \tau$.
\end{lemma}


\begin{theorem}[Compilation]
If ~$\rho\sim\Theta\rightsquigarrow i:\tau$~ then $\vdash_{\Theta_0}\Delta$,\ $\vdash_{\Theta_0}\Theta$ and $\emptyset\vdash_{\Theta} i\Leftarrow\tau$.
\end{theorem}
\begin{proof}
This theorem can be proved with the following two lemmas for the formation of $\Delta$ and $\Theta$.
\end{proof}

\begin{lemma}[Type Keyword Declaration] 
If $\vdash_{\Theta_0}\eta\sim\Delta$, then $\vdash_{\Theta_0}\Delta$.
\end{lemma}
\begin{proof}
The proof is simple a induction on $\vdash_{\Theta_0}\Delta$ and using the External Type Preservation Theorem. (Not shown)
\end{proof}

\begin{lemma}[Type Declaration]
If $\vdash_{\Theta_0}^{\Delta}\theta\sim\Theta$ then $\vdash\Theta_0\Theta$.
\end{lemma}
\begin{proof}
By induction on the formation of $\Theta$, we have the following three cases:
\begin{itemize}
\item $\vdash_{\Theta}\emptyset\sim\emptyset \Longrightarrow \vdash{\emptyset}$.
\item ${\vdash^{\Delta}_{\Theta}} \theta';T[\mathbf{explicit},\tau,e_m,\kappa] \sim \Theta',T[\tau,i_m:\tau_m,\dot\kappa] \Longrightarrow \vdash_{\Theta}\Theta',T[\tau,i_m:\tau_m,\dot{\kappa}]$. 

By induction, we have $\vdash_{\Theta}\Theta'$. And by the rule (ctx-explicit-type), we have $\vdash_{\Theta\Theta',T[?,?,?]}^{\Delta}\tau, \myvdash\dot\kappa$ and $\emptyset\vdash_{\Theta\Theta',T[\tau,?,?]}^{\Delta}e\rightsquigarrow i_m\Rightarrow\tau_m$. With External Type Preservation Lemma, we have $\vdash_{\Theta}\Theta',T[\tau,i_m:\tau_m,\dot{\kappa}]$.
\item $\myvdash \theta';T[\mathbf{tykw},k,body,e_m,\kappa] \sim \Theta',T[\tau,i''_m:\tau'_m,\dot{\kappa}\dot{\kappa}'] \Longrightarrow \vdash_{\Theta}\Theta',T[\tau,i''_m:\tau'_m,\dot{\kappa}\dot{\kappa}'].$

By induction, we have $\myvdash\Theta'$. And by rule (ctx-typekw-type), we have (1) $\vdash_{\Theta\Theta',T[?,?,?]}^{\Delta}\tau$. (2).$\dot\kappa\dot\kappa'$ is well formed the the fact that $\myvdash \dot\kappa$~~~~ $\vdash^{\Delta}_{\Theta\Theta',T[\tau,i'_m:\tau'_m,?]}\kappa\rightsquigarrow\dot{\kappa}'$ ~~~~ $dom(\dot{\kappa})\cap dom(\dot{\kappa}')=\emptyset$. (3) $i''_m:\tau'_m$ is well formed by the formation of $i'_m$ and the application of $i'_m$ on $i_m$. Thus we have the formation of the \textbf{tykw} construction.
\end{itemize}
With the three cases proved, we have the formation of type declaration proved.
\end{proof}

%\input{kw-contextformation.tex}

% end the environment with {table*}, NOTE not {table}!
\section{Related Work}\label{related}
\section{Conclusions}
This paragraph will end the body of this sample document.
Remember that you might still have Acknowledgments or
Appendices; brief samples of these
follow.  There is still the Bibliography to deal with; and
we will make a disclaimer about that here: with the exception
of the reference to the \LaTeX\ book, the citations in
this paper are to articles which have nothing to
do with the present subject and are used as
examples only.
%\end{document}  % This is where a 'short' article might terminate

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
This section is optional; it is a location for you
to acknowledge grants, funding, editing assistance and
what have you.  In the present case, for example, the
authors would like to thank Gerald Murray of ACM for
his help in codifying this \textit{Author's Guide}
and the \textbf{.cls} and \textbf{.tex} files that it describes.

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{../ecoop14/research}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
\end{document}