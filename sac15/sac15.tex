

% This is "sig-alternate.tex" V1.9 April 2009
% This file should be compiled with V2.4 of "sig-alternate.cls" April 2009
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.4 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.4) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V1.9 - April 2009

\documentclass{sig-alternate}
  \pdfpagewidth=8.5truein
  \pdfpageheight=11truein

\usepackage{epstopdf}
\usepackage{bussproofs}
\usepackage[usenames,dvipsnames]{color} % Required for specifying custom colors and referring to colors by name
\usepackage{listings}
\usepackage{xcolor}
\usepackage{verbatim}
\usepackage{multirow}
\usepackage{array}
\EnableBpAbbreviations
\input{macros.tex}

\newcommand\BeraMonottfamily{%
  \def\fvm@Scale{0.85}% scales the font down
  \fontfamily{fvm}\selectfont% selects the Bera Mono font
}

\lstdefinestyle{wyvern}{
%backgroundcolor=\color{highlight}, % Set the background color for the snippet - useful for highlighting
basicstyle=\scriptsize\BeraMonottfamily, % The default font size and style of the code
breakatwhitespace=false, % If true, only allows line breaks at white space
breaklines=true, % Automatic line breaking (prevents code from protruding outside the box)
captionpos=b, % Sets the caption position: b for bottom; t for top
morecomment=[s]{(*}{*)},
commentstyle=\fontshape{it}\color{Gray}\selectfont, % Style of comments within the code - dark green courier font
deletekeywords={}, % If you want to delete any keywords from the current language separate them by commas
%escapeinside={\%}, % This allows you to escape to LaTeX using the character in the bracket
firstnumber=1, % Line numbers begin at line 1
frame=lines, % Frame around the code box, value can be: none, leftline, topline, bottomline, lines, single, shadowbox
frameround=tttt, % Rounds the corners of the frame for the top left, top right, bottom left and bottom right positions
keywords=[1]{new, objtype, type, casetype, val, def, metadata, expkw, of, fn, with, typekw, let},
keywordstyle={[1]\bfseries},
keywordstyle={[3]\color{red!80!orange}},
morekeywords={}, % Add any functions no included by default here separated by commas
numbers=left, % Location of line numbers, can take the values of: none, left, right
numbersep=8pt, % Distance of line numbers from the code box
numberstyle=\tiny\color{Gray}, % Style used for line numbers
rulecolor=\color{black}, % Frame border color
showstringspaces=false, % Don't put marks in string spaces
showtabs=false, % Display tabs in the code as lines
stepnumber=1, % The step distance between line numbers, i.e. how often will lines be numbered
tabsize=4, % Number of spaces per tab in the code
}

\lstdefinestyle{tempwyvern}{
basicstyle=\scriptsize\BeraMonottfamily, % The default font size and style of the code
breakatwhitespace=false, % If true, only allows line breaks at white space
breaklines=true, % Automatic line breaking (prevents code from protruding outside the box)
captionpos=b, % Sets the caption position: b for bottom; t for top
morecomment=[s]{(*}{*)},
commentstyle=\fontshape{it}\color{Gray}\selectfont, % Style of comments within the code - dark green courier font
deletekeywords={}, % If you want to delete any keywords from the current language separate them by commas
%escapeinside={\%}, % This allows you to escape to LaTeX using the character in the bracket
firstnumber=1, % Line numbers begin at line 1
frame=lines, % Frame around the code box, value can be: none, leftline, topline, bottomline, lines, single, shadowbox
frameround=tttt, % Rounds the corners of the frame for the top left, top right, bottom left and bottom right positions
keywords=[1]{new, objtype, type, casetype, val, def, metadata, expkw, of, fn, with, typekw, let},
keywordstyle={[1]\bfseries},
keywordstyle={[3]\color{red!80!orange}},
morekeywords={}, % Add any functions no included by default here separated by commas
numbers=left, % Location of line numbers, can take the values of: none, left, right
numbersep=8pt, % Distance of line numbers from the code box
numberstyle=\tiny\color{Gray}, % Style used for line numbers
rulecolor=\color{black}, % Frame border color
showstringspaces=false, % Don't put marks in string spaces
showtabs=false, % Display tabs in the code as lines
tabsize=4, % Number of spaces per tab in the code
}
\lstset{basicstyle=\footnotesize\,breaklines=true}
\lstset{escapeinside={@}{@}}
\newcommand{\htmlcolor}[1]{\textcolor[HTML]{339933}{#1}}
\newcommand{\expkwparsercolor}[1]{\textcolor[HTML]{336699}{#1}}
\newcommand{\typekwparsercolor}[1]{\textcolor[HTML]{7C803E}{#1}}
\newcommand{\urlcolor}[1]{\textcolor[HTML]{FFCC33}{#1}}
\newcommand{\expcolor}[1]{\textcolor[HTML]{FF0033}{#1}}
\newcommand{\membercolor}[1]{\textcolor[HTML]{FF6600}{#1}}
\newcommand{\typecolor}[1]{\textcolor[HTML]{660066}{#1}}
\newcommand{\dbcolor}[1]{\textcolor[HTML]{FF47FF}{#1}}
\newcommand{\hastslcolor}[1]{\textcolor[HTML]{002FC9}{#1}}
\newcommand{\simpleHTMLcolor}[1]{\textcolor[HTML]{7D5100}{#1}}
\newcommand{\boolIfcolor}[1]{\textcolor[HTML]{5E0C0C}{#1}}
\newcommand{\dbshcemacolor}[1]{\textcolor[HTML]{5AC3D1}{#1}}

\newcommand{\flyingbox}[1]{\begin{flushleft}\fbox{{#1}}\end{flushleft}}
\newcommand{\myvdash}{\vdash_{\Theta}^{\Delta}}
\newcommand{\textcd}[1]{\textbf{\scriptsize\BeraMonottfamily{#1}}}
\newcommand{\textsp}[1]{\text{\footnotesize\BeraMonottfamily{#1}}}
\newcommand{\mycaption}[1]{\vspace{-4px}\caption{#1}\vspace{-2px}}
\newcommand{\tabularspace}{~~~~~~~}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{property}{Property}

\begin{document}

%
% --- Author Metadata here ---
\conferenceinfo{SAC'15}{April 13-17, 2015, Salamanca, Spain.}
\CopyrightYear{2015} % Allows default copyright year (2002) to be over-ridden - IF NEED BE.
\crdata{978-1-4503-3196-8/15/04}  % Allows default copyright data (X-XXXXX-XX-X/XX/XX) to be over-ridden.
% --- End of Author Metadata ---

\title{Composable and Hygienic Typed Syntax Macros}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{1} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Chenglong Wang ~~~~~~~~ Cyrus Omar ~~~~~~~~ Jonathan Aldrich \\ Carnegie Mellon University \\ \email{\{stwong, comar, aldrich\}@cs.cmu.edu}
% 2nd. author
}
%\and  % use '\and' if you need 'another row' of author names

% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
This is abstract.
\end{abstract}

% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]
%\terms{Delphi theory}
%\keywords{ACM proceedings, \LaTeX, text tagging}

\section{Introduction}
As general-purpose programming languages evolve, they inevitably accumulate \emph{syntactic sugar} to capture common idioms more concisely or naturally. In most contemporary languages, syntactic sugar must be built in by the language designers. Consequently, idioms that arise only situationally or in specialized domains may be neglected. This dynamic has motivated substantial research into mechanisms that allow the users of a language to extend its syntax directly. 

Decentralizing control over syntax is difficult because there is no central designer to bear the responsibility of ensuring that there are no parsing ambiguities and that desugarings are semantically well-behaved. Instead, the extension mechanism must provide these important guarantees:

\noindent
\textbf{Composability} Separately defined fragments of syntax that are known not to cause parsing ambiguities individually can, in general, still cause ambiguities when they are composed by interfering directly with one another (e.g. extensions adding support for XML and HTML). To avoid this issue, the mechanism must  separate extensions from one another, without sacrificing too much expressive power.

\noindent
\textbf{Hygiene} The desugaring logic  must be constrained to ensure that the meaning of a term cannot change simply because some surrounding variables have been renamed (e.g. manually or by a refactoring tool). It should also be possible to determine the binding site of a variable, even if there are intervening uses of sugar. These two situations correspond to inadvertent variable capture and shadowing, respectively. 

\noindent
\textbf{Typing Discipline} In a statically typed setting, which will be our focus in this work, a \emph{typing discipline} is also ideally maintained: determining the type of a term should be possible without requiring that the desugaring be performed, to aid both programmers and tools. 

Most prior approaches to syntax extension, summarized in Sec. \ref{related}, has failed to consider at least one of these goals. Recent work on \emph{type-specific languages} (TSLs) achieves these goals, but only in a limited setting: library providers can define new syntax for introducing values of a type (i.e. \emph{literal forms}), associating it with the type when it is declared \cite{TSLs}. Local type inference, specified as a bidirectional type system \cite{Pierce:2000:LTI:345099.345100}, controls which syntax extension is invoked, so extensions are composable and maintain the typing discipline. The semantics given by Omar et al. also guarantees hygiene. We will show an example of a TSL in Sec. \ref{background}.

Many forms of syntactic sugar can be seen as TSLs, but there remain situations where the mechanism described by Omar et al. is insufficient. 

(limitations: 1) cannot choose different for same type, 2) cannot extend language with new operations, 3) cannot generate types using specialized syntax) (compare to Scala and other typed macro systems -- can only repurpose existing syntax, not add new syntax)

(contributions: we extend the TSL work with expression (Sec 2) and type-level (Sec 3) syntax macros, build on same underlying semantics (Sec 4) to ensure composition and hygiene)

\section{Background}\label{background}
As we present our work as an extension of the type-specific language built on Wyvern, some background for type-specific language mechanism and Wyvern language is necessary to present the extensible keywords mechanism. 

\subsection{Type-Specific Language}
Type-Specific Language(TSL) is designed to support constructing a datatype using specific designed syntax (e.g. HTML) rather than the usual way of using strings to build build the type. As using strings to represent these special data types frequently leads to correctness, performance, usability and security problems, allowing the directly usage of special syntax in a general purpose language will improve the behavior and the usability of a program.
\par
TSL allows users to define metadata with a parser to parse DSL literals in the host language with external syntax. As the external expressions with DSL literals are always associated with a type, the right parser defined in that type declaration will be used to parse the literals and then perform a transformation on the literals to generate inner Wyvern code. By pushing the parsing of delimited blocks of specialized syntax into the type checker, we guaranteed that these extensions could be composed arbitrarily without conflicts.
\par
The following example (Figure \ref{f-htmltype}) illustrates how to use TSL to construct a value of type HTML using HTML syntax.

\begin{figure}[ht!]
\begin{lstlisting}[style=wyvern]
type @\htmlcolor{HTML}@ = casetype 
  Empty of Unit
  Seq of HTML * HTML 
  Text of String
  BodyElement of Attributes * HTML
  PElement of Attributes * HTML
  StyleElement  of Attributes * CSS
  ... (* Other HTML cases *)
  metadata = new : HasTSL
    val parser = ~
      @\hastslcolor{...}@ (* HTML parser definition *)

val heading_text : String = "A Heading"
val x : HTML = ~
  @\htmlcolor{<body id="doc1">
    <h1><\{}@heading_text@\htmlcolor{\}></h1>
    <p>My first paragraph.</p>
  </body>}@
\end{lstlisting}
\mycaption{A Wyvern case type with an associated TSL. \todo{color TSLs and show splicing. Set vspace using tex setting.}}
\label{f-htmltype}
\end{figure}

In this example, we present the declaration of type \verb|HTML| as a Wyvern casetype with different HTML cases (StyleElement, Text etc). Along with the definition of different cases, a metadata of type \verb|HasParser| is defined with a parser to transform inserted DSL literals with HTML syntax. In line 13-17 of figure \ref{f-htmltype}, we construct a value \verb|x| of type \verb|HTML| using HTML syntax rather initialized all fields and methods one by one. The literals present inside the declaration body of type HTML body after a tilde (\verb|~|), and as the tilde indicates that the TSL body is the layout-delimited block beginning on the next line, the parser in the metadata of HTML will be invoked to parse them and then initialize the value \verb|x|.

Using TSL mechanism, DSL literals (HTML in this example) can be safely injected into Wyvern, and with its type-specific property, composing different DSL syntax in Wyvern can be easily achieved. 

Although TSL provides the mechanism to construct data using DSL syntax, TSL alone is not powerful enough enough due to its limits on: 
\begin{enumerate}\setlength{\itemsep}{0pt}
\item Only a single choice of syntax is available for any particular type.
\item This couldn't be used to handle the usage of external syntax on an existing value after its construction.
\item Only value construction is permitted with external syntax while type construction using external schema is not possible.
\end{enumerate}

In the following sections, we introduce an extensible keyword framework to deal with these problems mentioned before built atop of TSLs in Wyvern language. 

\section{Extensible keywords in Wyvern}
Several examples are presented in this section how the extensible keywords are used to solve these problems.
\subsection{Expression Keyword}
An expression keyword is a keyword associated with a parser to transform DSL literals into a Wyvern expression. Depending on whether a keyword provides the return type in its declaration, expression keywords are separated into two kinds, namely black-box keyword and white-box keyword (This terminology is borrowed from Scala's macro system). 

\paragraph{Black-box ``simpleHTML'' keyword}
We start with an example showing the usage of an expression keyword to construct an \verb|HTML| value using an expression keyword \verb|simpleHTML|, which provides an alternative syntax to construct the HTML value. The \verb|simpleHTML| syntax is an abbreviate representation of HTML using whitespace to close tags rather than explicit closing tags. The syntax is declared using a parser TSL in line 2-10 in figure \ref{f-simplehtml}.
\begin{figure}[ht]
\begin{lstlisting}[style=wyvern]
expkw @\simpleHTMLcolor{simpleHTML}@ : HTML = ~ (* : ExpParser *)
  @\expkwparsercolor{start <- '>body'= attributes> start>}@
    fn attrs, child => "@\expcolor{BodyElement((\$}@attrs@\expcolor{, \$}@child@\expcolor{))}@"
  @\expkwparsercolor{start <- '>p'= attributes> start>}@
    fn attrs, child => "@\expcolor{PElement((\$}@attrs@\expcolor{, \$}@ child@\expcolor{))}@"
  @\expkwparsercolor{start <- text}@
    fn text => "@\expcolor{Text(\$}@text@\expcolor{)}@"
  @\expkwparsercolor{start <- '<'= EXP>}@
    fn e => '@\expcolor{\$}@e'
val y : HTML = simpleHTML ~
  @\simpleHTMLcolor{>body[id="doc1"]}@
    @\simpleHTMLcolor{>h1 <\{}@heading_text@\simpleHTMLcolor{\}}@
    @\simpleHTMLcolor{>p My first paragraph}@
\end{lstlisting}
\mycaption{The `simpleHTML' keyword example.\todo{set uniform spacing for whole document}}
\label{f-simplehtml}
\end{figure}

Besides the definition of the parser for \verb|simpleHTML| syntax, the return type (\verb|HTML|) is also provided, which indicates that the DSL literals used in the body of the keyword invocation will elaborates to an expression of type \verb|HTML|. The invocation of the keyword is presented in line 11-14, including a call to the keyword \verb|simpleHTML|, and providing the DSL literals in the next indent level (colored brown). The variable \verb|heading_text| (colored black, in line 13), a Wyvern variable of type\verb|String| defined in line 10 of figure \ref{f-htmltype}, is inserted using curly braces to switch back to Wyvern.

The goal to support multiple external syntax for one type can be achieved using expression keywords.

\paragraph{White-box ``if'' keyword}
Differently, white-box keywords are defined without a return type. Here we use the key word \verb|if| as an example. The keyword \verb|if| is declared in the type \verb|Bool|, a casetype with two cases: \verb|True| and \verb|False|. As no return type is declared with \verb|if|, the return type should be provided when the keyword is used and the type checker will analyze the type against the provided type (Reversely, we can allow type synthesis on the expression after elaboration, but considering for stronger type preserving property, we only use type analysis for a white-box keyword, which will be discussed in Sec[\todo{Metadata Section}]). Using \verb|if| macro can simplify the required cases analysis process for a casetype.
\begin{figure}[ht]
\begin{lstlisting}[style=wyvern]
type Bool = casetype 
  True
  False
  expkw @\boolIfcolor{if}@ = fn self (* : Exp *) => ~ (* : ExpParser *)
    @\expkwparsercolor{EXP BOUNDARY `else' BOUNDARY EXP}@
      fn e1 (* : Exp *), e2 (* : Exp *) => ~ (* : Exp *)
        @\expcolor{case \$}@self
          @\expcolor{True => \$}@e1
          @\expcolor{False => \$}@e2
def f(x : Bool) : T
  x.if {branch_1} @\boolIfcolor{else}@ {branch_2}
\end{lstlisting}
\mycaption{The black-box keyword `if' example\todo{color quotations}}
\label{if-example}
\end{figure}

The syntax for the body of \verb|if| is defined on line 5: an expression followed by an identifier \verb|else| and then another expression. Here we use the parsing mechanism in TSL to support multi-part body parsing: any delimited forms appeared next to each other or delimited by a keyword. (Different delimited forms can be referred to figure \ref{f-delimited}) The parser will identify the delimited form and insert a \verb|BOUNDRY| between different delimited forms and the keywords. 

The usage of the keyword is presented in line 11: the variable \verb|x| (of type \verb|Bool|) call the variable, followed by the keyword body. Wyvern type checker will identify the parser to parse the literals by checking the keyword definition in type $\verb|Bool|$, and the return type will be checked against $\verb|T|$, provided in the function definition.  

The keyword is associated with the type \verb|Bool|, so it can be invoked by a value of type \verb|Bool|, which permits operations on value after initialization. 
\begin{figure}[ht!]
\begin{lstlisting}[style=wyvern]
type @\expkwparsercolor{ExpParser}@ = objtype
  def parse(ps : ParseStream) : Result(Exp)
  metadata : HasTSL = new 
    val parser = (* parser generator *)

type @\expcolor{Exp}@ = casetype
  Var of ID
  Lam of ID * Exp
  Ap of Exp * Exp
  (* ... *)
  metadata : HasTSL = new
    val parser = (* exp quasiquotes *)

type Result(T) = casetype
  OK of T * ParseStream
  Error of String * Location
\end{lstlisting}
\label{exp-prelude}
\mycaption{Wyvern prelude for expression keywords extension}
\end{figure}

\subsection{Type Keyword}
\todo{Not confident in this introduction paragraph.}Besides using expression keywords and TSLs to extend the host language with new syntax in expressions, constructing a type with external syntax can be useful in object-relational mapping (ORM). Declaring a type and defining a value requires much repetitive works to define fields and methods based on the data schema, and constructing a type and generating a metadata using data schema for a type can be easier. The following example shows how we construct a type using database schema.

\begin{figure}
\begin{lstlisting}[style=wyvern]
type @\dbcolor{EmployeesDB}@ = DBSchema ~
  @\dbshcemacolor{*ID   int}@
  @\dbshcemacolor{Name  varchar}@

val db : EmployeeDB = ~
  @\dbcolor{connect to}@ ~
    @\urlcolor{mysql://localhost:3306}@
  @\dbcolor{username: }@"user1"
  @\dbcolor{password: }@"001"
  @\dbcolor{table: Employees}@
\end{lstlisting}
\mycaption{The usage of the type keyword ``DBTable''}
\label{f-tykwexample}
\end{figure}

\begin{figure}[ht]
\begin{lstlisting}[style=wyvern]
type EmployeesDB = objtype
  type Entry = objtype
    val ID : Int
    val Name : String 
  val connection : URL
  val username : String
  val password : String
  ...
  def getById (x:Int) : Option(Entry)
  def getByName (x : String) : List(Entry)
  metadata = new : HasTSL
    val parser = ~
      ... (* TSL parser generated by type constructor *)

val db : EmployeesDB = new
  val connection = new
    val domain = "localhost"
    ...
  val username = "user1"
  val password = "001"
  ... (* Other fields *)
  def getByID(x:Int) : List(Entry)
    ...
\end{lstlisting}
\mycaption{An alternative version without using type keyword}
\label{typekw-example-2}
\end{figure}

\begin{figure}[ht]
\begin{lstlisting}[style=wyvern]
typekw @\dbshcemacolor{DBSchema}@ with metadata:HasTSL = ~ (*:TypeParser*)
  @\typekwparsercolor{start <- pairs}@
    fn pairs =>
      let ty : Type = ~
        @\typecolor{objtype}@
          @\typecolor{type Entry = objtype}@
            @\typecolor{\{}@map(pairs, Nil, 
              fn ((p, lbl, ty), l) => Cons(~, l))
                @\membercolor{val \$}@lbl @\membercolor{:  \$}@ty
            @\typecolor{\}}@
          @\typecolor{val connection : URL}@
          @\typecolor{val username : String}@
          @\typecolor{val password : String}@
          @\typecolor{...}@
          @\typecolor{\{}@map(pairs, Nil, 
            (fn ((p, lbl, ty), l) => Cons(~, l)))
              @\membercolor{def getBy\$}@lbl @\membercolor{(\$}@ty@\membercolor{)}@
          @\typecolor{\}}@
      let md : HasTSL = new 
        val parser = ~
          @\hastslcolor{start <- ("connect to "= EXP>}@
                    @\hastslcolor{"username:"= EXP>}@
                    @\hastslcolor{"password:"= EXP>}@
                    @\hastslcolor{"table:" EXP>)}@
            fn url, un, pw, table => ~
              @\expcolor{new}@ 
                @\expcolor{val connection = \$}@url
                @\expcolor{val username = \$}@un
                @\expcolor{val password = \$}@pw
                @\expcolor{...}@
                @\expcolor{\{}@map(pairs, Nil, 
                  (fn ((p, lbl, ty), l) => Cons(~, l)))
                    @\membercolor{def getBy}@$lbl @\membercolor{(x)}@ 
                      @\membercolor{...}@(* implementation *)
                @\expcolor{\}}@
      (ty, md, Nil)
  @\typekwparsercolor{pairs <- ()}@
    fn () => Nil 
  @\typekwparsercolor{pairs <- pair= pairs=}@
    fn hd, tl => Cons(hd, tl)
  @\typekwparsercolor{pair <- "*"? ID ID}@
    fn is_primary, colid, tyid => (
      is_primary, colid, ty_from_sqlty(tyid))
\end{lstlisting}
\mycaption{The declaration the type keyword ``DBTable''}
\label{typekw-example-1}
\end{figure}
We present an example in figure \ref{f-tykwexample}: constructing the type \verb|EmployeeDB| using the type keyword \verb|DBSchema|. By defining the type \verb|EmployeeDB| using a type keyword, \verb|EmployeeDB| will be provided with:
\begin{enumerate}\setlength{\itemsep}{0pt}
\item Fields and methods declarations based on the data schema. (e.g. \verb|employee|, \verb|getByName|)
\item Common fields and method declarations not depends on the schema. (e.g. \verb|connection| and \verb|stmts| and provided for whatever schema is provided.)
\item A TSL metadata for value initialization using external syntax. 
\end{enumerate}

Line 1-3 in figure \ref{f-tykwexample} shows the declaration of type \verb|EmployeeDB| using employee schema. And a value \verb|db| (line 5-10) is defined using the syntax which is defined in the generated TSL metadata. 

The elaborated version of type \verb|Employee| and the value \verb|db| is presented in figure \ref{typekw-example-2}: a type member \verb|Entry| is declared in the type to represent a data table entry, and methods like \verb|getById| is generated as methods to access the database. The elaborated value \verb|db| (line 15) will be an initialized value with fields and methods declared.

The definition of the type keyword \verb|DBSchema| can be referred to figure \ref{typekw-example-1}. A type keyword is a value of type \verb|TypeParser|, which takes in a parsestream and returns a parsing result (of type \verb|Result|, which is a casetype defined in figure \ref{exp-prelude}). When there is no parsing error, a tuple \verb|(t:Type, e:Exp, k:List(KwMember))| will be returned for type construction: the type structure provided by \verb|t|, metadata indicated by \verb|e|, and expression keywords defined by \verb|k|. \verb|DBSchema| will construct an object type (line 5-18), and provide a TSL metadata for value initialization (line 20-35). The type of the metadata is provided on the first line of keyword declaration with keyword \verb|with metadata|, which will be used to check against the metadata type during type checking.

\begin{figure}
\begin{lstlisting}[style=wyvern]
type @\typekwparsercolor{TypeParser}@ = objtype
  def parse(ps : ParseStream) : Result(Type * Exp * List(KwMember))
  metadata : HasTSL = new 
    val parser = (* parser generator *)

type @\typecolor{Type}@ = casetype
  Named of ID
  Objtype of List(MemberDecl)
  Casetype of List(CaseDecl)
  Arrow of Type * Type
  metadata : HasTSL = new
    val parser = (* type quasiquotes *)

type KwMember = casetype
  Whitebox of Label * ExpKw
  Blackbox of Label * ExpKw * Type
\end{lstlisting}
\mycaption{Wyvern prelude for type keywords}
\end{figure}



\section{Syntax}
We start our formal presentation by introducing the abstract syntax built upon pure functional Wyvern together their concrete forms. For simplicity consideration, we omit some of the syntax not directly related to composable syntax macros, which can be referred to \todo{TSL paper}.

A Wyvern program ($\rho$) is consisted of three parts: type-keyword declarations ($\eta$), named-type declarations ($\theta$) and an expression ($e$).

\begin{figure}[ht]
\begin{tabular}{ l l l l l }
 \multicolumn{1}{l}{\textbf{Abstract Forms}} & \multicolumn{1}{l}{\textbf{Concrete Forms}}\\
 \multicolumn{3}{l}{Programs}\\
$\rho$~::=~$\eta;\theta;e$\\
\multicolumn{3}{l}{Type Keywords}\\
$\eta$~::=~$\emptyset$\\
\tabularspace$\eta;k[e,\tau]$ & \textcd{typekw} $k$ \textcd{with metadata:}$\tau$ \textcd{=} $e$ \\
\multicolumn{3}{l}{Expression Keywords}\\
$\kappa$~::=~$\emptyset$                        & \\
\tabularspace$\kappa;k[\mathbf{bk}(\tau),e]$    & \textcd{expkw} $k$ : $\tau$ \textcd{=} $e$\\
\tabularspace$\kappa;k[\mathbf{wk},e]$          & \textcd{expkw} $k$ \textcd{=} $e$\\
\multicolumn{3}{l}{Type Declarations}\\
$\theta$~::=~$\emptyset$                        & \\
\tabularspace$\theta; T[\mathbf{explicit},\tau, e, \kappa]$  & \textcd{type} $T$ \textcd{=} $\tau$\\
&~~~\textcd{metadata = }$e$\\
&~~~$\kappa$\\
\tabularspace$\theta; T[\mathbf{tykw},k, body, e, \kappa]$   & \textcd{type} $T$ \textcd{=} $k$ $delims$\\
                                                          & ~~~\textcd{metadata = }$e$\\
                                                          & ~~~$\kappa$\\
\multicolumn{3}{l}{Types}\\
$\tau$~::=~$\mathbf{named}[T]$              & $T$\\
\tabularspace$\mathbf{objtype}[\omega]$       & \textcd{objtype} $\omega$ \\
\tabularspace$\mathbf{casetype}[\chi]$        & \textcd{casetype} $\chi$\\
\tabularspace$\mathbf{arrow}[\tau, \tau]$     & $\tau$ \textcd{->} $\tau$\\
\multicolumn{3}{l}{Object Fields}\\       
$\omega$~::=~$\emptyset$                      \\
\tabularspace$l[\mathbf{val},\tau];\omega$                 & \textcd{val} $l$ : $\tau$\\
\tabularspace$l[\mathbf{def},\tau];\omega$                 & \textcd{def} $l$ : $\tau$\\
\multicolumn{3}{l}{Casetype Cases}\\
$\chi$~::=~$\emptyset$                      \\                 
\tabularspace$C[\tau];\chi$                   & $C$~\textcd{of}~$\tau$\\
\multicolumn{3}{l}{External Term}\\
 $e$~::=~...                              & \\
\tabularspace$\mathbf{lit}[body]$             & $delims$\\
\tabularspace$\mathbf{ekey}[k,body](e)$       & $e.k$ $delims$\\
\multicolumn{3}{l}{Translational Terms}\\
$\hat{e}$~::=~...                              & \\
\tabularspace$\mathbf{spliced}[e]$            & \\
\multicolumn{3}{l}{Internal Terms}\\
$i$~::=~...                                                     
\end{tabular}
\mycaption{Abstract and Concrete Forms \todo{remove duplicate metavariable columns, separate out delimited into new concrete metavariable, add sequential delimited forms}}
\label{formal-syntax}
\end{figure}

\begin{figure}[ht]
\begin{lstlisting}[style=tempwyvern]
{literals here, {inner braces} must be balanced}
[literals here, [inner brackets] must be balanced]
'literals here, 'inner brackets' must be balanced'
<literals here, <inner brackets> must be balanced>
~
  literals here, one more indent level beneath the tilde
\end{lstlisting}
\mycaption{Different kind of delimited forms used in Wyvern, including 4 inline delimited forms and one multiline example using tiled(line 5-6)}
\label{f-delimited}
\end{figure}

\paragraph{Type-keyword Declaration}
Users define type keywords in the type-keyword declaration section ($\eta$). The declaration of a keyword includes an expression $e$ and a metadata type $\tau$. The expression $e$ is the parser to parse the DSL literals used in a type keyword invocation, and the type $\tau$ is the type of the metadata which will be generated by the parser. The type keyword declaration is supposed to belong to a module, but as module is not defined in our language formal, it is presented at the top level of the program.

\paragraph{Named type declaration}
Named type declarations is the declaration of types associated with their names, and according to the way to declare, there are two kinds of type declarations: an explicit type declaration with their structure and metadata directly specified, or a type keyword based declaration, whose structure, metadata and keywords are defined using a type keyword.

An explicit type declaration ($T[\mathbf{explicit}, \tau,e,\kappa]$) consists of four parts: $T$ as the type name, $\tau$ as the structure of the type, (which can be one of $\mathbf{objtype}$, $\mathbf{casetype}$, $\mathbf{arrowtype}$ or a copy of named type $\mathbf{named}[T']$),  $e$ as the metadata associated with the type and $\kappa$ as the expression keywords associated with the type. 

The second kind ($T[\mathbf{tykw},k,body,e,\kappa]$) is a type declared using a type keyword $k$, with DSL literals specified by $body$. Metadata ($e$) and expression keywords ($\kappa$) can be defined as an extension of metadata and keywords generated by the type keyword $k$, the details for this extension mechanism will be presented in the next section.

\paragraph{External Expressions}
Our extensions on external terms to support syntax macros including a keyword invocation expression ($\mathbf{ekey}[k,body](e)$) and several expression for parser access at run-time (omitted here, can be referred to \todo{TR}). The keyword invocation expression includes the following parts: an expression $e$, a keyword $k$ and the delimited DSL literals $body$.

Note that there is no extension on the translational expressions and inner expressions, as keywords invocation and parser access will be transformed to inner Wyvern expressions and no DSL literals will exist after elaboration.

\section{Bidirectional Typechecking and Elaboration}
As syntax macros consists of DSL literals, it is necessary to transform them into inner Wyvern expressions during compile time. Bidirectional typechecking is used here as type can be clearly specified as input or output during typechecking process. In conventional type systems, a type judgment is written as $\Gamma\vdash_{\Theta} e:\tau$, where $\Gamma$ is the typing context, $\Theta$ is the declaration environment, and $e:\tau$ specifies that the expression is of type $\tau$. But with a bidirectional type system, a type judgment is written as $\Gamma\vdash_{\Theta} e\Leftarrow(\Rightarrow)\tau$, which specifies the type $\tau$ is used as input(output) of the checking process, which is important in distinguishing the black-box keyword from while-box keyword.
\par
The type checking process also involves the elaboration of an external expression, written as $\Gamma\vdash_{\Theta} e\rightsquigarrow i \Leftarrow(\Rightarrow) \tau$. It indicates that an external expression will be elaborates to an inner expression and synthesis to (or analysis against) the type $\tau$. The arrow ($\rightsquigarrow$) is used to represent the elaboration process, including literal elimination and hygiene process, which is part of the type checking rules.

\subsection{Declaration Environments}
The type declaration environments (figure \ref{typechecking-environment}) involves the declaration of type keywords and named types. The declarations appeared in the Wyvern program will be parsed and checked before going to the environment, and the type checking rules for environment is presented in figure \ref{typechecking-elaboration} \todo{modify the number}. 

Type keyword environment ($\Delta$) is used to store all type keywords declaration, and it will be used to look up a type keyword during type checking process.

In the type environment, external terms are replaced by the inner Wyvern expression they elaborates to, and a type declared with type keyword goes into the environment with its structure presented as a normal type with optional metadata and expression keywords. The environment formalization an be referred to figure \ref{typechecking-environment}.

\begin{figure}[ht]
\begin{center}
\begin{tabular}{r r c l}
Type Keyword Context & $\Delta$ & ::= & $\emptyset$\\
              &                 &  |  & $\Delta;k[i,\tau]$\\
Named Type Context  & $\Theta$        & ::= & $\emptyset$\\
              &                 &  |  & $\Theta,T[\delta,\mu,\zeta]$\\
              & $\delta$        & ::= & $?$ ~ | ~ $\tau$\\
   & $\mu$           & ::= & $?$ ~ | ~ $i:\tau$\\
   & $\zeta$         & ::= & $?$ ~ | ~ $\dot\kappa$\\
Keyword Members & $\dot\kappa$    & ::= & $\emptyset$\\
            &                 &   |  & $\dot\kappa;k[\mathbf{bk}(\tau),i]$\\
            &                 &   |  & $\dot\kappa;k[\mathbf{wk},i]$\\
Typing Context & $\Gamma$ &   ::=  & $\emptyset$\\
                 &          &     |  & $\Gamma,x:\tau$
\end{tabular}
\end{center}
\mycaption{Definition of environment, including a set for type keywords ($\Delta$) and a named type environment ($\Theta$). The type keyword environment is a set containing keywords ($k$) and their parser (an inner Wyvern expression $i$), while the named type environment consists of type declarations with its type structure($\delta$), metadata expression ($i:\tau$) and keywords set($\zeta$, expression keywords after elaboration). The question mark here indicates that these fields can be of a value `unknown' during type checking process.b}
\label{typechecking-environment}
\end{figure}

To support mutually recursive type declaration, we split the checking rules for type declarations into three steps: 1) Add the type name into the type environment. 2) Add the type structure into the environment. 3) Check the type extensions (i.e. TSL or expression keywords) and add them into the environment. A type can refer to another one in the field or type extensions. But the extension in a type cannot refer to that from a type defined after it, as using extension syntax recursively can make the program too complicated.

For a normal named type declaration, we have rules type-name, type-defs, type-exts to add the type into the environment. The rule type-name will check that the name has not yet appeared in the previous environment to avoid conflicts while the rule type-defs checks the formation of the type structure, i.e. whether fields in a objtype or cases in a casetype is well formed. And the last rule type-exts will add the metadata and the expression keywords declaration into the environment, where the external representation of the metadata ($e_m$) will be transformed into a inner Wyvern expression of type $\tau_m$ ($i_m:\tau_m$) and the keywords declaration ($\kappa$) will be transformed to $\dot\kappa$. 

In the transformation of $\kappa\rightsquigarrow\dot\kappa$, two rules exists to deal with both black-box keywords and white-box keywords. Both of the two rules will check there is no name conflicts in a type keyword. And the parser expression ($e_k$) should elaborates to an Wyvern expression ($i_m$) and checks against $TypeKw$, which is a standard type saved in the prelude environment for the keyword parser type. The difference between black-box and white-box keywords lies in the fact that a return type is presented in the declaration of a black-box keyword while a white-box one doesn't.

The type environment $\Theta$ is finished once $\Theta_{names}, \Theta_{defs}$ and $\Theta_{exts}$ are processed.
\subsection{External Type Literals}
In the type environment, there is no difference between the two types of type declaration mentioned in the syntax as all types defined using type keywords elaborates to a type with concrete structure during type checking process.

The type checking rules for type keywords usage is labeled as type-name-2, type-defs-2 and type-exts-2. The rule type-name-2 simply adds the type name into the environment for other types to refer to.

The rule type-name-2 present the type elaboration process, and the external syntax used in type keyword will be transformed to a normalized type structure. The process consists of the following steps:
\begin{enumerate}\setlength{\itemsep}{0pt}
\item Check if the environment prelude is in the type environment. The prelude environment consists of necessary types and parser definition. 
\item Look up the keyword in $\Delta$. This requires a valid parser defined in the type keyword environment for parsing the literals later.
\item Invoke the parser to parse the DSL literal body ($i_{ps}$, as an expression the parser parsed to). In the rule kw-env, the parser is already checked against type $TypeKw$, so the parser is of type $PasrseStream->DeclResult$. So a return type ($i_{type}$) and an type metadata ($i_{exp}$) will be provided by the parser.
\item The type expression ($i_{type}$) will be transformed to a Wyvern type structure (i.e. objtype or casetype) using type dereification rules (marked as `$\uparrow$'). And the type will be checked to guarantee the formation of its structure.
\item The metadata expression will be reconstructed, it will be reificate to a spliced expression and then transform to an inner Wyvern expression of type $\tau_m$. 
\end{enumerate} 
After these steps, the type structure as well as the TSL metadata associated with the type is generated, and no more external type syntax exists.

The rule type-exts-2 stands for the rule to resolve the metadata conflict between the metadata generated by type keyword ($i_m$) and that defined in the named type declaration ($i_w$). In the rule type-exts for normal named type declaration, the metadata will be directly added into the environment, but in this case, we require $i_w$ to be a metadata resolver: it should be a function of type $\tau_m\rightarrow\tau'_m$, as it will take in $i_m$ and return a modified metadata $i'_m$ ($\mathbf{iap}(i_w, i_m)\Downarrow i'_m$ presents the process). The expression keywords part is the same as that in a normal named type declaration.
\input{kw-elaboration.tex}

\subsection{Expression Keywords Literals}
Besides type keywords and TSLs, another usage of the DSL literals is in expression keywords. The different rules to process keywords invocation includes three situations: Using DSL literals in a black-box keyword, using DSL literals in a white-box keyword with type analysis and using DSL literals in a white-box keyword with type synthesis. Their difference only lies in the inference of the return type so we only explain the rule using the rule T-wk-syn. Processing literals in an expression keyword invocation includes the following steps:
\begin{enumerate}\setlength{\itemsep}{0pt}
\item Check that the prelude environment $\Theta_0$ is in the current environment. 
\item The target term ($e_0$) elaborates into an inner Wyvern term ($i_0:T$), and then check that the type $T$ is declared in the type environment with an keyword environment $\dot\kappa$ inside it.
\item Look up the expression keyword inside the keyword declarations, as checked in the rule expkw-bk and expkw-wk, the parser should be of type $ExprKw$ (The parser type for expression keyword presented in Wyvern prelude).
\item Transform the target expression into an reified elaboration form ($i_0\downarrow i'_0$), this will transform the target expression into an \verb|Exp| expression, which will be used in the parsing process of literal elaboration.
\item The parser takes in two expressions: the reified target expression and the parsestream of the literals, then generate an expression of type $Result$, which will be used to build the return expression.
\item The expression is dereified into an translational term of $\hat{e}$, which is used to mirror an external term but transform the representation of DSL literals into $\mathbf{spliced}[e]$, as a middle representation before elaborates to an external term.
\item The last step is type checking. It checks the term $i$ which will synthesize to type $\tau$ (For black-box keyword or white-box under analysis, it will be replaced by a type analysis against $\tau$). The expression the keyword invocation elaborates to should be the expression $i$ of type $\tau$, which is an inner Wyvern term used to compile and execute at run time. 
\end{enumerate}
\input{kw-statics.tex}

\subsection{Hygiene}
\todo{Do we need to do it here?}

\subsection{Metatheory}
\paragraph{Reification and Dereification}
For each type and expression, we have the following properties to support converting a type to an expression of type \textbf{named}[$Type$] and an expression to an expression of type \textbf{named}[$Exp$] (Property 1, 2). And reversely, converting an inner term to an Wyvern expression $i$ of type $\mathbf{named}[Exp]$ (Property 3). These properties are used to construct a type $\tau$ or an expression $\hat{e}$ from parsing results (an expression of type $Exp$ or $Type$) in the elaboration rule. 
\begin{property}If $\emptyset\vdash_{\Theta} i:\mathbf{named}[Type]$ then there exists a corresponding $\tau$ s.t. $i\uparrow\tau$. 
\end{property}
\begin{property}
If $\emptyset\vdash_{\Theta} i:\mathbf{named}[Exp]$ then there exists an translational term $\hat{e}$, s.t. $i\uparrow\hat{e}$.
\end{property}

\begin{property}
For any $i$, these exists an inner term $i'$, s.t. $i\downarrow i'$ and $\emptyset\vdash_{\Theta_0} i':\mathbf{named}[Exp]$.
\end{property}
The rules for these properties can be referred to \todo{TR}.

\paragraph{Type Safety and Preservation}
Extension of the TSL Wyvern semantics with keywords mechanism still constitutes a type safe language. We will outline the key theorems and lemmas here presenting the properties a type safe language has: 1) internal type safety 2) type preservation. 

To formalize the type safety property, we defined the judgments for context formation, type formation and bidirectional typing judgment. \todo{Refer to TSL as well as TR}

\begin{theorem}[Internal Type Safety]
If ~$\vdash_{\Theta_0}\Delta$, $\vdash_{\Theta_0}\Theta$~ and $\emptyset\vdash_{\Theta}i\Leftarrow\tau$ or $\vdash_{\Theta}i\Rightarrow\tau$, then either $i~\texttt{val}$ or $i\mapsto i'$ such that $\emptyset\vdash_{\Theta}i'\Leftarrow\tau$.
\end{theorem}
\begin{proof}
As the keyword extension on TSL framework does not extend inner Wyvern expressions, the proof for this theorem is directly from TSL proof. 
\end{proof}

\begin{theorem}[External Type Preservation]
If ~$\vdash_{\Theta_0}\Delta$, $\vdash_{\Theta_0}\Theta$, $\vdash_{\Theta}\Gamma$, and $\Gamma\myvdash e\rightsquigarrow i\Leftarrow\tau$ or $\Gamma\myvdash e\rightsquigarrow i\Rightarrow\tau$ then $\Gamma\myvdash i\Leftarrow\tau$.
\end{theorem}
\begin{proof}
Based on TSL proof of the external type preservation, we need to proof the following cases on keywords extension (Expressions for parser access is presented in the \todo{TR}, thus the corresponding proofs of the case for the expression is omitted here. ):
\begin{itemize}
\item $e=\mathbf{ekey}[k,body](e)$. According to the rule T-bk and T-wk, $\Gamma\vdash_{\Theta}\mathbf{ekey}[k,body](e_0) \rightsquigarrow i \Rightarrow \tau \Longrightarrow \Gamma;\emptyset\myvdash \hat{e} \rightsquigarrow i \Rightarrow \tau$. According to Lemma 1, $\Gamma;\emptyset\myvdash \hat{e} \rightsquigarrow i \Rightarrow \tau \Longrightarrow \Gamma;\emptyset\vdash_{\Theta} i\Rightarrow\tau$.
\end{itemize}
\end{proof}

\begin{lemma}[Translational Type Preservation]
If \\$\vdash_{\Theta_0}\Theta$, $\vdash_{\Theta_0}\Delta$ and $\vdash_{\Theta}\Gamma_{out}$ and $\vdash_{\Theta}\Gamma$ and $dom(\Gamma_{out})\cap dom(\Gamma)=\emptyset$ and $\Gamma_{out};\Gamma\vdash_{\Theta}^{\Delta}\hat{e}\rightsquigarrow i\Leftarrow\tau$ or $\Gamma_{out};\Gamma\vdash_{\Theta}^{\Delta}\hat{e}\rightsquigarrow i\Rightarrow \tau$ then $\Gamma_{out}\Gamma\vdash_{\Theta}i\Leftarrow \tau$.
\end{lemma}


\begin{theorem}[Compilation]
If ~$\rho\sim\Theta\rightsquigarrow i:\tau$~ then $\vdash_{\Theta_0}\Delta$,\ $\vdash_{\Theta_0}\Theta$ and $\emptyset\vdash_{\Theta} i\Leftarrow\tau$.
\end{theorem}
\begin{proof}
This theorem can be proved with the following two lemmas for the formation of $\Delta$ and $\Theta$.
\end{proof}

\begin{lemma}[Type Keyword Declaration] 
If $\vdash_{\Theta_0}\eta\sim\Delta$, then $\vdash_{\Theta_0}\Delta$.
\end{lemma}
\begin{proof}
The proof is simple a induction on $\vdash_{\Theta_0}\Delta$ and using the External Type Preservation Theorem. (Not shown)
\end{proof}

\begin{lemma}[Type Declaration]
If $\vdash_{\Theta_0}^{\Delta}\theta\sim\Theta$ then $\vdash\Theta_0\Theta$.
\end{lemma}
\begin{proof}
By induction on the formation of $\Theta$, we have the following three cases:
\begin{itemize}
\item $\vdash_{\Theta}\emptyset\sim\emptyset \Longrightarrow \vdash{\emptyset}$.
\item ${\vdash^{\Delta}_{\Theta}} \theta';T[\mathbf{explicit},\tau,e_m,\kappa] \sim \Theta',T[\tau,i_m:\tau_m,\dot\kappa] \Longrightarrow \vdash_{\Theta}\Theta',T[\tau,i_m:\tau_m,\dot{\kappa}]$. 

By induction, we have $\vdash_{\Theta}\Theta'$. And by the rule (ctx-explicit-type), we have $\vdash_{\Theta\Theta',T[?,?,?]}^{\Delta}\tau, \myvdash\dot\kappa$ and $\emptyset\vdash_{\Theta\Theta',T[\tau,?,?]}^{\Delta}e\rightsquigarrow i_m\Rightarrow\tau_m$. With External Type Preservation Lemma, we have $\vdash_{\Theta}\Theta',T[\tau,i_m:\tau_m,\dot{\kappa}]$.
\item $\myvdash \theta';T[\mathbf{tykw},k,body,e_m,\kappa] \sim \Theta',T[\tau,i''_m:\tau'_m,\dot{\kappa}\dot{\kappa}'] \Longrightarrow \vdash_{\Theta}\Theta',T[\tau,i''_m:\tau'_m,\dot{\kappa}\dot{\kappa}'].$

By induction, we have $\myvdash\Theta'$. And by rule (ctx-typekw-type), we have (1) $\vdash_{\Theta\Theta',T[?,?,?]}^{\Delta}\tau$. (2).$\dot\kappa\dot\kappa'$ is well formed the the fact that $\myvdash \dot\kappa$~~~~ $\vdash^{\Delta}_{\Theta\Theta',T[\tau,i'_m:\tau'_m,?]}\kappa\rightsquigarrow\dot{\kappa}'$ ~~~~ $dom(\dot{\kappa})\cap dom(\dot{\kappa}')=\emptyset$. (3) $i''_m:\tau'_m$ is well formed by the formation of $i'_m$ and the application of $i'_m$ on $i_m$. Thus we have the formation of the \textbf{tykw} construction.
\end{itemize}
With the three cases proved, we have the formation of type declaration proved.
\end{proof}

%\input{kw-contextformation.tex}

% end the environment with {table*}, NOTE not {table}!

\section{Conclusions}
This paragraph will end the body of this sample document.
Remember that you might still have Acknowledgments or
Appendices; brief samples of these
follow.  There is still the Bibliography to deal with; and
we will make a disclaimer about that here: with the exception
of the reference to the \LaTeX\ book, the citations in
this paper are to articles which have nothing to
do with the present subject and are used as
examples only.
%\end{document}  % This is where a 'short' article might terminate

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
This section is optional; it is a location for you
to acknowledge grants, funding, editing assistance and
what have you.  In the present case, for example, the
authors would like to thank Gerald Murray of ACM for
his help in codifying this \textit{Author's Guide}
and the \textbf{.cls} and \textbf{.tex} files that it describes.

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{../ecoop14/research}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
\end{document}