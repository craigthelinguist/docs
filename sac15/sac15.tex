\documentclass{sig-alternate}
  \pdfpagewidth=8.5truein
  \pdfpageheight=11truein

\usepackage{epstopdf}
\usepackage{bussproofs}
\usepackage[usenames,dvipsnames]{color} % Required for specifying custom colors and referring to colors by name
\usepackage{listings}
\usepackage{xcolor}
\usepackage{verbatim}
\usepackage{multirow}
\usepackage{array}
\usepackage{parcolumns}
\EnableBpAbbreviations
\input{macros.tex}

\newcommand\BeraMonottfamily{%
  \def\fvm@Scale{0.85}% scales the font down
  \fontfamily{fvm}\selectfont% selects the Bera Mono font
}

\lstdefinestyle{wyvern}{
%backgroundcolor=\color{highlight}, % Set the background color for the snippet - useful for highlighting
basicstyle=\scriptsize\BeraMonottfamily, % The default font size and style of the code
breakatwhitespace=false, % If true, only allows line breaks at white space
breaklines=true, % Automatic line breaking (prevents code from protruding outside the box)
captionpos=b, % Sets the caption position: b for bottom; t for top
morecomment=[s]{(*}{*)},
commentstyle=\fontshape{it}\color{Gray}\selectfont, % Style of comments within the code - dark green courier font
deletekeywords={}, % If you want to delete any keywords from the current language separate them by commas
%escapeinside={\%}, % This allows you to escape to LaTeX using the character in the bracket
firstnumber=1, % Line numbers begin at line 1
frame=lines, % Frame around the code box, value can be: none, leftline, topline, bottomline, lines, single, shadowbox
frameround=tttt, % Rounds the corners of the frame for the top left, top right, bottom left and bottom right positions
keywords=[1]{new, objtype, type, casetype, val, def, metadata, syntax, of, fn, with, let},
keywordstyle={[1]\bfseries},
keywordstyle={[3]\color{red!80!orange}},
morekeywords={}, % Add any functions no included by default here separated by commas
numbers=left, % Location of line numbers, can take the values of: none, left, right
numbersep=8pt, % Distance of line numbers from the code box
numberstyle=\tiny\color{Gray}, % Style used for line numbers
rulecolor=\color{black}, % Frame border color
showstringspaces=false, % Don't put marks in string spaces
showtabs=false, % Display tabs in the code as lines
stepnumber=1, % The step distance between line numbers, i.e. how often will lines be numbered
tabsize=4, % Number of spaces per tab in the code
}

\lstdefinestyle{tempwyvern}{
basicstyle=\scriptsize\BeraMonottfamily, % The default font size and style of the code
breakatwhitespace=false, % If true, only allows line breaks at white space
breaklines=true, % Automatic line breaking (prevents code from protruding outside the box)
captionpos=b, % Sets the caption position: b for bottom; t for top
morecomment=[s]{(*}{*)},
commentstyle=\fontshape{it}\color{Gray}\selectfont, % Style of comments within the code - dark green courier font
deletekeywords={}, % If you want to delete any keywords from the current language separate them by commas
%escapeinside={\%}, % This allows you to escape to LaTeX using the character in the bracket
firstnumber=1, % Line numbers begin at line 1
frame=lines, % Frame around the code box, value can be: none, leftline, topline, bottomline, lines, single, shadowbox
frameround=tttt, % Rounds the corners of the frame for the top left, top right, bottom left and bottom right positions
keywords=[1]{new, objtype, type, casetype, val, def, metadata, expkw, of, fn, with, typekw, let},
keywordstyle={[1]\bfseries},
keywordstyle={[3]\color{red!80!orange}},
morekeywords={}, % Add any functions no included by default here separated by commas
numbers=left, % Location of line numbers, can take the values of: none, left, right
numbersep=8pt, % Distance of line numbers from the code box
numberstyle=\tiny\color{Gray}, % Style used for line numbers
rulecolor=\color{black}, % Frame border color
showstringspaces=false, % Don't put marks in string spaces
showtabs=false, % Display tabs in the code as lines
tabsize=4, % Number of spaces per tab in the code
}
\lstset{basicstyle=\footnotesize,breaklines=true}
\lstset{escapeinside={@}{@}}
\newcommand{\htmlcolor}[1]{\textcolor[HTML]{339933}{#1}}
\newcommand{\expkwparsercolor}[1]{\textcolor[HTML]{336699}{#1}}
\newcommand{\typekwparsercolor}[1]{\textcolor[HTML]{7C803E}{#1}}
\newcommand{\urlcolor}[1]{\textcolor[HTML]{FFCC33}{#1}}
\newcommand{\expcolor}[1]{\textcolor[HTML]{FF0033}{#1}}
\newcommand{\membercolor}[1]{\textcolor[HTML]{FF6600}{#1}}
\newcommand{\typecolor}[1]{\textcolor[HTML]{660066}{#1}}
\newcommand{\dbcolor}[1]{\textcolor[HTML]{FF47FF}{#1}}
\newcommand{\hastslcolor}[1]{\textcolor[HTML]{002FC9}{#1}}
\newcommand{\simpleHTMLcolor}[1]{\textcolor[HTML]{7D5100}{#1}}
\newcommand{\boolIfcolor}[1]{\textcolor[HTML]{5E0C0C}{#1}}
\newcommand{\dbshcemacolor}[1]{\textcolor[HTML]{5AC3D1}{#1}}

\newcommand{\flyingbox}[1]{\begin{flushleft}\fbox{{#1}}\end{flushleft}}
\newcommand{\myvdash}{\vdash_{\Theta}^{\Delta}}
\newcommand{\textcd}[1]{\textbf{\scriptsize\BeraMonottfamily{#1}}}
\newcommand{\textsp}[1]{\text{\footnotesize\BeraMonottfamily{#1}}}
\newcommand{\mycaption}[1]{\vspace{-4px}\caption{#1}\vspace{-2px}}
\newcommand{\tabularspace}{~~~~~~}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{property}{Property}

\begin{document}

%
% --- Author Metadata here ---
\conferenceinfo{XXX}{XXX}
\CopyrightYear{XXXX} % Allows default copyright year (2002) to be over-ridden - IF NEED BE.
\crdata{X-XXXXX-XX-X/XX/XX}  % Allows default copyright data (X-XXXXX-XX-X/XX/XX) to be over-ridden.
% --- End of Author Metadata ---

\title{Composable and Hygienic Typed Syntax Macros}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{1} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Chenglong Wang ~~~~~~~~ Cyrus Omar ~~~~~~~~ Jonathan Aldrich \\ Carnegie Mellon University \\ \email{\{stwong, comar, aldrich\}@cs.cmu.edu}
% 2nd. author
}
%\and  % use '\and' if you need 'another row' of author names

% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
Syntax extension mechanisms can be powerful, but ensuring that extensions are individually well-behaved and that they can be unambiguously composed is difficult. Recent work on \emph{type-specific languages (TSLs)} addressed these problems in the specific setting of literal forms. We supplement TSLs with \emph{typed syntax macros (TSMs)}: explicitly invoked delimited syntax extensions at both the level of terms and types. To maintain a strong typing discipline, we describe two flavors of term-level TSMs: synthetic TSMs specify the type of term that they elaborate to, while analytic TSMs can elaborate to arbitrary type, but can only be used in positions where the type is known (like TSLs). Type-level TSMs generate both a type declaration and its corresponding TSL, so the two mechanisms can operate in concert. To support conventional syntactic idioms, we supplement the previous set of delimiters with a new \emph{multipart} delimited form. We specify TSMs by extending  the bidirectionally typed elaboration semantics previously given for TSLs, leveraging the same hygiene mechanism and internal language. Taken together, TSLs and TSMs provide significant expressive power without compromising composability, hygiene and typing.
\end{abstract}

% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]
%\terms{Delphi theory}
%\keywords{ACM proceedings, \LaTeX, text tagging}

\section{Introduction}
One way programming languages evolve is by introducing \emph{syntactic sugar} that captures common idioms more concisely and naturally. In most contemporary languages, this is the  responsibility of the language designers. Unfortunately, the designers of general-purpose languages do not have strong incentives to capture idioms that arise only situationally, motivating research into mechanisms that allow the users of a language to extend it with new syntactic sugar themselves.%, freeing designers from this responsibility.%, to varying degrees. 

Designing a useful syntax extension mechanism is non-trivial, however, because the designer can no longer  directly ensure that no parsing ambiguities have arisen and that the desugaring logic is semantically well-behaved. Instead, the mechanism must make several important guarantees:

\noindent
\textbf{Composability} The mechanism cannot simply allow the base language's syntax to  be modified arbitrarily due to the potential for parsing ambiguities, both with the base language and, critically, with one another (e.g. extensions adding support for XML and HTML).% To avoid this issue, extensions must be kept delimited from the base language and from one another. 

\noindent
\textbf{Hygiene} The logic specifying how newly introduced forms are elaborated must be constrained to ensure that the meaning of a program cannot change simply because some of the variables have been uniformly renamed (manually, or by a refactoring tool). It should also be straightforward to identify the binding site of a variable, even with intervening uses of sugar. These two situations correspond to inadvertent variable capture and shadowing by the desugaring logic. 

\noindent
\textbf{Typing Discipline} In a statically typed setting, which will be our focus in this work, a \emph{typing discipline} is also desirable: determining the type a term will have should be possible without requiring that the desugaring be performed, to aid both the programmer and tools like editors. 

Most prior approaches to syntax extension, discussed in Sec. \ref{related}, fail to provide all of these guarantees. Recent work on \emph{type-specific languages  (TSLs)} makes these guarantees, but only in a limited setting: library providers can define new syntax only for introducing values of a type (i.e. \emph{literal forms}), associating it as metadata with the type when it is declared \cite{TSLs}. Local type inference, specified as a bidirectional type system \cite{Pierce:2000:LTI:345099.345100}, controls which TSL is used to parse delimited pieces of syntax, so TSLs are composable and maintain the typing discipline. The semantics also guarantees that hygiene is maintained. We will review TSLs in Sec. \ref{background}. 

While many forms of syntactic sugar can be implemented as TSLs, there remain situations where TSLs do not suffice: 1) only a single TSL can be associated with a type, and only when it is declared, so alternative syntax for a type or syntax for a type not under a user's control cannot be defined; 2) idioms other than those that arise when introducing a value of a type (e.g. those related to control flow or API protocols) cannot be captured; and 3) types cannot themselves be declared using specialized syntax. In this paper, we introduce \emph{typed syntax macros (TSMs)}, which supplement TSLs to support these scenarios while maintaining the strong, and we believe crucial, guarantees above.% A TSM is invoked explicitly but otherwise benefits from the same mechanisms developed for TSLs. 

We introduce TSMs first at the term level in Sec. \ref{tsms-term}.  To maintain a typing discipline, there are two flavors of term-level TSMs: \emph{synthetic TSMs} can be used anywhere, while \emph{analytic TSMs} can only be used where the expected type of the term is otherwise known. Both TSLs and TSMs leverage a common set of  ligthweight delimited forms to separate syntax extensions from the host language. To support ``multi-argument'' TSMs (and TSLs), we supplement those previously defined with \emph{multipart delimited forms}. 

We next turn to the level of type declarations  in Sec. \ref{tsm-type}. Type-level TSMs generate not just a type declaration but also the TSL associated with it, allowing TSLs and TSMs to operate in concert, as we will demonstrate. 

In Sec. \ref{theory}, we give a minimal type-theoretic account of these mechanisms by extending the bidirectionally typed elaboration semantics for TSLs given previously by Omar et al., leveraging the same underlying hygiene mechanism and internal language.% (emphasizing the cohesion of these mechanisms). %   mechanism to support efforts to  decentralize control over the concrete syntax of a typed programming language. 

Taken together, TSLs and TSMs represent what we see as a new ``high water mark'' in expressive power, particularly within the space of systems providing the strong guarantees described above. We more specifically compare our work to related work in Sec. \ref{related}. 

\section{Background}\label{background}
\subsection{Wyvern}

\begin{figure}[t!]
\begin{lstlisting}[style=wyvern]
type @\htmlcolor{HTML}@ = casetype 
  Empty
  Seq of HTML * HTML 
  Text of String
  BodyElement of Attributes * HTML
  H1Element of Attributes * HTML
  StyleElement  of Attributes * CSS
  (* ... *)
  metadata = new : HasTSL
    val parser = ~
      @\expkwparsercolor{start <- '<body' attributes '>' start '</body>'}@
        fn atts, child => '@\expcolor{BodyElement((\$}@atts@\expcolor{, \$}@child@\expcolor{))}@'
      @\expkwparsercolor{start <- '<\{' EXP '\}>'}@
        fn e => e
      (* ... *)

let heading : HTML = H1Element({}, Text("My Heading"))
serve(~) (* serve : HTML -> Unit *)
  @\htmlcolor{<body id="doc1">}@
    @\htmlcolor{<\{}@heading@\htmlcolor{\}>}@
    @\htmlcolor{<p>My first paragraph.</p>}@
  @\htmlcolor{</body>}@
\end{lstlisting}
\mycaption{A case type with an associated TSL.}
\label{f-htmltype}
\end{figure}
We will present TSMs in the context of a simplified variant of the Wyvern programming language introduced previously to describe TSLs  \cite{TSLs}, making only minor changes that we will note as they come up. Wyvern is a statically typed  language with features from both the functional and object-oriented traditions and has a layout-sensitive concrete syntax. 

An example of a type encoding the tree structure of HTML is declared in Figure \ref{f-htmltype}. The named type \verb|HTML| is a \emph{case type}, with cases for each HTML tag and additional cases for an empty document, a sequence of nodes and a text node. Case types are similar to datatypes in an ML-like language (in type-theoretic terms, recursive labeled sum types). 
We can introduce a value of type \verb|HTML| by naming a case and providing data of the type the case declares, seen on line 12.

Type declarations are generative: \verb|HTML| is identified by name and so is distinct from any other type, including other case types with the same cases. Unlike in ML and the previously described variant of Wyvern, we do not combine type generativity and case types into a single construct. Instead, a named type is declared by deferring semantically to any other type underneath. For the purposes of this paper, this may be a  case type, a tuple types, e.g., \verb|HTML * HTML|, a function type, e.g., \verb|HTML -> Unit|, or an object type. We also assume that parameterized types can be defined, written e.g. \verb|List(T)|, where \verb|T| is another type. 
We assume that the definitions of standard  types like strings, lists and options are ambiently available via the \emph{prelude}, a collection of type declarations loaded before all others. 

Object types in Wyvern are structural (not class-based) and can declare fields (via \texttt{val}) and methods (via \texttt{def}). Two object types included in the prelude are shown in Figure \ref{exp-prelude}, described further below. The introductory form for an object type is \verb|new|, and it can only be used in an \emph{analytic position}, i.e. where the expected type is known (e.g. via an explicit type ascription or as an argument to a function). The keyword \verb|new| serves as a syntactic \emph{forward reference}: it can appear once per line, and the next indented block must give values for all the fields and implementations for all the methods specified by its type. We will see an example below.


All named types can be equipped with \emph{metadata}: a value constructed at compile-time and available for use by the language itself (in particular, the TSL mechanism) as well as other tools. Metadata is analagous to class annotations in Java, or class attributes in .NET languages, but unlike in these languages, it can be any Wyvern value (see below). % Here, we will use metadata to associate a TSL with \verb|HTML|. 

\subsection{Type-Specific Languages (TSLs)}


\begin{figure}[t!]
\begin{lstlisting}[style=wyvern]
type HasTSL = objtype
  val parser : Parser(Exp)

type @\expkwparsercolor{Parser}@(T) = objtype
  def parse(ps : ParseStream) : Result(T)
  metadata = new : HasTSL
    val parser = (* ... parser generator ... *)

type Result(T) = casetype
  OK of T
  Error of String * Location

type @\expcolor{Exp}@ = casetype
  Var of ID
  Lam of ID * Exp
  Ap of Exp * Exp
  Ascription of Exp * Type
  CaseIntro of ID * Exp
  (* ... *)
  metadata = new : HasTSL
    val parser = (* ... exp quasiquotes ... *)

type @\typecolor{Type}@ = casetype
  Named of ID
  Objtype of List(MemberDecl)
  Casetype of List(CaseDecl)
  Arrow of Type * Type
  metadata : HasTSL = new
    val parser = (* ... type quasiquotes ... *)
\end{lstlisting}
\mycaption{A portion of the Wyvern prelude relevant to TSLs and TSMs.}
\label{exp-prelude}
\end{figure}

Introducing a value of a type like \verb|HTML| using general-purpose syntax like that shown on line 12 can be tedious. Moreover, there is standard concrete syntax for HTML that might be preferable for reasons of familiarity or compatibility. To allow for this, we associate a \emph{type-specific language} with the \verb|HTML| type by setting the metadata to a value of type \verb|HasTSL|, an object type with a field \verb|parser| of type \verb|Parser(Exp)| (Figure \ref{exp-prelude}). 
 %We omit the implementation of the \verb|HTML| type's TSL \verb|parse| method here for concision. 

We see the TSL for \verb|HTML| being used on lines 13-15 of Figure \ref{f-htmltype}. On line 13, we wish to call a function \verb|serve| of type \verb|HTML -> Unit|. Rather than explicitly constructing a term of type \verb|HTML| as the argument, however, we use the \emph{forward referenced literal form} \lstinline[style=wyvern]{~}. The \emph{body} of the literal consists of the text in the indented block beginning on the next line, stripped of the leading indentation. In effect, whitespace is serving as a delimiter for the literal. We could equivalently have used other \emph{inline delimiters}, e.g. curly braces or single quotes, which restrict what can appear inside them, as described in Figure \ref{f-delimited}. For example, we could have written line 12 equivalently as:
\begin{lstlisting}[style=wyvern, numbers=none, frame=none]
  val heading : HTML = '@\htmlcolor{<h1>My Heading</h1>}@'
\end{lstlisting}

\begin{figure}[t]
\begin{lstlisting}[style=tempwyvern]
'@\htmlcolor{body here, '{}'inner single quotes'{}' must be doubled}@'
[@\htmlcolor{body here, [inner braces] must be balanced}@]
~ (* can appear at any expression position *)
  @\htmlcolor{forward referenced body here, leading indent stripped}@
{when body is a single base term, curly braces
can be useful because forward references propagate out}
[@\htmlcolor{adjacent}@] {@\htmlcolor{delimited forms}@} @\htmlcolor{or}@ [@\htmlcolor{those}@] @\htmlcolor{separated}@ ~ @\htmlcolor{form}@
  @\htmlcolor{by identifiers create a single multipart delimited}@
\end{lstlisting}
\mycaption{Available delimited forms. The curly brace delimited and multipart delimited forms are novel and shown being used in Sec. \ref{tsms-term}. }
\label{f-delimited}
\end{figure}


When the type system encounters literal forms like this, it defers to the parser defining the TSL of the type the literal is being analyzed against, here \verb|HTML| because it is the argument type of \verb|serve|. As suggested by the declarations in Figure \ref{exp-prelude}, the TSL is responsible for transforming a \verb|ParseStream| based on the body to a \verb|Result(Exp)|, which is either an \verb|Exp| or a parse error. The case type \verb|Exp| simply encodes the abstract syntax of Wyvern, so the TSL is defined as a desugaring. Note that the prelude types \verb|Parser| and \verb|Exp| each have TSLs associated with them, which provide a \emph{grammar-based parser generator} (based on Adams grammars \cite{Adams:2013:PPI:2429069.2429129}, see below) and \emph{quasiquote} facilities, respectively. We see them being used in Figure \ref{f-htmltype}. We refer the reader to \cite{TSLs} for further details on the TSL mechanism and this application  of them.

The \verb|parse| method can request that some portion of the parse stream be treated as a \emph{spliced} host language term. For example, the TSL for \verb|HTML| specifies the delimiters \verb|<{| and \verb|}>| to mean ``insert the enclosed term, of type \verb|HTML|, here''. The parser generator reserves the non-terminal \verb|EXP| for such spliced host language terms. The hygiene mechanism for TSLs, which we will use essentially as-is, ensures that only spliced terms can refer to variables in the surrounding scope.

For clarity in this paper, we will color host language terms, including those spliced in this way, black. Portions of TSL (and TSM) bodies that are not spliced host language terms will be colored a unique color corresponding to the TSL or TSM being used, identified when declared. 

\section{Term-Level TSM\lowercase{s}}\label{tsms-term}
In this section, we will give examples of term-level typed syntax macros in Wyvern to illustrate how they are defined and can be used in situations where TSLs are not suitable. We follow up with a more formal treatment in Sec. \ref{theory}. 

%Term-level TSMs come in two flavors: \emph{synthetic TSMs} specify the type of term they will elaborate to, meaning they can be used anywhere, while \emph{analytic TSMs} can elaborate to a term of any type, but to maintain the typing discipline, they can only be used in positions where the type can otherwise be determined. 

\subsection{Synthetic TSMs}
TSMs are defined using the \verb|syntax| keyword. Figure \ref{f-simplehtml} shows a synthetic TSM, \verb|simpleHTML|, being defined and used. The annotation on the first line indicates that valid uses of the TSM will always elaborate to a term that synthesizes the type \verb|HTML|. Like defining a TSL, defining a TSM requires defining a parser, which is a statically-evaluated value of type \verb|Parser(Exp)| (for the purposes of exposition, we include type annotations that are not strictly necessary in comments throughout the paper). 

We again define the parser by using the TSL for \verb|Parser|. Here, we are defining an alternative layout-sensitive syntax for HTML that is more concise than the conventional one by way of an \emph{Adams grammar}, which supports declarative specifications of layout-sensitive grammars by using \emph{layout constraints} within productions \cite{Adams:2013:PPI:2429069.2429129}. Here, \verb|=| indicates that the left-most column (on any line) occupied by the annotated terminal or non-terminal must occur at the same column as the parent production and \verb|>| indicates that it must be further indented. More detail on Adams' grammars and this example syntax for HTML can be found in \cite{TSLs}. 

A TSM is invoked by naming it and following it with a delimited form (Figure \ref{f-delimited}). The body of the delimited form is parsed according to the definition of the TSM. Notice here that on line 7, we no longer need a type annotation on \verb|heading| because \verb|simpleHTML| is synthetic. On lines 8-11, we use the same forward referenced delimited form introduced in the work on TSLs to avoid syntactic clashes between explicit delimiters and the extended syntax. The only difference here is the addition of the \verb|simpleHTML| ``keyword'', which indicates to the type system that the TSM should be used rather than the TSL for \verb|HTML|. Note that both can straightforwardly be used in the same program, so synthetic TSMs address the issue of defining more than one possible syntax for a type that either has a TSL defined for it already, or a type which a user cannot modify (because it appears in an external library). We do not here address namespacing issues, as standard techniques can be used to ensure that different TSMs have globally unique names. 

%An expression keyword is a keyword associated with a parser to transform DSL literals into a Wyvern expression. Depending on whether a return type is provided in the keyword declaration, expression keywords can be further divided into black-box keyword and white-box keyword (This terminology is borrowed from Scala's macro system). 


\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
syntax @\simpleHTMLcolor{simpleHTML}@ : HTML = ~ (* : Parser(Exp) *)
  @\expkwparsercolor{start <- '>body'= attributes> start>}@
    fn atts, child => '@\expcolor{BodyElement((\$}@atts@\expcolor{, \$}@child@\expcolor{))}@'
  @\expkwparsercolor{start <- '<'= EXP>}@
    fn e => e
  (* ... *)
let heading = simpleHTML '@\simpleHTMLcolor{>h1 My Heading}@'
serve(simpleHTML ~)
  @\simpleHTMLcolor{>body[id="doc1"]}@
    @\simpleHTMLcolor{<}@ heading
    @\simpleHTMLcolor{>p My first paragraph}@
\end{lstlisting}
\mycaption{A synthetic TSM providing alternative syntax for the \texttt{HTML} type in Figure \ref{f-htmltype}. The programs are semantically identical.}
\label{f-simplehtml}
\end{figure}
\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
type Bool = casetype 
  True
  False
syntax @\boolIfcolor{if}@ = ~ (* : Parser(Exp) *)
  @\expkwparsercolor{EXP BOUNDARY EXP BOUNDARY `else' BOUNDARY EXP}@
    fn guard, branch1, branch2 => ~ (* : Exp *)
      @\expcolor{case \$}@guard
        @\expcolor{True => \$}@branch1
        @\expcolor{False => \$}@branch2
def testIf(ok : Bool) : HTML
  if [ok] {simpleHTML ~} @\boolIfcolor{else }@{simpleHTML '@\simpleHTMLcolor{>h1 Not OK!}@'}
    @\simpleHTMLcolor{>h1 Everything is OK!}@
\end{lstlisting}
\mycaption{An analytic TSM providing a conventional syntax for \texttt{if} based on case analysis. Lines 11-12 demonstrate multipart delimited forms.}
\label{if-example}
\end{figure}

\subsection{Analytic TSMs}
Some idioms may be valid at many types. As perhaps the simplest example, consider a case type encoding booleans, \verb|Bool|, shown in Figure \ref{if-example}. Using explicit case analysis on booleans is often unnecessarily verbose, so we wish to introduce the more idiomatic and concise \verb|if| construct. Rather than having to build this in to the language, however, we can implement it as an analytic TSM. These are distinguished from synthetic TSMs by the absence of a type annotation, because the type of an \verb|if| expression is determined by its branches. 

We see \verb|if| being used on lines 10-12 of Figure \ref{if-example} with a \emph{multipart delimited form}. Each \emph{part} can be either a delimited form (e.g. the guard and the two branches) or an intervening keyword (e.g. \verb|else|). There are implicit boundaries between each part which parse to  a special token called \verb|BOUNDARY| by our parser generator (line 5). For the branches, we use curly brace delimiters, which have evolved since our previous work on TSLs to be specialized for situations where the body consists of a single spliced term. Because the parser can assume this, forward references can be identified prior to typechecking and thus be allowed to escape, as we see in the ``then'' branch in our example: the body is on the next line. Were, for example, square brackets used, then we would need to write the example as follows:

\begin{lstlisting}[style=wyvern]
def testIf2(ok : Bool) : HTML
  if [ok] [simpleHTML ~
    @\simpleHTMLcolor{>h1 Everything is OK!}@
  ] else [simpleHTML '@\simpleHTMLcolor{>h1 Not OK!}@']
\end{lstlisting}

An analytic TSM can only be used in a position where the type is otherwise known, e.g. due to the return type annotation on line 10. This is to maintain the typing discipline: we do not need to expand the TSM to know what type it will have, as with synthetic TSMs and TSLs. Although we believe this trade-off is worthwhile, another point in the design space is to permit a special signifier that can be used to allow analytic TSMs to be used in synthetic positions. For example, we might permit a post-fix asterisk on the TSM to indicate that the elaboration is expected to synthesize a type. The specific type that is synthesized requires a deeper understanding of the TSM in question (e.g. by knowing how it elaborates, or based on a ``derived'' typing rule that the authors of \verb|if| assert, or prove \cite{conf/icfp/LorenzenE13}, is always admissible):

\begin{lstlisting}[style=wyvern]
def testIf3(ok : Bool) (* no return type annotation *)
  if* [ok] {simpleHTML ~} else {simpleHTML '@\simpleHTMLcolor{>h1 Not OK!}@'}
    @\simpleHTMLcolor{>h1 Everything is OK!}@
\end{lstlisting}

The most permissive point in the design space is to simply allow such TSMs in synthetic positions without an explicit signifier. We note that would be the syntax macro analogy of \emph{white-box (term rewriting) macros} in Scala \cite{ScalaMacros2013}, which are not  available by default in the upcoming Scala 2.12. Synthetic TSMs are analagous to black-box macros. 

\section{Type-Level TSMs}
Besides using expression keywords and TSLs to extend the host language with new syntax in expressions, constructing a type with external syntax can be useful in object-relational mapping (ORM). Although data schema already exists, declaring a type with fields to represent the data structure still require users to create them manually in Wyvern syntax. Type keywords make this process easier by allowing users to generate type declarations directly using the data schema syntax, and furthermore, a metadata will be generated for initializing the value of that type. The following example shows how we construct a type using database schema.



In figure \ref{f-tykwexample}, we present an example of constructing the type \verb|EmployeeDB| using the type keyword \verb|DBSchema|. By defining the type \verb|EmployeeDB| using a type keyword, the type \verb|EmployeeDB| will be provided with the following fields/methods after elaboration (line 1-13 in figure \ref{typekw-example-2}):
\begin{itemize}\setlength{\itemsep}{0pt}
\item Fields and method declarations based on the data schema. (e.g. \verb|employee|, \verb|getByName|)
\item Common fields and method declarations provided for all types using the type keyword, and they don't depend on a certain schema. (e.g. \verb|connection| and \verb|stmts|)
\item A TSL metadata for value initialization using the DSL syntax.
\end{itemize}

Line 1-3 in figure \ref{f-tykwexample} shows the declaration of the type \verb|EmployeeDB| using database schema syntax. And a value \verb|db| (line 5-10) is defined using the syntax provided by the generated TSL metadata. 

The elaborated version of the type \verb|Employee| and the value \verb|db| is presented in figure \ref{typekw-example-2}: a type member \verb|Entry| is declared in the type to represent a data table entry, and methods like \verb|getById| are generated for database access. The elaborated value \verb|db| (line 15) is initialized with fields and methods.

The definition of the type keyword \verb|DBSchema| can be referred to figure \ref{typekw-example-1}. A type keyword itself is a parser for DSL literals: it is a value of type \verb|TypeParser|, which takes in a parsestream and returns a parsing result (of type \verb|Result|, which is a casetype defined in figure \ref{exp-prelude}). When there is no parsing error, a tuple \verb|(t:Type, e:Exp, k:List(KwMember))| will be returned for type construction: the type structure stored in \verb|t|, metadata in \verb|e|, and expression keywords defined by \verb|k|. \verb|DBSchema| will construct an object type with fields specified in line 5-18, and it will provide a TSL metadata for value initialization (line 20-35). The type of the metadata is provided on the first line of keyword declaration with keyword \verb|with metadata|, which is used by the type checker to analyze the metadata type.

% \begin{figure}
% \begin{lstlisting}[style=wyvern]
% type @\typekwparsercolor{TypeParser}@ = objtype
%   def parse(ps : ParseStream) : Result(Type * Exp * List(KwMember))
%   metadata : HasTSL = new 
%     val parser = (* parser generator *)

% type @\typecolor{Type}@ = casetype
%   Named of ID
%   Objtype of List(MemberDecl)
%   Casetype of List(CaseDecl)
%   Arrow of Type * Type
%   metadata : HasTSL = new
%     val parser = (* type quasiquotes *)

% type KwMember = casetype
%   Whitebox of Label * ExpKw
%   Blackbox of Label * ExpKw * Type
% \end{lstlisting}
% \mycaption{Wyvern prelude for type keywords}
% \label{type-prelude}
% \end{figure}
\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
type @\dbcolor{EmployeesDB}@ = DBSchema ~
  @\dbshcemacolor{*ID   int}@
  @\dbshcemacolor{Name  varchar}@

val db : EmployeeDB = ~
  @\dbcolor{connect to}@ ~
    @\urlcolor{mysql://localhost:3306}@
  @\dbcolor{username: }@"user1"
  @\dbcolor{password: }@"001"
  @\dbcolor{table: Employees}@
\end{lstlisting}
\mycaption{The usage of the type keyword ``DBTable''}
\label{f-tykwexample}
\end{figure}

\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
type EmployeesDB = objtype
  type Entry = objtype
    val ID : Int
    val Name : String 
  val connection : URL
  val username : String
  val password : String
  ...
  def getById (x:Int) : Option(Entry)
  def getByName (x : String) : List(Entry)
  metadata = new : HasTSL
    val parser = ~
      ... (* TSL parser generated by type constructor *)

val db : EmployeesDB = new
  val connection = new
    val domain = "localhost"
    ...
  val username = "user1"
  val password = "001"
  ... (* Other fields *)
  def getByID(x:Int) : List(Entry)
    ...
\end{lstlisting}
\mycaption{The elaborated type declaration}
\label{typekw-example-2}
\end{figure}

\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
typekw @\dbshcemacolor{DBSchema}@ with metadata:HasTSL = ~ (*:TypeParser*)
  @\typekwparsercolor{start <- pairs}@
    fn pairs =>
      let ty : Type = ~
        @\typecolor{objtype}@
          @\typecolor{type Entry = objtype}@
            @\typecolor{\{}@map(pairs, Nil, 
              fn ((p, lbl, ty), l) => Cons(~, l))
                @\membercolor{val \$}@lbl @\membercolor{:  \$}@ty
            @\typecolor{\}}@
          @\typecolor{val connection : URL}@
          @\typecolor{val username : String}@
          @\typecolor{val password : String}@
          @\typecolor{...}@
          @\typecolor{\{}@map(pairs, Nil, 
            (fn ((p, lbl, ty), l) => Cons(~, l)))
              @\membercolor{def getBy\$}@lbl @\membercolor{(\$}@ty@\membercolor{)}@
          @\typecolor{\}}@
      let md : HasTSL = new 
        val parser = ~
          @\hastslcolor{start <- ("connect to "= EXP>}@
                    @\hastslcolor{"username:"= EXP>}@
                    @\hastslcolor{"password:"= EXP>}@
                    @\hastslcolor{"table:" EXP>)}@
            fn url, un, pw, table => ~
              @\expcolor{new}@ 
                @\expcolor{val connection = \$}@url
                @\expcolor{val username = \$}@un
                @\expcolor{val password = \$}@pw
                @\expcolor{...}@
                @\expcolor{\{}@map(pairs, Nil, 
                  (fn ((p, lbl, ty), l) => Cons(~, l)))
                    @\membercolor{def getBy}@$lbl @\membercolor{(x)}@ 
                      @\membercolor{...}@(* implementation *)
                @\expcolor{\}}@
      (ty, md, Nil)
  @\typekwparsercolor{pairs <- ()}@
    fn () => Nil 
  @\typekwparsercolor{pairs <- pair= pairs=}@
    fn hd, tl => Cons(hd, tl)
  @\typekwparsercolor{pair <- "*"? ID ID}@
    fn is_primary, colid, tyid => (
      is_primary, colid, ty_from_sqlty(tyid))
\end{lstlisting}
\mycaption{The declaration the type keyword ``DBTable''}
\label{typekw-example-1}
\end{figure}


\section{Syntax}\label{theory}
We start our formal presentation by introducing the abstract syntax together with their concrete forms built upon pure functional Wyvern. For simplicity consideration, we omit some of the syntax not directly related to composable syntax macros, which can be referred to \todo{TSL paper}.

A Wyvern program ($\rho$) consists of three parts: type keyword declarations ($\eta$), named-type declarations ($\theta$) and an expression ($e$) representing the program body.

\begin{figure}[ht]
  \[
  \begin{array}{ll}
      \textbf{Abstract Forms}   & \textbf{Concrete Forms}\\
      \text{Program}\\
      \rho~::=~\eta;\theta;e  &\\
      \text{Type Keywords}\\
      \eta~::=~\emptyset      &\\
      \tabularspace\eta;k[e,\tau] & \textcd{typekw}~k~\textcd{with metadata:}\tau~\textcd{=}~e\\
      \text{Expression Keywords}\\
      \kappa~::=~\emptyset\\
      \tabularspace\kappa;k[\mathbf{bk}(\tau),e]    & \textcd{expkw}~k : \tau~\textcd{=}~e\\
      \tabularspace\kappa;k[\mathbf{wk},e]          & \textcd{expkw}~k~\textcd{=}~e\\
      \text{Type Declarations}\\
      \theta~::=~\emptyset\\
      \tabularspace\theta; T[\mathbf{explicit},\tau, e, \kappa]  & \textcd{type}~T~\textcd{=}~\tau\\
                                                            & ~~~\textcd{metadata = }e\\
                                                            & ~~~\kappa\\
      \tabularspace\theta; T[\mathbf{tykw},k, body, e, \kappa]   & \textcd{type}~T~\textcd{=}~k~delims\\
                                                            & ~~~\textcd{metadata = }e\\
                                                            & ~~~\kappa\\
      \text{Types}\\
      \tau~::=~\mathbf{named}[T]              & T\\
      \tabularspace\mathbf{objtype}[\omega]       & \textcd{objtype}~\omega \\
      \tabularspace\mathbf{casetype}[\chi]        & \textcd{casetype}~\chi\\
      \tabularspace\mathbf{arrow}[\tau, \tau]     & \tau \textcd{->}~\tau\\
      \text{Object Fields}\\
      \omega~::=~\emptyset                      \\
      \tabularspace l[\mathbf{val},\tau];\omega                 & \textcd{val} l : \tau\\
      \tabularspace l[\mathbf{def},\tau];\omega                 & \textcd{def} l : \tau\\
      \text{Casetype Cases}\\
      \chi~::=~\emptyset                      \\                 
      \tabularspace C[\tau];\chi                   & C~\textcd{of}~\tau\\
      \text{External Terms}\\
       e~::=~...                              & \\
      \tabularspace\mathbf{lit}[body]             & delims\\
      \tabularspace\mathbf{ekey}[k,body](e)       & e.k~delims\\
      \text{Translational Terms}\\
      \hat{e}~::=~...                              & \\
      \tabularspace\mathbf{spliced}[e]            & \\
      \text{Internal Terms}\\
      i~::=~...
  \end{array}
  \]
\mycaption{Abstract and Concrete Forms}
\label{formal-syntax}
\end{figure}


\begin{comment}
\begin{figure}[ht]
\hspace{-5px}\begin{tabular}{ l l l l l }
 \multicolumn{1}{l}{\textbf{Abstract Forms}} & \multicolumn{1}{l}{\textbf{Concrete Forms}}\\
 \multicolumn{3}{l}{Programs}\\
$\rho$~::=~$\eta;\theta;e$\\
\multicolumn{3}{l}{Type Keywords}\\
$\eta$~::=~$\emptyset$\\
\tabularspace$\eta;k[e,\tau]$ & \textcd{typekw} $k$ \textcd{with metadata:}$\tau$ \textcd{=} $e$ \\
\multicolumn{3}{l}{Expression Keywords}\\
$\kappa$~::=~$\emptyset$                        & \\
\tabularspace$\kappa;k[\mathbf{bk}(\tau),e]$    & \textcd{expkw} $k$ : $\tau$ \textcd{=} $e$\\
\tabularspace$\kappa;k[\mathbf{wk},e]$          & \textcd{expkw} $k$ \textcd{=} $e$\\
\multicolumn{3}{l}{Type Declarations}\\
$\theta$~::=~$\emptyset$                        & \\
\tabularspace$\theta; T[\mathbf{explicit},\tau, e, \kappa]$  & \textcd{type} $T$ \textcd{=} $\tau$\\
&~~~\textcd{metadata = }$e$\\
&~~~$\kappa$\\
\tabularspace$\theta; T[\mathbf{tykw},k, body, e, \kappa]$   & \textcd{type} $T$ \textcd{=} $k$ $delims$\\
                                                          & ~~~\textcd{metadata = }$e$\\
                                                          & ~~~$\kappa$\\
\multicolumn{3}{l}{Types}\\
$\tau$~::=~$\mathbf{named}[T]$              & $T$\\
\tabularspace$\mathbf{objtype}[\omega]$       & \textcd{objtype} $\omega$ \\
\tabularspace$\mathbf{casetype}[\chi]$        & \textcd{casetype} $\chi$\\
\tabularspace$\mathbf{arrow}[\tau, \tau]$     & $\tau$ \textcd{->} $\tau$\\
\multicolumn{3}{l}{Object Fields}\\       
$\omega$~::=~$\emptyset$                      \\
\tabularspace$l[\mathbf{val},\tau];\omega$                 & \textcd{val} $l$ : $\tau$\\
\tabularspace$l[\mathbf{def},\tau];\omega$                 & \textcd{def} $l$ : $\tau$\\
\multicolumn{3}{l}{Casetype Cases}\\
$\chi$~::=~$\emptyset$                      \\                 
\tabularspace$C[\tau];\chi$                   & $C$~\textcd{of}~$\tau$\\
\multicolumn{3}{l}{External Term}\\
 $e$~::=~...                              & \\
\tabularspace$\mathbf{lit}[body]$             & $delims$\\
\tabularspace$\mathbf{ekey}[k,body](e)$       & $e.k$ $delims$\\
\multicolumn{3}{l}{Translational Terms}\\
$\hat{e}$~::=~...                              & \\
\tabularspace$\mathbf{spliced}[e]$            & \\
\multicolumn{3}{l}{Internal Terms}\\
$i$~::=~...                                                     
\end{tabular}
\mycaption{Abstract and Concrete Forms}
\label{formal-syntax}
\end{figure}
\end{comment}


\paragraph{Type-keyword Declaration}
Users define type keywords in the type-keyword declaration section ($\eta$). The declaration of a keyword includes an expression $e$ and a metadata type $\tau$. The expression $e$ is the parser to parse the DSL literals used in a type keyword invocation, and the type $\tau$ is the type of the generated metadata. Type keyword declarations are in the top level of the program in our formal definition, but in practice, they will be defined in different modules, which supports better modularity.

\paragraph{Named type declaration}
Named type declarations is the declaration of types ($\tau$) which are associated with a type name ($T$). 
According to the way to declare, there are two kinds of type declarations: an explicit type declaration with its structure and metadata explicitly specified, or a type declared with a type keyword invocation, whose structure, metadata and keywords are generated by the elaborated DSL literals presented in the keyword invocation body.

An explicit type declaration ($T[\mathbf{explicit}, \tau,e,\kappa]$) consists of four parts: $T$ is the type name, $\tau$ is the structure of the type, which can be one of $\mathbf{objtype}$, $\mathbf{casetype}$, $\mathbf{arrowtype}$ or a copy of named type $\mathbf{named}[T']$,  $e$ is the metadata associated with the type and $\kappa$ is the expression keyword declarations in the type.

The second kind of type declaration ($T[\mathbf{tykw},k,body,e,\kappa]$) is a type declared using DSL syntax specified in a type keyword $k$, with DSL literals specified in $body$. Metadata ($e$) and expression keywords ($\kappa$), different from those in the first kind, serve as an extension to metadata and keywords generated by the keyword parser. Details for this extension mechanism will be discussed in the next section.

\paragraph{External Expressions}
By naming expressions presented in a Wyvern program ``external expressions'' ($e$), we distinguish them from ``internal expressions'' ($i$), which are pure Wyvern expressions without DSL literals. 

To support syntax macros, we extend Wyvern syntax with a keyword invocation expression ($\mathbf{ekey}[k,body](e)$) and several expressions for run-time parser access (omitted here, can be referred to \todo{TR}). The concrete form of a keyword invocation expression can be referred to figure~\ref{formal-syntax}, which consists of a call to the keyword followed by delimited DSL literals. 

An external expression with DSL literals will elaborate to internal Wyvern expressions finally with the help from the DSL parser, and a translational expression  
is defined in the abstract syntax to represent the expression forms in translational phase. The syntax for translational terms mirrors that of external terms, except that literal forms are removed and and translational state $\mathbf{spliced}[e]$ is added, which represents an external term $e$ spliced into a literal body.

\section{Bidirectional Typechecking and Elaboration}
Both expression keywords and type keywords are used in external Wyvern languages, so an elaboration phase is required to transform external a Wyvern program with DSL literals into internal Wyvern representations.

Bidirectional typechecking is used here as type can be clearly specified as input or output during typechecking process. In bidirectional type system, a type judgment is written as $\Gamma\vdash_{\Theta} e\Leftarrow(\Rightarrow)\tau$ instead of $\Gamma\vdash_{\Theta} e:\tau$ in a traditional type system, where $\Gamma$ is the typing context, $\Theta$ is the declaration context, and the type $\tau$ is specified as input ($\Leftarrow$) or output ($\Rightarrow$) according to the arrow direction. 

The type checking process involves the elaboration of an external expression, written as $\Gamma\vdash_{\Theta} e\rightsquigarrow i \Leftarrow(\Rightarrow) \tau$. It indicates that an external expression will be elaborates to an internal expression and synthesize to (or analyze against) the type $\tau$. The arrow ($\rightsquigarrow$) is used to represent the elaboration process, including literal elimination and hygiene process, which is part of the type checking rules.

\subsection{Program Context}
\todo{Type environment or type context or typing context? -I use ``program context'' for the moment to refer to them}
The program context (figure \ref{typechecking-environment}) contains the context for type keywords and named type declarations, which will be used during elaboration and type checking. 

\begin{figure}[ht]
\begin{center}
\begin{tabular}{r r c l}
Type Keyword Context & $\Delta$ & ::= & $\emptyset$\\
              &                 &  |  & $\Delta;k[i,\tau]$\\
Named Type Context  & $\Theta$        & ::= & $\emptyset$\\
              &                 &  |  & $\Theta,T[\delta,\mu,\zeta]$\\
              & $\delta$        & ::= & $?$ ~ | ~ $\tau$\\
   & $\mu$           & ::= & $?$ ~ | ~ $i:\tau$\\
   & $\zeta$         & ::= & $?$ ~ | ~ $\dot\kappa$\\
Keyword Members & $\dot\kappa$    & ::= & $\emptyset$\\
            &                 &   |  & $\dot\kappa;k[\mathbf{bk}(\tau),i]$\\
            &                 &   |  & $\dot\kappa;k[\mathbf{wk},i]$\\
Typing Context & $\Gamma$ &   ::=  & $\emptyset$\\
                 &          &     |  & $\Gamma,x:\tau$
\end{tabular}
\end{center}
\mycaption{Definition of type context}
\label{typechecking-environment}
\end{figure}

Type keyword context ($\Delta$) is the environment for user defined type keywords. A keyword in $\Delta$ is associate with an internal Wyvern expression, representing the parser expression, and a type $\tau$ representing the metadata type of the keyword. 

Named typed context ($\Theta$) is the environment to keep all elaborated type declarations. In named typed context both explicitly declared types and type keyword defined types will go into the context in the form of $T[\delta,\mu,\zeta]$, which is interpreted as a type of name $T$ with structure $\delta$, metadata $\mu$ and expression keywords $\zeta$. In named typed context, all of $\delta$, $\mu$, $\zeta$ have an option to be $?$, which is used to represent an ``unknown state'' during elaboration phase. 

And at last, $Gamma$ is the typing context used in type checking, values in $\Gamma$ are bindings of variables and their types ($x:\tau$).

\todo{Stop here}

\subsection{External Type Literals}
In the type environment, there is no difference between the two types of type declaration mentioned in the syntax as all types defined using type keywords elaborates to a type with concrete structure during type checking process.

The type checking rules for type keywords usage is labeled as type-name-2, type-defs-2 and type-exts-2. The rule type-name-2 simply adds the type name into the environment for other types to refer to.

The rule type-name-2 present the type elaboration process, and the external syntax used in type keyword will be transformed to a normalized type structure. The process consists of the following steps:
\begin{enumerate}\setlength{\itemsep}{0pt}
\item Check if the environment prelude is in the type environment. The prelude environment consists of necessary types and parser definition. 
\item Look up the keyword in $\Delta$. This requires a valid parser defined in the type keyword environment for parsing the literals later.
\item Invoke the parser to parse the DSL literal body ($i_{ps}$, as an expression the parser parsed to). In the rule kw-env, the parser is already checked against type $TypeKw$, so the parser is of type $PasrseStream->DeclResult$. So a return type ($i_{type}$) and an type metadata ($i_{exp}$) will be provided by the parser.
\item The type expression ($i_{type}$) will be transformed to a Wyvern type structure (i.e. objtype or casetype) using type dereification rules (marked as `$\uparrow$'). And the type will be checked to guarantee the formation of its structure.
\item The metadata expression will be reconstructed, it will be reificate to a spliced expression and then transform to an inner Wyvern expression of type $\tau_m$. 
\end{enumerate} 
After these steps, the type structure as well as the TSL metadata associated with the type is generated, and no more external type syntax exists.

The rule type-exts-2 stands for the rule to resolve the metadata conflict between the metadata generated by type keyword ($i_m$) and that defined in the named type declaration ($i_w$). In the rule type-exts for normal named type declaration, the metadata will be directly added into the environment, but in this case, we require $i_w$ to be a metadata resolver: it should be a function of type $\tau_m\rightarrow\tau'_m$, as it will take in $i_m$ and return a modified metadata $i'_m$ ($\mathbf{iap}(i_w, i_m)\Downarrow i'_m$ presents the process). The expression keywords part is the same as that in a normal named type declaration.
\input{kw-elaboration.tex}

\subsection{Expression Keywords Literals}
Besides type keywords and TSLs, another usage of the DSL literals is in expression keywords. The different rules to process keywords invocation includes three situations: Using DSL literals in a black-box keyword, using DSL literals in a white-box keyword with type analysis and using DSL literals in a white-box keyword with type synthesis. Their difference only lies in the inference of the return type so we only explain the rule using the rule T-wk-syn. Processing literals in an expression keyword invocation includes the following steps:
\begin{enumerate}\setlength{\itemsep}{0pt}
\item Check that the prelude environment $\Theta_0$ is in the current environment. 
\item The target term ($e_0$) elaborates into an inner Wyvern term ($i_0:T$), and then check that the type $T$ is declared in the type environment with an keyword environment $\dot\kappa$ inside it.
\item Look up the expression keyword inside the keyword declarations, as checked in the rule expkw-bk and expkw-wk, the parser should be of type $ExprKw$ (The parser type for expression keyword presented in Wyvern prelude).
\item Transform the target expression into an reified elaboration form ($i_0\downarrow i'_0$), this will transform the target expression into an \verb|Exp| expression, which will be used in the parsing process of literal elaboration.
\item The parser takes in two expressions: the reified target expression and the parsestream of the literals, then generate an expression of type $Result$, which will be used to build the return expression.
\item The expression is dereified into an translational term of $\hat{e}$, which is used to mirror an external term but transform the representation of DSL literals into $\mathbf{spliced}[e]$, as a middle representation before elaborates to an external term.
\item The last step is type checking. It checks the term $i$ which will synthesize to type $\tau$ (For black-box keyword or white-box under analysis, it will be replaced by a type analysis against $\tau$). The expression the keyword invocation elaborates to should be the expression $i$ of type $\tau$, which is an inner Wyvern term used to compile and execute at run time. 
\end{enumerate}
\input{kw-statics.tex}

\subsection{Hygiene}
\todo{Do we need to do it here?}

\subsection{Metatheory}
\paragraph{Reification and Dereification}
For each type and expression, we have the following properties to support converting a type to an expression of type \textbf{named}[$Type$] and an expression to an expression of type \textbf{named}[$Exp$] (Property 1, 2). And reversely, converting an inner term to an Wyvern expression $i$ of type $\mathbf{named}[Exp]$ (Property 3). These properties are used to construct a type $\tau$ or an expression $\hat{e}$ from parsing results (an expression of type $Exp$ or $Type$) in the elaboration rule. 
\begin{property}If $\emptyset\vdash_{\Theta} i:\mathbf{named}[Type]$ then there exists a corresponding $\tau$ s.t. $i\uparrow\tau$. 
\end{property}
\begin{property}
If $\emptyset\vdash_{\Theta} i:\mathbf{named}[Exp]$ then there exists an translational term $\hat{e}$, s.t. $i\uparrow\hat{e}$.
\end{property}

\begin{property}
For any $i$, these exists an inner term $i'$, s.t. $i\downarrow i'$ and $\emptyset\vdash_{\Theta_0} i':\mathbf{named}[Exp]$.
\end{property}
The rules for these properties can be referred to \todo{TR}.

\paragraph{Type Safety and Preservation}
Extension of the TSL Wyvern semantics with keywords mechanism still constitutes a type safe language. We will outline the key theorems and lemmas here presenting the properties a type safe language has: 1) internal type safety 2) type preservation. 

To formalize the type safety property, we defined the judgments for context formation, type formation and bidirectional typing judgment. \todo{Refer to TSL as well as TR}

\begin{theorem}[Internal Type Safety]
If ~$\vdash_{\Theta_0}\Delta$, $\vdash_{\Theta_0}\Theta$~ and $\emptyset\vdash_{\Theta}i\Leftarrow\tau$ or $\vdash_{\Theta}i\Rightarrow\tau$, then either $i~\texttt{val}$ or $i\mapsto i'$ such that $\emptyset\vdash_{\Theta}i'\Leftarrow\tau$.
\end{theorem}
\begin{proof}
As the keyword extension on TSL framework does not extend inner Wyvern expressions, the proof for this theorem is directly from TSL proof. 
\end{proof}

\begin{theorem}[External Type Preservation]
If ~$\vdash_{\Theta_0}\Delta$, $\vdash_{\Theta_0}\Theta$, $\vdash_{\Theta}\Gamma$, and $\Gamma\myvdash e\rightsquigarrow i\Leftarrow\tau$ or $\Gamma\myvdash e\rightsquigarrow i\Rightarrow\tau$ then $\Gamma\myvdash i\Leftarrow\tau$.
\end{theorem}
\begin{proof}
Based on TSL proof of the external type preservation, we need to proof the following cases on keywords extension (Expressions for parser access is presented in the \todo{TR}, thus the corresponding proofs of the case for the expression is omitted here. ):
\begin{itemize}
\item $e=\mathbf{ekey}[k,body](e)$. According to the rule T-bk and T-wk, $\Gamma\vdash_{\Theta}\mathbf{ekey}[k,body](e_0) \rightsquigarrow i \Rightarrow \tau \Longrightarrow \Gamma;\emptyset\myvdash \hat{e} \rightsquigarrow i \Rightarrow \tau$. According to Lemma 1, $\Gamma;\emptyset\myvdash \hat{e} \rightsquigarrow i \Rightarrow \tau \Longrightarrow \Gamma;\emptyset\vdash_{\Theta} i\Rightarrow\tau$.
\end{itemize}
\end{proof}

\begin{lemma}[Translational Type Preservation]
If \\$\vdash_{\Theta_0}\Theta$, $\vdash_{\Theta_0}\Delta$ and $\vdash_{\Theta}\Gamma_{out}$ and $\vdash_{\Theta}\Gamma$ and $dom(\Gamma_{out})\cap dom(\Gamma)=\emptyset$ and $\Gamma_{out};\Gamma\vdash_{\Theta}^{\Delta}\hat{e}\rightsquigarrow i\Leftarrow\tau$ or $\Gamma_{out};\Gamma\vdash_{\Theta}^{\Delta}\hat{e}\rightsquigarrow i\Rightarrow \tau$ then $\Gamma_{out}\Gamma\vdash_{\Theta}i\Leftarrow \tau$.
\end{lemma}


\begin{theorem}[Compilation]
If ~$\rho\sim\Theta\rightsquigarrow i:\tau$~ then $\vdash_{\Theta_0}\Delta$,\ $\vdash_{\Theta_0}\Theta$ and $\emptyset\vdash_{\Theta} i\Leftarrow\tau$.
\end{theorem}
\begin{proof}
This theorem can be proved with the following two lemmas for the formation of $\Delta$ and $\Theta$.
\end{proof}

\begin{lemma}[Type Keyword Declaration] 
If $\vdash_{\Theta_0}\eta\sim\Delta$, then $\vdash_{\Theta_0}\Delta$.
\end{lemma}
\begin{proof}
The proof is simple a induction on $\vdash_{\Theta_0}\Delta$ and using the External Type Preservation Theorem. (Not shown)
\end{proof}

\begin{lemma}[Type Declaration]
If $\vdash_{\Theta_0}^{\Delta}\theta\sim\Theta$ then $\vdash\Theta_0\Theta$.
\end{lemma}
\begin{proof}
By induction on the formation of $\Theta$, we have the following three cases:
\begin{itemize}
\item $\vdash_{\Theta}\emptyset\sim\emptyset \Longrightarrow \vdash{\emptyset}$.
\item ${\vdash^{\Delta}_{\Theta}} \theta';T[\mathbf{explicit},\tau,e_m,\kappa] \sim \Theta',T[\tau,i_m:\tau_m,\dot\kappa] \Longrightarrow \vdash_{\Theta}\Theta',T[\tau,i_m:\tau_m,\dot{\kappa}]$. 

By induction, we have $\vdash_{\Theta}\Theta'$. And by the rule (ctx-explicit-type), we have $\vdash_{\Theta\Theta',T[?,?,?]}^{\Delta}\tau, \myvdash\dot\kappa$ and $\emptyset\vdash_{\Theta\Theta',T[\tau,?,?]}^{\Delta}e\rightsquigarrow i_m\Rightarrow\tau_m$. With External Type Preservation Lemma, we have $\vdash_{\Theta}\Theta',T[\tau,i_m:\tau_m,\dot{\kappa}]$.
\item $\myvdash \theta';T[\mathbf{tykw},k,body,e_m,\kappa] \sim \Theta',T[\tau,i''_m:\tau'_m,\dot{\kappa}\dot{\kappa}'] \Longrightarrow \vdash_{\Theta}\Theta',T[\tau,i''_m:\tau'_m,\dot{\kappa}\dot{\kappa}'].$

By induction, we have $\myvdash\Theta'$. And by rule (ctx-typekw-type), we have (1) $\vdash_{\Theta\Theta',T[?,?,?]}^{\Delta}\tau$. (2).$\dot\kappa\dot\kappa'$ is well formed the the fact that $\myvdash \dot\kappa$~~~~ $\vdash^{\Delta}_{\Theta\Theta',T[\tau,i'_m:\tau'_m,?]}\kappa\rightsquigarrow\dot{\kappa}'$ ~~~~ $dom(\dot{\kappa})\cap dom(\dot{\kappa}')=\emptyset$. (3) $i''_m:\tau'_m$ is well formed by the formation of $i'_m$ and the application of $i'_m$ on $i_m$. Thus we have the formation of the \textbf{tykw} construction.
\end{itemize}
With the three cases proved, we have the formation of type declaration proved.
\end{proof}

%\input{kw-contextformation.tex}

% end the environment with {table*}, NOTE not {table}!
\section{Related Work}\label{related}
\section{Conclusions}
This paragraph will end the body of this sample document.
Remember that you might still have Acknowledgments or
Appendices; brief samples of these
follow.  There is still the Bibliography to deal with; and
we will make a disclaimer about that here: with the exception
of the reference to the \LaTeX\ book, the citations in
this paper are to articles which have nothing to
do with the present subject and are used as
examples only.
%\end{document}  % This is where a 'short' article might terminate

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
This section is optional; it is a location for you
to acknowledge grants, funding, editing assistance and
what have you.  In the present case, for example, the
authors would like to thank Gerald Murray of ACM for
his help in codifying this \textit{Author's Guide}
and the \textbf{.cls} and \textbf{.tex} files that it describes.

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{../ecoop14/research}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
\end{document}