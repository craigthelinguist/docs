\documentclass{sig-alternate}[10pt]
  \pdfpagewidth=8.5truein
  \pdfpageheight=11truein

\usepackage{epstopdf}
\usepackage{bussproofs}
\usepackage[usenames,dvipsnames]{color} % Required for specifying custom colors and referring to colors by name
\usepackage{listings}
\usepackage{xcolor}
\usepackage{verbatim}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{array}
\usepackage{parcolumns}
\usepackage{stackengine}
\usepackage{enumitem}
\EnableBpAbbreviations
\input{macros.tex}
\usepackage[english]{babel}


\newcommand\BeraMonottfamily{%
  \def\fvm@Scale{0.85}% scales the font down
  \fontfamily{fvm}\selectfont% selects the Bera Mono font
}

\lstdefinestyle{wyvern}{
%backgroundcolor=\color{highlight}, % Set the background color for the snippet - useful for highlighting
basicstyle=\scriptsize\BeraMonottfamily, % The default font size and style of the code
breakatwhitespace=false, % If true, only allows line breaks at white space
breaklines=true, % Automatic line breaking (prevents code from protruding outside the box)
captionpos=b, % Sets the caption position: b for bottom; t for top
morecomment=[s]{(*}{*)},
commentstyle=\fontshape{it}\color{Gray}\selectfont, % Style of comments within the code - dark green courier font
deletekeywords={}, % If you want to delete any keywords from the current language separate them by commas
%escapeinside={\%}, % This allows you to escape to LaTeX using the character in the bracket
firstnumber=1, % Line numbers begin at line 1
frame=lines, % Frame around the code box, value can be: none, leftline, topline, bottomline, lines, single, shadowbox
frameround=tttt, % Rounds the corners of the frame for the top left, top right, bottom left and bottom right positions
keywords=[1]{new, objtype, type, casetype, val, def, metadata, syntax, of, fn, typekw, with, let, tyfn, for, decltype},
keywordstyle={[1]\bfseries},
keywordstyle={[3]\color{red!80!orange}},
morekeywords={}, % Add any functions no included by default here separated by commas
numbers=left, % Location of line numbers, can take the values of: none, left, right
numbersep=3px, % Distance of line numbers from the code box
xleftmargin=12px,
framexleftmargin=10px,
numberstyle=\tiny\color{Gray}, % Style used for line numbers
rulecolor=\color{black}, % Frame border color
showstringspaces=false, % Don't put marks in string spaces
showtabs=false, % Display tabs in the code as lines
stepnumber=1, % The step distance between line numbers, i.e. how often will lines be numbered
tabsize=4, % Number of spaces per tab in the code
}

\lstdefinestyle{tempwyvern}{
basicstyle=\scriptsize\BeraMonottfamily, % The default font size and style of the code
breakatwhitespace=false, % If true, only allows line breaks at white space
breaklines=true, % Automatic line breaking (prevents code from protruding outside the box)
captionpos=b, % Sets the caption position: b for bottom; t for top
morecomment=[s]{(*}{*)},
commentstyle=\fontshape{it}\color{Gray}\selectfont, % Style of comments within the code - dark green courier font
deletekeywords={}, % If you want to delete any keywords from the current language separate them by commas
%escapeinside={\%}, % This allows you to escape to LaTeX using the character in the bracket
firstnumber=1, % Line numbers begin at line 1
frame=lines, % Frame around the code box, value can be: none, leftline, topline, bottomline, lines, single, shadowbox
frameround=tttt, % Rounds the corners of the frame for the top left, top right, bottom left and bottom right positions
keywords=[1]{new, objtype, type, casetype, val, def, metadata, expkw, of, fn, with, typekw, let},
keywordstyle={[1]\bfseries},
keywordstyle={[3]\color{red!80!orange}},
morekeywords={}, % Add any functions no included by default here separated by commas
numbers=left, % Location of line numbers, can take the values of: none, left, right
numbersep=8pt, % Distance of line numbers from the code box
numberstyle=\tiny\color{Gray}, % Style used for line numbers
rulecolor=\color{black}, % Frame border color
showstringspaces=false, % Don't put marks in string spaces
showtabs=false, % Display tabs in the code as lines
tabsize=4, % Number of spaces per tab in the code
}
\lstset{basicstyle=\footnotesize,breaklines=true}
\lstset{escapeinside={@}{@}}



\newcommand{\blackcolor}[1]{\textcolor[HTML]{000000}{#1}}

\newcommand{\htmlcolor}[1]{\textcolor[HTML]{339933}{#1}}
\newcommand{\expkwparsercolor}[1]{\textcolor[HTML]{336699}{#1}}
\newcommand{\typekwparsercolor}[1]{\textcolor[HTML]{7C803E}{#1}}
\newcommand{\urlcolor}[1]{\textcolor[HTML]{FFCC33}{#1}}
\newcommand{\expcolor}[1]{\textcolor[HTML]{FF0033}{#1}}
\newcommand{\membercolor}[1]{\textcolor[HTML]{FF6600}{#1}}
\newcommand{\typecolor}[1]{\textcolor[HTML]{660066}{#1}}
\newcommand{\dbcolor}[1]{\textcolor[HTML]{2F276F}{#1}}
\newcommand{\hastslcolor}[1]{\textcolor[HTML]{002FC9}{#1}}
\newcommand{\simpleHTMLcolor}[1]{\textcolor[HTML]{7D5100}{#1}}
\newcommand{\boolIfcolor}[1]{\textcolor[HTML]{CD7300}{#1}}
\newcommand{\dbshcemacolor}[1]{\textcolor[HTML]{5AC3D1}{#1}}
\newcommand{\doublebox}[2]{\begin{flushleft}\fbox{{#1}}\ \fbox{{#2}}\end{flushleft}}

\newcommand{\flyingbox}[1]{\fbox{{#1}}}
\newcommand{\myvdash}{\vdash_{\Theta}^{\Psi}}
\newcommand{\textcd}[1]{\textbf{\scriptsize\BeraMonottfamily{#1}}}
\newcommand{\textsp}[1]{\text{\footnotesize\BeraMonottfamily{#1}}}
\newcommand{\mycaption}[1]{\vspace{-10px}\caption{#1}\vspace{-8px}}
\newcommand{\tabularspace}{~~}
\newcommand{\tsm}{s}
\newcommand{\T}{\mathtt{T}}

\newfont{\mycrnotice}{ptmr8t at 7pt}
\newfont{\myconfname}{ptmri8t at 7pt}
\let\crnotice\mycrnotice%
\let\confname\myconfname%
\newcommand{\lstinlinew}[1]{\lstinline[style=wyvern]{#1}}
%\newcommand{\lstinlinew}[1]{{\scriptsize\BeraMonottfamily #1}}
\newcommand{\subparagraph}{}
\usepackage[compact]{titlesec}
\titlespacing{\section}{0pt}{*2}{*0.6}
%\titleformat{\section}
%  {\large\bfseries\uppercase}{\thesection}{1em}{}

\titlespacing{\subsection}{2pt}{*2}{*1}
\titlespacing{\subsubsection}{2pt}{*2}{*1}



\begin{document}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{property}{Property}
%
% --- Author Metadata here ---
\toappear{\the\boilerplate\par
{\confname{\the\conf}} \the\confinfo\par \the\copyrightetc}
\permission{Permission to make digital or hard copies of all or part of
this work for personal or classroom use is granted without fee provided 
that copies are not made or distributed for profit or commercial advantage 
and that copies bear this notice and the full citation on the first page. 
Copyrights for components of this work owned by others than the author(s) 
must be honored. Abstracting with credit is permitted. To copy otherwise, 
or republish, to post on servers or to redistribute to lists, requires 
prior specific permission and/or a fee. Request permissions from 
Permissions@acm.org.}
\conferenceinfo{SAC}{'15 April 13 - 17 2015, Salamanca, Spain\\
{\mycrnotice{Copyright is held by the owner/author(s). Publication rights 
licensed to ACM.}}}
\copyrightetc{ACM \the\acmcopyr}
\CopyrightYear{2015} % Allows default copyright year (2002) to be over-ridden - IF NEED BE.
\crdata{978-1-4503-3196-8/15/04 ...\$15.00.\\
http://dx.doi.org/10.1145/2695664.2695936}  % Allows default copyright data (X-XXXXX-XX-X/XX/XX) to be over-ridden.
% --- End of Author Metadata ---

\title{Composable and Hygienic Typed Syntax Macros\titlenote{This paper uses {\color{red} color} for clarity of exposition.}}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{1} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
%% 1st. author
\alignauthor
Cyrus Omar ~~~~~~~~ Chenglong Wang ~~~~~~~~ Jonathan Aldrich \\ Carnegie Mellon University \\ \email{\{comar, stwong, aldrich\}@cs.cmu.edu}
% 2nd. author
}
%\and  % use '\and' if you need 'another row' of author names

% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
\noindent Syntax extension mechanisms are powerful, but reasoning about syntax extensions can be difficult. Recent work on \emph{type-specific languages (TSLs)} addressed reasoning about composition, hygiene and typing for extensions introducing new  literal forms. We supplement TSLs with \emph{typed syntax macros (TSMs)}, which, unlike TSLs, are explicitly invoked to give meaning to  delimited segments of arbitrary syntax. To maintain a typing discipline, we describe two flavors of term-level TSMs: synthetic TSMs specify the type of term that they generate, while analytic TSMs can generate terms of arbitrary type, but can only be used in positions where the type is otherwise known. At the level of types, we describe a third flavor of TSM that generates a type of a specified kind along with its TSL and show interesting use cases where the two mechanisms operate in concert. % We specify these mechanisms by building on  the bidirectionally typed elaboration semantics previously given for TSLs. %Taken together, TSLs and TSMs provide significant expressive power and strong reasoning principles.
\end{abstract}
% A category with the (minimum) three required fields
\vspace{-5px}\category{\noindent D.3.2}{Programming Languages}{Language Classifications}[Extensible languages]
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]
%\terms{Delphi theory}
\vspace{-10px}\keywords{\noindent\vspace{-2px}extensible syntax; macros; hygiene; type inference}

\titleformat{\section}
 {\secfnt}{\thesection.}{1em}{\secfnt\MakeUppercase}

\section{Introduction}
\label{sec-intro}
One way programming languages evolve is by introducing \emph{syntactic sugar} that captures common idioms more concisely and naturally. In most contemporary languages, this is the  responsibility of the language designer. Unfortunately, the designers of general-purpose languages do not have strong incentives to capture idioms that arise only situationally, motivating research into mechanisms that allow the users of a language to extend it with new syntactic sugar themselves.%, freeing designers from this responsibility.%, to varying degrees. 

Designing a useful syntax extension mechanism is non-trivial because the designer can no longer  comprehensively check that parsing ambiguities cannot arise and that desugarings are semantically well-behaved. Instead, the extension mechanism must provide several key guarantees:


\textbf{Composability} The mechanism cannot simply allow the base language's syntax to  be modified arbitrarily due to the potential for parsing ambiguities, both due to conflicts with the base language and, critically, between extensions (e.g. extensions adding support for XML and HTML).% To avoid this issue, extensions must be kept delimited from the base language and from one another. 


\textbf{Hygiene} The desugaring logic associated with new forms must be constrained to ensure that the meaning of a valid program cannot change simply because some of the variables have been uniformly renamed (manually, or by a refactoring tool). It should also be straightforward to identify the binding site of a variable, even with intervening uses of sugar. These two situations correspond to inadvertent variable capture and shadowing by the desugaring. 


\textbf{Typing Discipline} In a rich statically typed language, which will be our focus in this work,  determining the type a sugared term will have, and analagously the \emph{kind} a type will have (discussed further below), should be possible without requiring that the desugaring be performed, to aid both the programmer and tools like type-aware code editors. 

Most prior approaches to syntax extension, discussed in Sec. \ref{related}, fail to simultaneously provide all of these guarantees. Recent work on \emph{type-specific languages  (TSLs)} makes these guarantees, but in a limited setting: library providers can define new literal syntax by associating parsing and desugaring logic with type declarations \cite{TSLs}. Local type inference, specified as a bidirectional type system \cite{Pierce:2000:LTI:345099.345100}, controls which such TSL is used to parse  the  bodies of literal forms. The available delimiters are fixed by the language, but the bodies of literal forms can be arbitrary, so TSLs are flexible, and this approach guarantees composability and maintains the typing discipline by construction. The semantics given also guarantees hygiene. We will review in Sec. \ref{background}. 

While many forms of syntactic sugar can be realized as TSLs, there remain situations where TSLs do not suffice: 
\begin{enumerate}[noitemsep]
\item[(i)] Only a single TSL can be associated with a type, and only when it is declared, so alternate syntactic choices, or syntax for a type not under a user's control, cannot be defined.
\item[(ii)] Syntax cannot be associated with types that are not identified nominally (e.g. arrow types).
\item[(iii)] Idioms other than those that arise when introducing a value of a type (e.g. those related to control flow or API protocols) cannot be captured
\item[(iv)] Types cannot themselves be declared using specialized syntax. 
\end{enumerate}

%\vspace{5px}
\noindent\textbf{\textit{Contributions}} In this paper, we introduce \emph{typed syntax macros (TSMs)}, which supplement TSLs to handle these scenarios while maintaining the crucial guarantees above. 

Our specific contributions are as follows:% A TSM is invoked explicitly but otherwise benefits from the same mechanisms developed for TSLs. 
\begin{enumerate}[noitemsep]
\item We introduce TSMs first at the term level in Sec. \ref{tsms-term}.  To maintain a typing discipline, there are two flavors of term-level TSMs: \emph{synthetic TSMs} can be used anywhere, while \emph{analytic TSMs} can only be used where the expected type of the term is otherwise known. 
\item We next turn to type declarations  in Sec. \ref{tsms-type}. Type-level TSMs generate both a type of a specified \emph{kind}, maintaining the \emph{kinding discipline} that governs type parameter application, and also the TSL associated with it, so TSLs and TSMs can operate in concert. %In doing so, we also extend the work on TSLs to handle parameterized types. % as we will demonstrate. 
%\item In Sec. \ref{theory}, we very briefly outline a type-theoretic account of TSMs by extending the bidirectionally typed elaboration semantics for TSLs given previously by Omar et al. \cite{TSLs}, leveraging essentially the same underlying language and hygiene mechanism at the term level and introducing an analagous type-level hygiene mechanism. % (emphasizing the cohesion of these mechanisms). %   mechanism to support efforts to  decentralize control over the concrete syntax of a typed programming language. 
\item Both TSLs and TSMs leverage lightweight delimiters to separate syntax extensions from the host language. We supplement the delimited forms previously defined to support additional idioms.
\end{enumerate}

We more specifically compare our work to related work in Sec. \ref{related} and conclude in Sec. \ref{conclusion}. A more detailed type-theoretic treatment of these mechanisms is available in an accompanying technical report \cite{sac15tr}.

\section{Background}\label{background}
\subsection{Wyvern}

\begin{figure}[t!]
\begin{lstlisting}[style=wyvern]
casetype @\htmlcolor{HTML}@
  Empty
  Seq of HTML * HTML 
  Text of String
  BodyElement of Attributes * HTML
  H1Element of Attributes * HTML
  StyleElement  of Attributes * CSS
  (* ... *)
  syntax = ~ (* : Parser(Exp) *)
    @\expkwparsercolor{start <- '<body' attributes '>' start '</body>'}@
      fn atts, child => '@\expcolor{BodyElement((\$}@atts@\expcolor{, \$}@child@\expcolor{))}@'
    @\expkwparsercolor{start <- '<(' EXP ')>'}@
      fn e => e
    (* ... *)

let heading : HTML = H1Element({}, Text("My Heading"))
serve(~) (* serve : HTML -> Unit *)
  @\htmlcolor{<body id="doc1">}@
    @\htmlcolor{<(}@heading@\htmlcolor{)>}@
    @\htmlcolor{<p>My first paragraph.</p>}@
  @\htmlcolor{</body>}@
\end{lstlisting}
\mycaption{A case type with an associated TSL.}
\label{f-htmltype}
\end{figure}
We will present TSMs in the context of the simple variant of the Wyvern programming language introduced previously to describe TSLs  \cite{TSLs}, making only minor changes that we will note as they come up. Wyvern is a statically typed  language with features from both the functional and object-oriented traditions and has a layout-sensitive syntax. 

An example of a type encoding the tree structure of HTML is declared in Figure \ref{f-htmltype}. The type \lstinlinew{HTML} is a \emph{case type}, with cases for each HTML tag and additional cases for an empty document, a sequence of nodes and a text node. Case types are similar to datatypes in an ML-like language (in type-theoretic terms, recursive labeled sum types). 
We introduce a value of type \lstinlinew{HTML} on line 17 by naming a case and providing an argument of the type the case declares.

Wyvern also supports declaring object types, e.g. \lstinlinew{Parser} in Figure \ref{exp-prelude} (discussed below). Object types declare fields and methods via \texttt{val} and \texttt{def}, respectively. Values of object type are introduced with \lstinlinew{new}, which  is a  \emph{syntactic forward reference}: it can appear once per line, at the term position where an object is needed. The next indented block gives the field values and method implementations (Figure \ref{typekw-example-2} shows some examples). Objects are similar to functional records. %We will see an example below.

We assume standard types like \lstinlinew{String}, \lstinlinew{List} and \lstinlinew{Option} are ambiently available in a \emph{prelude}. Types declarations are \emph{generative}, i.e. declared types are identified nominally (like datatypes in ML, or classes in Java). Declarations can also include type parameters, e.g. \lstinlinew{List} would declare one type parameter. To be more precise, we say that \lstinlinew{List} is a \emph{type constructor}, in that applying \lstinlinew{List} to a type produces a particular list type, e.g. \lstinlinew{List(String)}. Types have \emph{kind} \lstinlinew{Ty}, while {type constructors} have arrow kind, e.g. \lstinlinew{List} has kind \lstinlinew{Ty -> Ty}. For concision, we use the phrase \emph{declared type} for names having any kind. 


Some types are identified structurally, e.g. tuple types like \lstinlinew{HTML * HTML} and function types like \lstinlinew{HTML -> Unit}. When object and case types are written anonymously, rather than via a declaration, they are also identified structurally. %Only declared types can be recursive.

\begin{figure}[t!]
\begin{lstlisting}[style=wyvern]
objtype @\expkwparsercolor{Parser}@(T)
  def parse(ParseStream) : Result(T)
  syntax = (* ... parser generator syntax ... *)

casetype Result(T)
  OK of T
  Error of String * Location

casetype @\expcolor{Exp}@
  Var of ID
  Fn of ID * Exp
  Ap of Exp * Exp
  Ascription of Exp * Type
  CaseIntro of ID * Exp
  (* ... *)
  Spliced of ParseStream (* see Sec. 3.3 *)
  syntax = (* ... exp quasiquotes ... *)

casetype @\typecolor{Type}@
  Declared of ID
  Objtype of List(MemberDecl)
  Casetype of List(CaseDecl)
  Arrow of Type * Type
  (* ... *)
  TyVar of ID (* see Sec. 4.1 *)
  TyFn of ID * Type
  TyAp of Type * Type
  Spliced of ParseStream (* see Sec. 4.2 *)
  syntax = (* ... type quasiquotes ... *)
\end{lstlisting}
\mycaption{A portion of the Wyvern prelude relevant to TSLs and TSMs.}
\label{exp-prelude}
\end{figure}


%Declared types can also be equipped with \emph{metadata}, which is a value constructed at compile time and available for use by the language itself (in particular, the TSL mechanism) as well as tools. Metadata is analagous to class annotations in Java, but in Wyvern, it can be any value. % Here, we will use metadata to associate a TSL with \lstinlinew{HTML}. 

\subsection{Type-Specific Languages (TSLs)}



Introducing a value of type \lstinlinew{HTML} using general-purpose syntax like that shown on line 17 of Figure \ref{f-htmltype} can be tedious. Moreover, there is standard concrete syntax for HTML that might be preferable for reasons of familiarity or backwards compatibility. To allow for this, we associate a \emph{type-specific language} with the \lstinlinew{HTML} type. %Both are declared  in Figure \ref{exp-prelude}.
 %We omit the implementation of the \lstinlinew{HTML} type's TSL \lstinlinew{parse} method here for concision. 
We see this TSL being used on lines 18-22 of Figure \ref{f-htmltype}. On line 18, we  call the function \lstinlinew{serve}, which we assume has type \lstinlinew{HTML -> Unit}. Rather than explicitly constructing a term of type \lstinlinew{HTML} as the argument, we use the \emph{forward referenced literal form} \lstinline[style=wyvern]{~}. The \emph{body} of the literal consists of the text in the indented block beginning on the next line, stripped of the leading indentation. In effect, whitespace is serving as a delimiter. 

We could equivalently have used other \emph{inline delimiters}, e.g. curly braces or single quotes, though we would then need to follow the restrictions described in Figure \ref{f-delimited}. For example, we could have written line 17 equivalently as:
\vspace{-3px}\begin{lstlisting}[style=wyvern, numbers=none, frame=none]
  val heading : HTML = '@\htmlcolor{<h1>My Heading</h1>}@'
\end{lstlisting}\vspace{-5px}

The first phase of parsing leaves the bodies of such delimited forms unparsed. They are parsed and elaborated during typechecking. More specifically, when the semantics encounters any such literal form, the syntax associated with the declared type that the literal is being analyzed against, here \lstinlinew{HTML}, is used to desugar it before continuing.

\begin{figure}[t]
\begin{lstlisting}[style=wyvern,numbers=none,xleftmargin=0px,framexleftmargin=0px]
'@\htmlcolor{body here, '{}'inner single quotes'{}' must be doubled}@'
[@\htmlcolor{body here, [inner braces] must be balanced}@]
{@\htmlcolor{body here, \{inner curly braces\} must be balanced}@}
~ (* can appear at any expression position *)
  @\htmlcolor{forward referenced body here, leading indent stripped}@
(parentheses_delimit_spliced_terms_in_TSM_arguments(~)) 
  @\htmlcolor{so forward references can propagate out}@
[@\htmlcolor{adjacent}@] {@\htmlcolor{delimited forms}@} @\htmlcolor{or}@ [@\htmlcolor{those}@] @\htmlcolor{separated}@ ~ @\htmlcolor{form}@
  @\htmlcolor{by identifiers create a single multipart delimited}@
\end{lstlisting}
\mycaption{Available delimited forms in Wyvern. The parentheses and multipart delimited forms are novel, discussed in Sec. \ref{tsms-term}.}
\label{f-delimited}
\end{figure}

Such syntax is associated with a declared type as seen on lines 9-14 of Figure \ref{f-htmltype} by writing \lstinline[style=wyvern]{syntax = e}, where \lstinlinew{e} is a parser of type \lstinlinew{Parser(Exp)}.\footnote{ In \cite{TSLs}, we gave a more general \emph{metadata}-based mechanism, but we give a simpler TSL-specific mechanism here.}\textsuperscript{,}\footnote{ For expository purposes, we include type ascriptions that are not strictly needed in comments throughout the paper.} Per  Figure \ref{exp-prelude}, a parser defines a \lstinlinew{parse} function that transforms a \lstinlinew{ParseStream} based on the body to a \lstinlinew{Result(Exp)}, which is either a desugaring, encoded as a value of type \lstinlinew{Exp}, or an indication of a parse error. Rather than writing a \lstinlinew{parse} function explicitly, we make use of the fact that \lstinlinew{Parser} itself has a TSL associated with it providing a static \emph{grammar-based parser generator}. This allows us to create a \lstinlinew{Parser(Exp)} by specifying a number of productions each of which is followed by a Wyvern function taking in the elaborations of each constituent non-terminal and producing the final elaboration of type \lstinlinew{Exp}. The non-terminal \lstinlinew{start} serves as the starting non-terminal. 

The types \lstinlinew{Exp} and \lstinlinew{Type} encode the abstract syntax of Wyvern terms and types, respectively. To make code generation more straightforward, these types are equipped with TSLs that provide \emph{quasiquotation}  \cite{quine40book,Bawd99a,ScalaMacros2013}: terms of these types  can be written using Wyvern's usual concrete syntax, extended with unquote forms \lstinlinew{\$x} and \lstinlinew{\$(e)}, which splice in variable \lstinlinew{x} and  term \lstinlinew{e}, respectively. %We refer to \cite{TSLs} for further details on these two modes of use.


Splicing can be supported by any TSL. For example, the TSL for \lstinlinew{HTML} uses the delimiters \lstinlinew{<(} and \lstinlinew{)>} to mean ``splice in the enclosed term  of type \lstinlinew{HTML} here'', as seen on line 19 of Figure \ref{f-htmltype}. This is supported because a parser can request that some portion of the parse stream be treated as a host language term, type or variable. The cases \lstinlinew{Spliced} in \lstinlinew{Exp} and \lstinlinew{Type} track these spliced portions of the parse stream. This is the basis of the hygiene mechanism in \cite{TSLs}. The parser generator provides the non-terminals \lstinlinew{EXP}, \lstinlinew{ID} and \lstinlinew{TYPE}, which generate these spliced forms internally. For example, \lstinlinew{EXP} is used on line 13 of Figure \ref{f-htmltype} to implement HTML splicing.%The hygiene mechanism for TSLs ensures that only spliced terms can refer to variables in the surrounding scope. New variables cannot be introduced into their scope (functions must be used to communicate between TSLs and the host language), so that binding sites are easy to determine. We will return to splicing in Sec. \ref{theory}. 

For expository purposes, we color the bodies of delimited forms a color corresponding to the TSL or TSM being used, identified when declared. Base language terms, including spliced base terms, are colored black. 

\section{Term-Level TSM\lowercase{s}}\label{tsms-term}
Having introduced the necessary background, we will now describe term-level typed syntax macros  and illustrate their use in situations where TSLs are not suitable. %We follow up with a more formal treatment in Sec. \ref{theory}. 

%Term-level TSMs come in two flavors: \emph{synthetic TSMs} specify the type of term they will elaborate to, meaning they can be used anywhere, while \emph{analytic TSMs} can elaborate to a term of any type, but to maintain the typing discipline, they can only be used in positions where the type can otherwise be determined. 

\subsection{Synthetic TSMs}

\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
syntax @\simpleHTMLcolor{simpleHTML}@ for HTML = ~ (* : Parser(Exp) *)
  @\expkwparsercolor{start <- '>body'= attributes> start>}@
    fn atts, child => '@\expcolor{BodyElement((\$}@atts@\expcolor{, \$}@child@\expcolor{))}@'
  @\expkwparsercolor{start <- '<'= EXP>}@
    fn e => e
  (* ... *)
let heading = simpleHTML '@\simpleHTMLcolor{>h1 My Heading}@'
serve(simpleHTML ~)
  @\simpleHTMLcolor{>body[id="doc1"]}@
    @\simpleHTMLcolor{<}@ heading
    @\simpleHTMLcolor{>p My first paragraph}@
\end{lstlisting}
\mycaption{A synthetic TSM providing alternative syntax for the \texttt{HTML} type in Figure \ref{f-htmltype}.}
\label{f-simplehtml}
\end{figure}
TSMs are defined using the \lstinlinew{syntax} keyword. Figure \ref{f-simplehtml} shows a synthetic TSM, \lstinlinew{simpleHTML}, being defined and used. This TSM defines an alternative layout-sensitive syntax for HTML. The clause \lstinlinew{for HTML} indicates that valid invocations of the TSM will necessarily elaborate to a term of type \lstinlinew{HTML}. 

Like defining a TSL, defining a TSM requires defining a parser, i.e. a statically evaluated value of type \lstinlinew{Parser(Exp)}. We again do so using the parser generator associated with \lstinlinew{Parser}. In this case, we take advantage of its support for \emph{Adams grammars}, which allow declarative specifications of layout-sensitive grammars using \emph{layout constraints} within productions \cite{Adams:2013:PPI:2429069.2429129}. Here, the suffix \lstinlinew{=} indicates that the left-most column (on any line) occupied by the annotated terminal or non-terminal must occur at the same column as the parent  and \lstinlinew{>} indicates that it must be further indented. %More detail on Adams grammars and this syntax for HTML can be found in \cite{TSLs}. 

Whereas TSLs are invoked implicitly based on local type inference, invoking a TSM is similar to function application: the name of the TSL is followed by a delimited form from Figure \ref{f-delimited}. The body of the delimited form is parsed and elaborated by the parser the TSM defines. %Note that we do not here address namespacing issues, as standard techniques can be used (e.g. using URIs as in Java). 
For example, we use single quotes on line 7 of Figure \ref{f-simplehtml}. Notice that we did not need a type annotation on \lstinlinew{heading}. %% because \lstinlinew{simpleHTML}  is synthetic, i.e. it declares a type.
 On lines 8-11, we again invoke \lstinlinew{simpleHTML}, this time using the same forward referenced delimited form described above. Lines 16-21 of Figure \ref{f-htmltype} are semantically equivalent to lines 7-11 of Figure \ref{f-simplehtml}, differing only syntactically.

 Synthetic TSMs address issue (i) from Sec. \ref{sec-intro}: modularly and composably defining more than one choice of syntax for a type that either has a TSL  already, or a type which a user cannot modify. Compared to the alternative solution of defining a type \lstinlinew{HTML2} with a TSL that has the desired syntax, and a function mapping from \lstinlinew{HTML2} to \lstinlinew{HTML},  TSMs avoid declaration duplication and  the $\mathcal{O}(n)$ runtime overhead of applying the mapping. %TSMs, like TSLs, perform their desugaring at compile-time.

Synthetic TSMs also address issue (ii) because they can define syntax for types identified structurally (e.g. functions, pairs and anonymous objects), not just nominally.

% (because it appears in an external library). 

%An expression keyword is a keyword associated with a parser to transform DSL literals into a Wyvern expression. Depending on whether a return type is provided in the keyword declaration, expression keywords can be further divided into black-box keyword and white-box keyword (This terminology is borrowed from Scala's macro system). 



\subsection{Analytic TSMs}
TSLs and synthetic TSMs are not suitable for expressing idioms that are valid at many types, i.e. issue (iii) from Sec. \ref{sec-intro}. As perhaps the simplest example, consider the case type encoding booleans declared in Figure \ref{if-example}. Explicit case analysis on booleans is considered unnecessarily verbose, so many languages defining booleans in this manner build in an \lstinlinew{if} construct as a desugaring. Rather than having to build this in to Wyvern, however, we can express it as an analytic TSM, on lines 4-9. These are distinguished from synthetic TSMs in that they don't declare a type, here because the type of an \lstinlinew{if} expression is determined by its branches. 

We see \lstinlinew{if} being used on lines 10-12 of Figure \ref{if-example} with a \emph{multipart delimited form}. Each \emph{part} can be either a single delimited form (e.g. the guard and the two branches) or one or more intervening identifiers (e.g. \lstinlinew{else}). The body is generated by concatenating the bodies of the parts and inserting between them a special boundary character outside the normal character set. We call this character \lstinlinew{BOUNDARY} in our parser generator (line 5). Intervening identifiers can be thought of as having implicit delimiters around them, e.g. \lstinlinew{if [e1] else [e2]} and \lstinlinew{if [e1] [else] [e2]} express the same body, \texttt{e1}$\cdot$\lstinlinew{else}$\cdot$\lstinlinew{e2}, where $\cdot$ is the boundary character.

For the branches in our example, we used parentheses-delimited parts. In a TSM application, this means that the part consists of a single spliced term and no other syntax. Because the parser can assume this, forward references can be identified prior to typechecking and thus be allowed to escape, as we see in the ``then'' branch in our example: the body is on the next line. Had we used, for example, square brackets, then we would need to write the example like this:


\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
casetype Bool
  True
  False
syntax @\boolIfcolor{if}@ = ~ (* : Parser(Exp) *)
  @\expkwparsercolor{EXP BOUNDARY EXP BOUNDARY `else' BOUNDARY EXP}@
    fn guard, branch1, branch2 => ~ (* : Exp *)
      @\expcolor{case \$}@guard
        @\expcolor{True => \$}@branch1
        @\expcolor{False => \$}@branch2
def testIf(ok : Bool) : HTML
  if (ok) (simpleHTML ~) @\boolIfcolor{else }@('@\htmlcolor{<h1>Not OK!</h1>}@')
    @\simpleHTMLcolor{>h1 Everything is OK!}@
\end{lstlisting}
\mycaption{An analytic TSM providing a conventional syntax for \texttt{if} based on case analysis. Lines 11-12 demonstrate multipart delimited forms.}
\label{if-example}
\end{figure}
\begin{lstlisting}[style=wyvern,numbers=none,frame=none]
def testIf2(ok : Bool) : HTML
  if (ok) [simpleHTML ~
    @\simpleHTMLcolor{>h1 Everything is OK!}@
  ] @\boolIfcolor{else}@ ['@\htmlcolor{<h1>Not OK!</h1>}@']
\end{lstlisting}

An analytic TSM can only be used in a position where the type is otherwise known, e.g. on line 10 due to the return type annotation. This is to maintain the typing discipline: we do not need to expand the TSM to know what type it will have, just as with synthetic TSMs and TSLs. 

Although we believe this trade-off is worthwhile, another point in the design space is to permit a special signifier that can be used to explicitly allow analytic TSMs to be used in synthetic positions. For example, we might permit a post-fix asterisk, \lstinlinew{if*}. The type the term will have then requires a deeper understanding of the TSM in question (e.g. by knowing how it elaborates, or based on a ``derived'' typing rule that the providers of \lstinlinew{if} assert or prove \cite{conf/icfp/LorenzenE13}).

\subsection{Hygiene}
The hygiene mechanism for term-level TSMs is identical to that for TSLs. The details are in \cite{TSLs}. To summarize: spliced sub-terms are marked as such in the generated code, and only these can refer to variables in the surrounding scope. No new variables can be introduced into their scope. %The remainder of the generated term must be closed (i.e. have no free variables).

% \begin{lstlisting}[style=wyvern]
% def testIf3(ok : Bool) (* no return type annotation *)
%   if* [ok] {simpleHTML ~} @\boolIfcolor{else}@ {simpleHTML '@\simpleHTMLcolor{>h1 Not OK!}@'}
%     @\simpleHTMLcolor{>h1 Everything is OK!}@
% \end{lstlisting}

\section{Type-Level TSM\lowercase{s}}\label{tsms-type}
We now turn our attention to TSMs at the level of type declarations. Our example will be a simple object-relational mapping (ORM) syntax, shown being used in Figure \ref{f-tykwexample}. An ORM provides an object-oriented interface to a relational database, generated from a database \emph{schema}. For example, the schema in Figure \ref{f-tykwexample} specifies a table with two columns, \lstinlinew{ID} and \lstinlinew{Name}, holding values of the SQL data types \lstinlinew{int} and \lstinlinew{varchar}. The \lstinlinew{ID} column is marked with an asterisk as being a \emph{primary key}, meaning that it must be unique across rows. 

ORMs typically rely on an external code generator, which can hinder code comprehension because the fully elaborated interface is exposed directly to the programmer, obscuring the simpler schema by moving it to an external resource. By instead using the type-level TSM \lstinlinew{schema}, the interface shown in Figure \ref{typekw-example-2} is generated from the schema during compilation, using a language-integrated mechanism. More specifically, in Figure \ref{typekw-example-2} the type member \lstinlinew{Entry} declares a field for each column in the schema, with its type generated based on a mapping from SQL types to Wyvern types (not shown). Moreover, for each column \lstinlinew{C}, a method named \lstinlinew{getByC} is also generated. The return type of this method is an option type if the column is a primary key (reflecting the uniqueness invariant) or a list otherwise. There are also fields for connection parameters. 

As discussed in Section \ref{background}, declared types in Wyvern can define a TSL. A type-level TSM   generates not only a type, but also its TSL. Here, the TSL that \lstinlinew{schema} generates is shown being used on lines 5-10 of Figure \ref{typekw-example-1} to create a value of the generated type \lstinlinew{EmployeesDB}. Only the per-database parameters need to be provided. %Note that we deferrito the TSL for \lstinlinew{URL}, not shown, for that portion of the configuration, demonstrating again that composition is safe and straightforward).% The remaining details are filled in automatically.

\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
schema @\dbcolor{EmployeesDB}@
  @\dbshcemacolor{*ID   int}@
  @\dbshcemacolor{Name  varchar}@

let db : EmployeesDB = ~
  @\dbcolor{connect to}@ ~
    @\urlcolor{mysql://localhost:3306}@
  @\dbcolor{table }@   "Employees"
  @\dbcolor{username }@"user1"
  @\dbcolor{password }@"001"
db.getByID(758) (* : Option(EmployeeDB.Entry) *)
\end{lstlisting}
\mycaption{The usage of a type-level TSM and the TSL it generates to enable a simple ORM.}
\label{f-tykwexample}
\end{figure}
  

The definition of \lstinlinew{schema} is shown in Figure \ref{typekw-example-1}. Type-level TSMs must specify the \emph{kind} of type-level term that will be generated, here \lstinlinew{*} because the type takes no parameters. This is to maintain a \emph{kinding discipline}: knowing how many type parameters a type takes does not require desugaring its declaration. Elaboration is then defined by a parser of type \lstinlinew{Parser(Type*Parser(Exp))}, i.e. it must map the body, which is always forward referenced, to a pair consisting of a reified type-level term and the TSL parser. 

Here, we generate the type using type quasiquotation by mapping over the column specifications parsed out of the body on lines 37-43 (using the same color for both \lstinlinew{Type} and \lstinlinew{MemberDecl} for simplicity). We assume a mapping from SQL types to Wyvern types, \lstinlinew{ty\_from\_sqlty}, not shown. Starting on line 20, we then generate the TSL as described in Sec. \ref{background}. Note  that the implementations of the methods generated on lines 4-19 are filled in by the TSL generated on lines 20-35.

\subsection{Recursive and Parameterized Types}
In this example, there were no type parameters and the generated type was not recursive. To understand how we can generate such types, we must first break down our type declaration mechanism in a bit more detail. Recall that type declarations using \lstinlinew{casetype} or \lstinlinew{objtype} were generative. In fact, these declaration forms are (built in) syntactic sugar for the general generative type declaration form, \lstinlinew{decltype}. The right-hand side of this declaration form consists of a type level function that takes in a self-reference followed by the type parameters before producing an anonymous type on the right. For example, \lstinlinew{List} is actually declared as follows:

\begin{lstlisting}[style=wyvern, numbers=none,xleftmargin=0px,framexleftmargin=0px, frame=none]
decltype List = tyfn S::Ty->Ty => tyfn T::Ty => casetype 
  Nil
  Cons of T * S(T)
\end{lstlisting}
Note that the type-level function after the equals sign as a whole has kind \lstinlinew{(Ty -> Ty) -> (Ty -> Ty)}. More generally, for a type with $n$ type parameters, the type-level function must have kind \lstinlinew{(Ty ->}$_n$~\lstinlinew{Ty) -> (Ty ->}$_n$~\lstinlinew{ Ty)}, where the subscript $n$ indicates $n$ arguments of kind \lstinlinew{Ty}. A type-level TSM must generate such a function. On line 5 of Figure \ref{typekw-example-1}, the mechanism allowed that the self-reference be omitted because the type was not recursive, but we could have written \lstinlinew{tyfn S :: Ty => objtype}. Note that the name of the type is determined by the client of the TSM. The type variable \lstinlinew{S} here is relevant only inside the TSM definition. We discuss mutually recursive types in the  technical report \cite{sac15tr}.

\subsection{Hygiene}
The previous work on TSLs did not handle parameterized types or parametric polymorphism, so there was no notion of a type variable there. With these features included, we must also have a notion of hygiene with respect to type variables. We can take an analagous approach to the one taken for term variables, marking spliced sub-terms and giving only these access to the surrounding type variable context when kind checking the generated type. The details are in the technical report \cite{sac15tr}.

%For example, a parser generator that also generates the abstract syntax representation. Need tyfn's to represent them. Mutually recursive types taken n arguments. Then type parameters for each decalaration. For example, .... 

% The metadata mechanism in Wyvern supports more than just TSLs. For example, a documentation generator might look for a \lstinlinew{doc} field in the metadata. Our type-level TSM only generates the TSL definition. To support extending the metadata generated by a type-level TSM further after it is invoked, the mechanism supports a \emph{metadata transformation} when a type is declared using a type-level TSM:

% \begin{lstlisting}[style=wyvern]
% type EmployeesDB2 = (schema ~
%   @\dbshcemacolor{...}@
% ) metadata fn original_md (* : HasTSL *) => new
%   val parser = original_md.parser
%   val doc = "ORM for Employees table in database."
% \end{lstlisting}

% The metadata type declared by the type-level TSM determines the input type of the transformation (here, \lstinlinew{HasTSL}).

%The definition of the type keyword \lstinlinew{DBSchema} can be referred to figure \ref{typekw-example-1}. A type keyword itself is a parser for DSL literals: it is a value of type \lstinlinew{TypeParser}, which takes in a parsestream and returns a parsing result (of type \lstinlinew{Result}, which is a casetype defined in figure \ref{exp-prelude}). When there is no parsing error, a tuple \lstinlinew{(t:Type, e:Exp, k:List(KwMember))} will be returned for type construction: the type structure stored in \lstinlinew{t}, metadata in \lstinlinew{e}, and expression keywords defined by \lstinlinew{k}. \lstinlinew{DBSchema} will construct an object type with fields specified in line 5-18, and it will provide a TSL metadata for value initialization (line 20-35). The type of the metadata is provided on the first line of keyword declaration with keyword \lstinlinew{with metadata}, which is used by the type checker to analyze the metadata type.

% \begin{figure}
% \begin{lstlisting}[style=wyvern]
% type @\typekwparsercolor{TypeParser}@ = objtype
%   def parse(ps : ParseStream) : Result(Type * Exp * List(KwMember))
%   metadata : HasTSL = new 
%     val parser = (* parser generator *)

% type @\typecolor{Type}@ = casetype
%   Named of ID
%   Objtype of List(MemberDecl)
%   Casetype of List(CaseDecl)
%   Arrow of Type * Type
%   metadata : HasTSL = new
%     val parser = (* type quasiquotes *)

% type KwMember = casetype
%   Whitebox of Label * ExpKw
%   Blackbox of Label * ExpKw * Type
% \end{lstlisting}
% \mycaption{Wyvern prelude for type keywords}
% \label{type-prelude}
% \end{figure}

\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
type EmployeesDB = objtype
  type Entry = objtype
    val ID : Int
    val Name : String 
  val connection : URL
  val username : String
  val password : String
  (* ... *)
  def getByID(Int) : Option(Entry)
  def getByName(String) : List(Entry)
  syntax = (* ... generated TSL, cf Figure 8 ... *)

let db : EmployeesDB = new
  val connection = new
    val domain = "localhost"
    (* ... *)
  val username = "user1"
  val password = "001"
  (* ... *)
  def getByID(x)
    (* send appropriate query *)
db.getByID(758)
\end{lstlisting}
\mycaption{The elaboration of Figure \ref{f-tykwexample}.}
\label{typekw-example-2}
\end{figure}


\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
syntax @\dbshcemacolor{schema}@ :: Ty = ~ (*:Parser(Type*Parser(Exp))*)
  @\expkwparsercolor{start <- columns}@
    fn cols (* : List(Bool*Label*Type) *) =>
      let ty : Type = ~
        @\typecolor{objtype}@ 
          @\typecolor{type Entry = objtype}@
            @\typecolor{\$(}@
              map(cols, fn (primary, lbl, ty) => ~)
                @\typecolor{val \$}@lbl @\typecolor{:  \$}@ty
            @\typecolor{)}@
          @\typecolor{val connection : URL}@
          @\typecolor{val username : String}@
          @\typecolor{val password : String}@
          @\typecolor{(* ... *)}@
          @\typecolor{\$(}@
            map(cols, fn (primary, lbl, ty) => ~)
              @\typecolor{def getBy\$}@lbl@\typecolor{(\$}@ty@\typecolor{) : \$(}if (primary) (@
                '@\typecolor{Option(Entry)}@') @\boolIfcolor{else}@ ('@\typecolor{List(Entry)}@')@\typecolor{)}@
          @\typecolor{)}@
      let tsl : Parser(Exp) = ~ 
        @\expkwparsercolor{start <- ("connect to"= EXP>}@
                  @\expkwparsercolor{"table"= EXP>}@
                  @\expkwparsercolor{"username"= EXP>}@
                  @\expkwparsercolor{"password"= EXP>)}@
          fn url, un, pw, table => ~
            @\expcolor{new}@ 
              @\expcolor{val connection = \$}@url
              @\expcolor{val username = \$}@un
              @\expcolor{val password = \$}@pw
              @\expcolor{(* ... *)}@
              @\expcolor{\$(}@
                map(cols, fn (primary, lbl, ty) => ~)
                  @\expcolor{def getBy\$}@lbl@\expcolor{(x)}@ 
                    @\expcolor{(* send appropriate query *)}@
              @\expcolor{)}@
      (ty, tsl)
  @\expkwparsercolor{columns <- column}@
    fn column => Cons(column, Nil)
  @\expkwparsercolor{columns <- column= columns=}@
    fn column, columns => Cons(column, columns)
  @\expkwparsercolor{column <- "*"? ID ID}@
    fn primary, lbl, sqlty => 
      (primary, lbl, ty_from_sqlty(sqlty))
\end{lstlisting}
\mycaption{The definition of a type-level TSM.}
\label{typekw-example-1}
\end{figure}

% \section{Formal Syntax and Semantics}\label{theory}
% We will now give a formal type theoretic treatment of the mechanisms described thusfar, building directly upon the calculus for TSLs in Wyvern presented previously by Omar et al. \cite{TSLs}. 
% The abstract syntax corresponding to the concrete syntax we introduced above is shown in Figures \ref{formal-syntax} and \ref{syntax-types}. A \emph{program}, $\rho$, consists of a series of declarations, $ d$, followed by a single external term, $e$. In practice, the declarations would be imported from separate packages, but we omit details of the package system here for simplicity. The top-level judgement in the system is the compilation judgement:
% $$\AXC{$d\sim(\Psi;\Theta)$ ~~~~ $\emptyset;\emptyset\vdash_{\Theta_0\Theta}^{\Psi}e\rightsquigarrow i\Rightarrow \tau$}      \RightLabel{(compile)}
% \UIC{$ d;e\sim(\Psi;\Theta)\rightsquigarrow i:\tau$}
% \DP$$

% %The syntax for the contexts used in these judgements is shown in Figure \ref{typechecking-environment}. The main rules defining these judgements  are shown in Figures \ref{typechecking-elaboration} through \ref{expkw-kwstatics}. %For simplicity, we do not formalize Wyvern's mechanisms for parameterized types and type members here. 

% A series of declarations, $d$, consists of TSM declarations and named type declarations. The judgement $d \sim (\Psi, \Theta)$, defined in Figure \ref{typechecking-elaboration}, generates a corresponding TSM context, $\Psi$, and named type context, $\Theta$, from $d$. The syntax for these contexts is given in Figure \ref{typechecking-environment}. We refer to the type declarations in the prelude, some of which were shown in Fig. \ref{exp-prelude}, by using the named type context $\Theta_0$ in our rules.


% Judgements $\Delta; \Gamma \vdash_\Theta^\Phi e \leadsto i \Rightarrow \tau$ and  $\Delta; \Gamma \vdash_\Theta^\Phi e \leadsto i \Leftarrow \tau$ can be read ``under kinding context $\Delta$, typing context $\Gamma$, named type context $\Theta$ and TSM context $\Phi$, external term $e$ elaborates to internal term $i$ and (synthesizes / analyzes against) type $\tau$''. This is a \emph{bidirectionally typed elaboration semantics}, used to elaborate TSL literals and TSM applications, which appear only in the external language, to an internal language, which includes only the core operations in the language. The semantics follows that given in \cite{TSLs}, so we do not repeat the rules for the core operations or TSL literals. The rules for the only new form, $\textbf{eaptsm}[s, body]$, are given in Figure \ref{expkw-kwstatics} and described below.

% \subsection{Term-Level TSMs}

% \begin{figure}[t]
% \hspace{-5px}$\begin{array}{ll}
%       \textbf{Abstract Forms}   & \textbf{Concrete Forms}\\
%       \textsf{Programs} ~ \rho~::=~ d;e\\
%       \textsf{Declarations}~d~::= \\
%       \tabularspace \emptyset\\
%       \tabularspace d;\mathbf{syntsm}(\tsm,\tau,e)    & \textcd{syntax}~\tsm : \tau~\textcd{=}~e\\
%       \tabularspace d;\mathbf{anatsm}(\tsm,e)          & \textcd{syntax}~\tsm~\textcd{=}~e\\
%       \tabularspace d;\mathbf{tytsm}(\tsm,\kappa, \tau, e) & \textcd{syntax}~\tsm::\kappa~\textcd{with metadata:}\tau\,\textcd{=}\,e\\
%       \tabularspace d; \mathbf{tydecl}(\mathtt{T}, \tau, e)  & \textcd{type}~\mathtt{T}~\textcd{=}~\tau\\
%                                                             & ~~~\textcd{metadata = }e\\
%       \tabularspace d; \mathbf{tyaptsm}(\mathtt{T}, \tsm, body, e)   & \textcd{type}~\mathtt{T}~\textcd{=}~\tsm~dform\\
%                                                             & ~~~\textcd{metadata }e\\
% %      \text{Object Fields}\\
% %      \omega~::=~\emptyset                      \\
% %      \tabularspace l[\mathbf{val},\tau];\omega                 & \textcd{val}~l : \tau\\
% %      \tabularspace l[\mathbf{def},\tau];\omega                 & \textcd{def}~l : \tau\\
% %      \text{Casetype Cases}\\
% %      \chi~::=~\emptyset                      \\                 
% %      \tabularspace C[\tau];\chi                   & C~\textcd{of}~\tau\\
%       \textsf{External Terms}~ e~::= ...                              & \\
%       \tabularspace\mathbf{lit}[body]             & dform\\
%       \tabularspace\mathbf{eaptsm}[\tsm,body]       & \tsm~dform\\
%       ~\\
%       \multicolumn{2}{l}{\textsf{Translational Terms} ~ \hat{e}~::= ... ~|~ \mathbf{spliced}[e]} \\
%       \multicolumn{2}{l}{\textsf{Internal Terms}~i~::= ...}
%   \end{array}$
% \mycaption{Abstract and concrete forms for declarations and terms. Metavariable $\tsm$ ranges over TSM names, $\mathtt{T}$ over type names, $dform$ over delimited forms, per Figure \ref{f-delimited}, and $body$ over their bodies. Translational and internal terms are used in the semantics only. Elided forms are given in \cite{TSLs}.}
% \label{formal-syntax}
% \end{figure}

% \begin{figure}[t]
% \hspace{-5px}$\begin{array}{llcl}
%       \mathsf{Kinds} &  \kappa &::= & \star  ~|~ \kappa \rightarrow \kappa\\
%       \textsf{Types} & \tau & ::= & \mathtt{T} ~|~ \tau \rightarrow \tau ~|~ \mathbf{objtype}[\omega] ~|~ \mathbf{casetype}[\chi] \\
%       & & | & t ~|~ \lambda[\kappa](t.\tau) ~|~ \tau(\tau) \\
%       \multicolumn{4}{l}{\textsf{Translational Types} ~ \hat{\tau} ~ ::= ... ~|~ \mathbf{spliced}[\tau]}
%   \end{array}$
% \mycaption{Syntax for types and kinds. Metavariable $t$ ranges over type variables. Object type and case type declarations $\omega$ and $\chi$ are taken from \cite{TSLs}.
% %Metavariable $T$ ranges over type names, $l$ over member labels, $C$ over case names, $x$ over term variables, $X$ over type variables.
% }\label{syntax-types}
% \end{figure}
% \begin{figure}[t]
% $\begin{array}{l}
%       \textsf{TSM Contexts}\\
%       \Psi ::= \emptyset ~|~ \Psi, s[\mathbf{ty}(\kappa,\tau, i)] ~|~ \Psi, s[\mathbf{syn}(\tau,i)] ~|~ \Psi, s[\mathbf{ana}(i)]\\
%       \textsf{Named Type Contexts} ~\Theta ::= \emptyset~|~\Theta, \mathtt{T}[\tau :: \kappa,i : \tau]\\
%       \textsf{Typing Contexts}~\Gamma ::= \emptyset ~|~ \Gamma, x : \tau\\
%       \textsf{Kinding Contexts}
%       ~~\Delta ::= \emptyset ~|~ \Delta,t::\kappa
% \end{array}$
% \mycaption{Syntax for contexts.}
% \label{typechecking-environment}
% \end{figure}
% The rule (D-syntsm) shows how a synthetic TSM named $s$, synthesizing type $\tau$ and implemented by $e_{tsm}$ is declared. The rule first recursively checks the preceding declarations, then ensures that no other TSM named $s$ was declared  (we treat contexts as finite mappings and write, e.g., $\text{dom}(\Psi)$ to be the domain of $\Psi$). Then, it checks that $\tau$ is a closed type by checking that it's kind is $\star$ in an empty kinding context. Kinding contexts are simply mappings from type variables to kinds and the key kinding rules are shown in Figure \ref{kinding}. We will return to them when discussing type declarations below. Finally, $e_{tsm}$ is analyzed against  $\mathtt{Parser}(\mathtt{Exp})$, defined in the prelude. It must be a closed term, so the kinding and typing contexts are empty (it can use the named types and TSMs declared previously, however). Once these checks are complete, the definition of $s$ is added to $\Psi$. The rule for analytic TSM declarations, (D-anatsm), is nearly identical, differing only in that no kind check is needed.

% Term-level TSM application is captured by the abstract form $\textbf{eaptsm}[s, body]$, where $s$ is the name of the TSM and $body$ is the body of the delimited form, per Sec. \ref{tsms-term}. The rule (T-syn) shows how typing and elaboration for a synthetic TSM proceeds. First, the definition of $s$ is extracted from $\Psi$. Then, a parse stream is constructed on the basis of $body$. We assume the relation $\textsf{parsestream}(body)=i_{ps}$ is defined such that $i_{ps}$ is a closed term of type $\mathtt{ParseStream}$. Then, the $parse$ method of the TSM implementation is invoked with the parse stream. The judgement $i \Downarrow i'$ captures evaluation of $i$ to a value, $i'$. Our internal language is identical to that in \cite{TSLs}, so we omit the rules. As suggested by the declarations in Figure \ref{exp-prelude}, the result is either a parse error or a valid parse, written $OK(i_{exp})$, where $i_{exp}$ is a value of type $\mathtt{Exp}$. Here, we simply leave the error case undefined -- the typing judgement cannot be derived if there is a parse error.% -- though in practice, the compiler would report errors that occurred. 

% The \emph{dereification judgement} $i \uparrow \hat{e}$, defined in \cite{TSLs}, takes a value of type \lstinlinew{Exp} to a corresponding \emph{translational term}, $\hat{e}$. 
% Translational terms mirror external terms but include an additional form, $\textbf{spliced}[e]$, which captures portions of the parse stream parsed as a spliced term. The case \lstinlinew{Spliced} of case type \lstinlinew{Exp}, which takes a (portion of) a parse stream, dereifies to this form. This permits us to ensure that only spliced portions of parse streams can refer to variables in the surrounding scope (and no others), ensuring that hygiene is maintained. 

% This is technically accomplished by the judgements \[\Delta_{out}; \Gamma_{out}; \Delta; \Gamma \vdash_{\Theta}^{\Psi} \hat{e} \leadsto i {\Rightarrow}{(\Leftarrow)} \tau\]  which can be read ``under outer typing and kinding contexts $\Delta_{out}$ and $\Gamma_{out}$ and inner typing and kinding contexts $\Delta$ and $\Gamma$,  $\hat{e}$ elaborates to internal term $i$ and (synthesizes/analyzes against) type $\tau$''. These judgements behave identically to the corresponding judgements for external terms, using the inner typing and kinding contexts, until a term of the form $\textbf{spliced}[e]$ is encountered. The outer contexts are then used. The relevant rule can be found in \cite{TSLs}, and an analagous type-level rule will be shown below. 
% In the rules for TSLs and TSMs, (T-syn) and (T-ana), the inner contexts begin empty so only variables inside spliced terms can refer to outer variables. A \lstinlinew{parse} function that generated, for example, \lstinlinew{Var('x')}, would not typecheck, because it captures a variable that it cannot know exists. An occurrence of a variable \lstinlinew{x} inside a spliced portion (e.g. between \lstinlinew{<ANDASDSAD} and \lstinlinew{ASDNSAD>} when using the \lstinlinew{HTML} TSL) would be checked in the outer context and thus be acceptable. Parse streams cannot be created manually, so this guarantee is strict. %The details of this mechanism at the term level are essentially identical (up to the orthogonal addition of parameterized types) to that in \cite{TSLs}, so we omit the rules.

% In the rule (T-syn), the type that $\hat{e}$ is being analyzed against is determined by the definition of the TSM. The rule (T-ana) is essentially identical, but the type is determined by the type that the whole application is being analyzed against instead, consistent with the descriptions in Sec. \ref{tsms-term}. 


% \subsection{Type Declarations}\label{declarations}
% \input{kw-elaboration.tex}

% \input{kw-statics.tex}

% \begin{figure}[ht]
% \flyingbox{$\Delta\vdash_{\Theta}\tau::\kappa$}
% \begin{center}
% \AXC{$t::\kappa\in\Delta$}
% \UIC{$\Delta\vdash_{\Theta} t::\kappa$}
% %%
% \AXC{$\Delta\vdash_{\Theta}\tau_1::\kappa \rightarrow \kappa'$ ~~~~ $\Delta\vdash_{\Theta}\tau_2::\kappa$}
% \UIC{$\Delta\vdash_{\Theta}\tau_1(\tau_2)::\kappa'$}
% \noLine
% \BIC{}
% \DP
% \end{center}

% \begin{center}
% \AXC{$\Delta,t::\kappa\vdash_{\Theta}\tau::\kappa'$}
% \UIC{$\Delta\vdash_{\Theta}\lambda[\kappa](t.\tau)::\kappa\rightarrow \kappa'$}
% %%
% \AXC{$T[\tau :: \kappa, i_{md} : \tau_{md}]\in\Theta$}
% \UIC{$\Delta\vdash_{\Theta} \mathtt{T}::\kappa$}
% \noLine
% \BIC{}
% \DP
% \end{center}
% \mycaption{Kinding (object and case types follow \cite{TSLs})}
% \label{kinding}
% \end{figure}


% The rule (D-tydecl) shows how explicit named type declarations (those which do not apply a type-level TSM) work. First, the preceding declarations are processed and we ensure that no other type named $T$ was declared. Then, we need that the type $\tau$ has arrow kind $\kappa \rightarrow \kappa$ where $\kappa$ is the kind of type being declared, e.g. $\kappa = \star \rightarrow \star$ for \lstinlinew{List}. The reason for this is to support recursive named types, e.g. 

% \begin{lstlisting}[style=wyvern]
% type List(T) = casetype
%   Nil
%   Cons of T * List(T)
% \end{lstlisting}
% \noindent
% desugars to a type-level function taking in a self reference before returning a type-level function accepting the type parameter and returning the case type being declared:

% \begin{lstlisting}[style=wyvern]
% type List = tyfn(List::* -> *) => tyfn(T::*) => casetype 
%   Nil 
%   Cons of T * List(T)
% \end{lstlisting}

% Before being added to the named type context, the named type constructor $\mathtt{List}$ is substituted for the type variable $List$ via type-level function application, $\tau(\mathtt{T})$, as can be seen in the conclusion of the rule. Non-recursive types can simply ignore the ``self reference'' argument.

% We do not formalize mutually recursive types here, though they follow the same pattern (taking $n$ arguments rather than just one). The full rules can be found in the appendix. Note also that we do not explicitly check for cyclic type definitions. Standard syntactic constraints can be imposed to rule these out. 

% The final premise of (D-tydecl) synthesizes a type for the metadata. Metadata can use  the type declaration, but not recursively refer to its own metadata yet so we write a dash for a dummy metadata value.

% Figure \ref{kinding} shows that named types have the kind of their underlying type-level term. Parameterized types can thus be applied to parameters like type-level functions.

% \subsection{Type-Level TSMs}

% \begin{figure}[t]
% \flyingbox{$\Delta;\Delta\vdash_{\Theta}\hat{\tau}\rightsquigarrow \tau::\kappa$}
% %\vspace{-6px}
% \begin{center}
% \AXC{$\Delta_{out}\vdash_{\Theta} \tau ::\kappa$}
% \UIC{$\Delta_{out};\Delta\vdash_{\Theta}\mathbf{spliced}[\tau]\rightsquigarrow \tau::\kappa$}
% %%%
% \AXC{$t::\kappa\in\Delta$}
% \UIC{$\Delta_{out}; \Delta\vdash_{\Theta} t::\kappa$}
% %%%

% \noLine
% \BIC{}
% \DP
% \end{center}
% \begin{center}

% \AXC{$\Delta_{out}; \Delta,t::\kappa\vdash_{\Theta}\hat\tau\rightsquigarrow\tau::\kappa'$}
% \UIC{$\Delta_{out}; \Delta\vdash_{\Theta}\lambda[\kappa](t.\hat\tau)\rightsquigarrow\lambda[\kappa](t.\tau)::\kappa\rightarrow \kappa'$}
% \DP
% \end{center}
% \mycaption{Translational Kinding. Remaining rules are directly analagous to those for $\tau$ in Figure \ref{kinding}.}
% \label{tr-kinding}
% \end{figure}
% Rule (D-tytsm) declares a type-level TSM $s$ that generates a type of kind $\kappa$ with metadata of type $\tau_{md}$ and an implementation $e_{tsm}$. The metadata type is checked to ensure that it is a type and the implementation is checked against type $\mathtt{Parser}(\mathtt{Type} \times \tau_{md})$, consistent with the explanation in Section \ref{tsms-type}. Note that we assume product types can be encoded as object types for simplicity in our calculus. This information is recorded in the TSM context, $\Psi$.

% Rule (D-aptsm) shows how type-level TSMs are applied. If the result of the \lstinlinew{parse} method is $OK((i_{type}, i_{md}))$, then we dereify $i_{type}$ to a \emph{translational type}, $\hat{\tau}$. These are analagous to translational terms, $\hat{e}$, and serve to ensure hygiene at the level of types. The judgement $\Delta_{out}; \Delta \vdash_{\Theta} \hat{\tau} \leadsto \tau :: \kappa$ can be read ``under outer kinding context $\Delta_{out}$, inner kinding context $\Delta$ and named type context $\Theta$, translational type $\hat\tau$ elaborates to type $\tau$ at kind $\kappa$''. The syntax of translational types mirrors that of types, again with the addition of a form capturing spliced type-level terms arising from the parse stream, $\textbf{spliced}[\tau]$. The rules related to type variables and spliced forms are shown in Figure \ref{tr-kinding}. Only spliced types are checked under the outer context. 

% As with type declarations, in (D-aptsm) we need that $\hat{\tau}$ has kind $\kappa \rightarrow \kappa$ to support recursive types (in the example in Sec. \ref{tsms-type}, we omitted this because in practice, the mechanism inserts it by default for non-recursive types). The outer kinding context here is initially empty because we do not formalize nested type declarations for simplicity, but in practice it would be the kinding context coming from any outer declarations. 

% The remaining two premises of (D-aptsm) check that the metadata transformation is a function of the right type and invoke it to produce the final metadata (per Sec. \ref{tsms-type}). An identity function would be generated automatically when one is not explicitly provided by the user.

% % \subsection{Bidirectional Typechecking and Elaboration of External Terms}\label{elaboration}


% % \paragraph{Declarations}

% % An element in the declaration section can be one of type-level TSM, term-level synthetic TSM, analytical TSM or named type. By allowing different kinds of declarations appearing in the same section, a declaration can refer to any kind of declarations appeared in the previous context, which enhance the flexibility of the TSM usage.

% % For a type level TSM $s[\mathbf{tytsm}(e,\tau)]$, its declaration contains a term $e$ and a type $\tau$: the term $e$ is the parser for DSL literal parsing, and the type $\tau$ is the type of the generated metadata.

% % Similar to type-level TSMs, a term-level TSM can be one of $s[\mathbf{syn}(\tau,e)]$ or $s[\mathbf{ana}(e)]$. As we presented in section \ref{tsms-term}, synthetic TSMs are defined with its return type $\tau$ while analytic TSMs are not. The expression ($e$) in both cases represents the parser, which is supposed to be of type $ExpParser$.

% % Named type declarations are the type declarations associated with a name $T$. Depending on the its definition method, there are two kinds of type declarations: an explicit type declaration with its structure and metadata explicitly declared, or a type defined by applying a TSM to DSL literals, whose structure and metadata will be generated by the elaborated DSL literals presented in the keyword invocation body. An explicit type declaration ($T[\mathbf{explicit}(\tau,e)]$) consists of three parts: $T$ is the type name, $\tau$ is the type structure, which can be one of $\mathbf{objtype}$, $\mathbf{casetype}$, $\mathbf{arrowtype}$ or named type $\mathbf{named}[T']$,  and $e$ is the metadata associated with the type. And the second kind of type declaration ($T[\mathbf{aptsm}(k,body,e)]$) is a type declared using DSL syntax specified in a type TSM $k$. DSL literals are presented as $body$ in the declaration and the type metadata as $e$. Different from those in the first kind, metadata $e$ here serve as a metadata extender to extend the metadata generated by the keyword parser.

% % \paragraph{External Terms}
% % By naming terms in a Wyvern program ``external terms'' ($e$), we distinguish them from ``internal terms'' ($i$), which are pure Wyvern terms without DSL literals. 

% % To support term-level TSMs, the syntax for external terms is extended with a TSM application term and several terms for run-time parser access (omitted here, can be referred to TR). The term-level TSM application term $\mathbf{eaptsm}[k,body]$ specifies the application of the TSM $k$ to DSLs presented in delimited forms as $body$. Its concrete form can be referred to figure \ref{formal-syntax}.

% % An external term with DSL literals will elaborate to internal Wyvern terms with the help of the DSL parsers. During elaboration, translational expressions  
% % are defined to support ``spliced terms'', allowing external terms co-exist with internal terms: its syntax mirrors that of external terms, except that literal forms are removed and and translational state $\mathbf{spliced}[e]$ is added, which represents an external term $e$ spliced into a literal body.

% % \subsection{Bidirectional Typechecking and Elaboration}



% % Bidirectional typechecking is used here as type can be clearly specified as input or output during typechecking process. In bidirectional type system, a type judgment is written as $\Gamma\vdash_{\Theta} e\Leftarrow(\Rightarrow)\tau$ instead of $\Gamma\vdash_{\Theta} e:\tau$ in a traditional type system, where $\Gamma$ is the typing context, $\Theta$ is the declaration context, and the type $\tau$ is specified as input ($\Leftarrow$) or output ($\Rightarrow$) according to the arrow direction. 

% % A term-TSM application contains DSL literals in its body, so it belongs to external Wyvern language, and an elaboration phase is required to transform them into internal Wyvern terms before execution. The elaboration of external terms is part of type checking process, written as $\Gamma\vdash_{\Theta} e\rightsquigarrow i \Leftarrow(\Rightarrow) \tau$. It indicates that an external term elaborates to an internal term and synthesize to (or analyze against) the type $\tau$. The arrow $\rightsquigarrow$ is used to represent the elaboration process, including literal elimination and hygiene process.

% % \subsection{Contexts}
% % The program contexts (figure \ref{typechecking-environment}) contains TSM context $\Psi$, declaration context $\Theta$ and typing context $\Gamma$. 



% % TSM context $\Psi$ is the environment for user defined TSMs. Type-level TSMs defined in a Wyvern program goes into context in the form of $s[\mathbf{ty}(i,\tau)]$: the macro $k$ is a type-level TSM with parser $i$ and metadata type $\tau$. Besides type-level TSMs, term-level TSMs are also defined in $\Psi$: synthetic TSMs goes into context in the form of $s[\mathbf{bk}(\tau,i)]$, representing a macro $k$ with parser $i$ and return type $\tau$, while an analytic TSM in the context is represented as $s[\mathbf{wk}(i)]$, which is a macro $k$ with parser $i$.

% % Named typed context ($\Theta$) is the context to keep elaborated type declarations. A declared type (either explicitly declared or type keyword defined) has the form of $T[\delta,\mu]$, which is interpreted as a type of name $T$ with structure $\delta$ and metadata $\mu$. We wrap the type structure $\tau$ in $\delta$ and the metadata $i:\tau$ in $\mu$ in order to represent their ``unknown state'' using ``$?$'' in type checking.

% % Besides, $\Gamma$ is the typing context, and elements in $\Gamma$ are bindings of variables and their types ($x:\tau$).

% % \subsection{Checking rules for keywords}
% % The rules ctx-tytsm, ctx-syntsm and ctx-anatsm in Fig~\ref{typechecking-elaboration} present the type checking process for TSMs.

% % According to the rule ctx-tytsm, a type TSM declaration $s[\mathbf{ty}(e,\tau)]$ is well typed iff 1) the macro has no name conflicts with those defined in the previous context, 2) the parser $e$ elaborates to an internal term $i$ of type $\mathbf{named}[TypeKw]$ and 3) the metadata type $\tau$ is well formed within the given named type context $\Theta$.

% % For term level TSMs, the checking rules are similar to that for the type TSM: it checks that no name conflicts exists in TSM declarations, the parser elaborate to an internal term $i$ of type $\mathbf{named}[ExpKw]$, and the type defined in a synthetic TSM is well formed under named type context $\Theta$.

% % By allowing both TSMs and types declared in the same part of the program (i.e. $ d$), we allow the definition of a named type or a TSM referred to declarations appeared in its previous context, which provides a flexible way to define macros and types. For simplicity consideration, we only present rules to support recursive declaration here, and the rules for mutually recursive type and macro declarations can be referred to TR \todo{cite TR}.

% % \subsection{External Type Literals}
% % Declaring a type using a type-level TSM involves application of a macro parser to external DSL literals, and the rule ctx-aptsm-type is used to transform it into internal Wyvern type representations with concrete type structure and metadata.

% % The elaboration process of a type $T[\mathbf{aptsm}(s,body,e_m)]$ under context $\Theta,\Psi$ contains the following steps:
% % \begin{enumerate}\setlength{\itemsep}{0pt}
% % \item Check that the Wyvern prelude is contained in the named type context, as parser types are defined in Wyvern preludes. ($\Theta_0\subset \Theta$)
% % \item Elaborate previous declarations ($ d'\sim(\Theta';\Psi')$), and check that the type name $T$ has no name conflicts with those in previous context ($T\notin dom(\Theta\Theta')$).
% % \item Look up the keyword $k$ in $\Psi\Psi'$. ($s[\mathbf{ty}(i_k,\tau_m)]\in\Psi\Psi'$)
% % \item Read in the literals ($body$) as an expression $i$, and apply the parser $i_k$ to the DSL body. A tuple $(i_{type}, i_m)$ is return by the parser: $i_{type}$ is an expression of type $\mathbf{named}[Type]$ and $i_m$ is the generated metadata term. ($\mathbf{iap}(\mathbf{iprj}[parse](i_k);i_{ps})\Downarrow(i_{type},i_{m})$)
% % \item Dereificate the term $i_{type}$ to an Wyvern type $\tau$, and check the formation of the type $\tau$ under the context $\Theta\Theta',T[?,?]$. ($i_{type}\uparrow\tau$ and $\vdash_{\Theta\Theta',T[?,?]}\tau$) Dereification rules for types can be referred to \todo{cite TR}.
% % \item Elaborate the metadata $e_m$ defined in the type to an internal term $i'_m$ of type $\mathbf{arrow}[\tau_m,\tau'_m]$, which serves as an metadata extender to extend the metadata generated by the type keyword. ($\emptyset\vdash_{\Theta\Theta',T[\tau,?]}e_m\rightsquigarrow i_m' \Rightarrow \mathbf{arrow}[\tau_m, \tau'_m]$)
% % \item Apply the keyword extender ($i'_m$) to the generated metadata ($i_m$) and generate the metadata of the type $T$. ($\mathbf{iap}(i'_m,i_m)\Downarrow i''_m$)  
% % \end{enumerate}
% % After these steps, the declaration $T[\mathbf{aptsm}(k,body,e_m)]$ elaborates to $T[\tau,i''_m:\tau'_m]$ and is added into environment for further reference.

% % \subsection{Literals in TSM applications}
% % DSL literals are used in a TSM application term $\mathbf{eaptsm}$ and these DSLs will be transformed to internal terms. Elaboration rules for both kinds of TSMs are presented in figure~\ref{expkw-kwstatics}.

% % For analytic TSMs, we have the following steps to transform them into internal terms:
% % \begin{enumerate}\setlength{\itemsep}{0pt}
% % \item Check that the prelude is in the named type context. ($\Theta_0\subset\Theta$)
% % \item Look up the TSM is defined in $\Psi$. ($s[\mathbf{ana}(i_k)]\in\Psi$)
% % \item Read in the DSL literals into an expression $i_{ps}$ of type $\mathbf{named}[ParseStream]$ and parse them by invoking the parser $i_k$. The parsing result is a term of type $\mathbf{named}[Result]$, and an AST term $i_{ast}$ is provided. ($\mathbf{iap}(\mathbf{iprj}[parse](i_k); i_{ps});\Downarrow \mathbf{iinj}[OK]((i_{ast}, i'_{ps}))$)
% % \item Dereificate the term $i_{ast}$ to an translational term $\hat{e}$ with spliced DSL body, then elaborate the translational term $\hat{e}$ to an internal Wyvern term and check it against the type $\tau$. ($i_{ast}\uparrow \hat{e}$ and $\Gamma;\emptyset\myvdash \hat{e} \rightsquigarrow i \Leftarrow \tau$)
% % \end{enumerate}
% % The term $\mathbf{ekey}[k,body]$ is then transformed into $i$ of type $\tau$, which is an internal term that can be used for evaluation. The process for synthetic TSMs is similar, except that the type of the elaborated expression comes from its definition. 


% % \subsection{Hygiene}
% % \todo{Where are we supposed to discuss Hygiene?}

% \subsection{Metatheory}
% The main theorems guaranteeing that the language is well-behaved are essentially identical to those in \cite{TSLs}. The key theorem states that well-typed external terms translate to internal terms of the same type. Combined with type safety of the IL, this constitutes type safety for the language.

% \begin{theorem}[External Type Preservation]
% If $\vdash\Theta$ and $\vdash_{\Theta}\Psi$ and $\vdash_{\Theta}\Gamma$ and $\Gamma\vdash_{\Theta}^{\Psi} e\rightsquigarrow i\Leftarrow\tau$ or $\Gamma\vdash_{\Theta}^{\Psi} e\rightsquigarrow i\Rightarrow\tau$ then $\Gamma\vdash_{\Theta} i\Leftarrow\tau$.
% \end{theorem}

% We define context well-formedness judgements and prove the new cases of this theorem in the accompanying appendix, along with several other lemmas and theorems.%\todo{appendix}

% \paragraph{Type Safety and Preservation}
% Extending Wyvern semantics with TSMs still constitutes a type safe language. We will outline the key theorems here presenting the properties a type safe language has: 1) internal type sfaety and 2) type preservation. 
% \begin{theorem}[Internal Type Safety]
% If $\vdash\!\!\Delta$, $\Delta\!\!\vdash\!\!\Theta$, and $\emptyset;\emptyset\vdash_{\Theta}i\Leftarrow\tau$ or $\emptyset;\emptyset\vdash_{\Theta}i\Rightarrow\tau$, then either $i~\texttt{val}$ or $i\mapsto i'$ such that $\emptyset;\emptyset\vdash_{\Theta}i'\Leftarrow\tau$.
% \end{theorem}

% \begin{theorem}[External Type Preservation]
% If $\vdash\!\!\Delta$ $\Delta\!\vdash\!\Theta$, $\Delta\!\vdash_{\Theta_0\Theta}\!\Psi$, $\Delta\!\vdash_{\Theta_0\Theta}\!\Gamma$, and $\Delta;\Gamma\vdash_{\Theta_0\Theta}^{\Psi} e\rightsquigarrow i\Leftarrow\tau$ or $\Delta;\Gamma\vdash_{\Theta_0\Theta}^{\Psi} e\rightsquigarrow i\Rightarrow\tau$ then $\Delta;\Gamma\vdash_{\Theta_0\Theta} i\Leftarrow\tau$.
% \end{theorem}


% \begin{theorem}[Compilation]
% If ~$\rho\sim(\Theta;\Psi)\rightsquigarrow i:\tau$ then $\emptyset\vdash\Theta$, $\emptyset\vdash_{\Theta_0\Theta}\Psi$ and $\emptyset;\emptyset\vdash_{\Theta_0\Theta} i\Leftarrow\tau$.
% \end{theorem}

%\input{kw-contextformation.tex}

% end the environment with {table*}, NOTE not {table}!
\section{Related Work}\label{related}
Unlike other work on library-integrated syntax extension mechanisms, e.g. SugarJ \cite{erdweg2011sugarj} and its subsequent variations \cite{erdweg2013framework}, protean operators \cite{conf/aosd/IchikawaC14}, mechanisms like those found in Coq \cite{Coq:manual,5134} and Nemerle \cite{skalski2004meta} and various language-external mechanisms like Camlp4 \cite{ocaml-manual}, we do not permit the syntax of the base language to be extended directly. Instead, we build on the delimited forms used for type-specific languages \cite{TSLs}. Using delimiters to separate extensions from the base language guarantees that any combination of  libraries can be imported and used together (i.e. \emph{composed}), without ``link-time'' parsing ambiguities, because different extensions can only interact via the host language using splicing.%We retain the layout delimited forward referenced form and we introduce two variations on the delimiters used by \cite{TSLs}, multipart delimited forms and a parenthesis-delimited form that allows escape of forward references when used in TSMs. 

Schwerdfeger and Van Wyk have shown a composable analysis for syntax specified using an LR parser generator with a context-aware scanner \cite{conf/pldi/SchwerdfegerW09}. Like our work, they rely on a unique starting token to identify a language, but perform a sophisticated analysis on follow sets of non-terminals to guarantee composability. Our use of fixed delimiters is simpler -- no analysis need to be run at all -- and allows for arbitrary parse functions. A parser generator (in our case, based on Adams grammars \cite{Adams:2013:PPI:2429069.2429129}) is simply a TSL atop this mechanism. Using a synthetic TSM, different parser generator formalisms could be defined (e.g. for regular languages, a simpler mechanism using regular expressions might suffice).

Macro systems have a long history in the LISP family of languages. These typically only permit rewriting existing syntax (typically, a variant on S-expressions), rather than introducing arbitrary new syntax, though \emph{reader macros} do allow some syntax extensions as well, albeit without strict composability guarantees \cite{steele1990common}. We use the phrase \emph{syntax macro} to describe our work because like macros, TSMs are invoked explicitly by name and are used to generate code, but this occurs during typechecking. The initial parsing phase separates delimited forms but leaves bodies unparsed. %Nemerle provides a similar extension facility that does use delimiters \cite{skalski2004meta} but does not consider issues related to the typing discipline. 

Most existing syntax extension mechanisms don't support a typing discipline. A notable exception is work by Lorenzen and Erdweg,  who described a mechanism for automatically proving the admissibility of derived typing rules for syntax extensions \cite{conf/icfp/LorenzenE13}. Integrating such facilities into TSMs would be an interesting avenue for future work. %For example, we would want to prove  that the type of an \lstinlinew{if} expression is the type of its two branches. 


Macro systems that do consider the typing discipline, e.g. in Scala \cite{ScalaMacros2013}, do exist but as just mentioned, do not support syntax extension. In Scala, \emph{black box macros} are similar to synthetic TSMs in that they specify a type signature. Analytic TSMs can be seen as a restriction on the use of \emph{white box macros} (disabled by default in recent versions of Scala) to analytic positions. 

Concerns about hygiene have been well-studied in the macros communities, e.g. in Scheme \cite{Dybvig:1992:SAS:173617.173620}. Because we defer parsing of delimited forms to typechecking time, our formalization of the hygiene mechanism can be cleanly specified in terms of access to typing contexts and, uniquely, we track portions of the parse stream that correspond to spliced terms implicitly. We also considered hygiene at the type level here.

Standard ML of New Jersey supports quotation and antiquotation using the concept of \emph{fragment lists} \cite{SML/Quote}. Terms delimited by backticks have type \lstinlinew{'a SMLofNJ.frag list}. A fragment, of type \lstinlinew{'a frag}, is either a string or an \emph{antiquoted} term of type \lstinlinew{'a}. Antiquotation is indicated syntactically within the backticks by a caret followed by an identifier or a parenthesized expression. This is composable and obeys a typing discipline, but has three main problems:
\vspace{-5px}\begin{enumerate}[noitemsep]
\item Parsing of fragment lists must still occur at run-time. This is perhaps the biggest difference relative to our mechanism, which introduces new static desugarings. %The only partial workaround is to attempt to refactor uses of specialized syntax to the top level of a program. This is not always possible, and even if possible, it can make programs more difficult to read (defeating part of the purpose of specialized syntax). 
\item Syntax that uses backticks or carets for different purposes is difficult to introduce in this way. In our mechanism, a variety of delimiters, notably including layout, can be used, and the extension itself determines how antiquotation (i.e. splicing) is initiated, so such difficulties can be avoided.
\item Only one type of subterm can occur inside antiquotes. One must define and use a datatype if there may be different types of subterms (e.g. our HTML example above). This can again defeat part of the purpose of introducing concrete syntax.
\end{enumerate}
\section{Conclusion and Future Work}\label{conclusion}
Taken together, TSLs and TSMs represent what we see as a new ``high water mark'' in expressive power, especially within the space of systems that guarantee \emph{composability}, \emph{hygiene} and \emph{typing discipline} described in Sec. \ref{sec-intro} and are rigorously specified in type theoretic terms, as we show in the accompanying technical report \cite{sac15tr}.

There remain several promising avenues for future work. While synthetic TSMs as shown allow specifying syntax for any particular type, we did not show any way to specify syntax for all types having a common type constructor (e.g. syntax for all lists). Similarly, we do not show how to specify syntax for abstract types. Both of these require \emph{parameterized} TSMs, which we plan to specify in subsequent work. Another promising avenue for future work is to strengthen splicing so that a single delimiter can support multiple types of spliced terms (e.g. allowing both strings and HTML to be spliced into HTML). Enabling editor support is also an important direction for future work.

\section*{Acknowledgements}
We thank the anonymous referees for helpful suggestions, and acknowledge the support of the National Security Agency lablet contract \#H98230-14-C-0140.

% Existing mechanisms to support DSL language extension atop a general purpose language includes 1) extensible macro systems and 2) syntax libraries.
% \paragraph{Macro Systems}
% Macro systems are either lexical or syntactic. 

% Lexical macro systems like CPP (C preprocessor) simply perform text substitution before compiling, which sometimes lead to ill-formed program structure after transformation. 

% Syntactic macro systems in Scheme~\cite{Dybvig:1992:SAS:173617.173620}, Lisp, Dylan~\cite{Shalit:1996:DRM:236379} and Nemerle provide users the ability to extend the host language with syntax libraries. These macros are expanded after the parsing of the program, thus can guarantee a well structured program. However, Lisp macro system lacks hygiene mechanism to avoid identifier conflicts, while hygienic macros in Scheme and Dylan are limited in its way of pattern matching and substitution. Nemerle provides a relatively flexible way to define macro syntax rules, but its extension strictly limited to those which can be expressed as a single production extension to its grammar. And all of these macros system does not support type-level syntax sugar for the host language.

% TSMs support language extension with arbitrary syntax forms with user defined parser, and limited them into term-level and type-level macros, TSM stay statically typed before literals elaboration. Besides, with hygiene mechanism and modular design specified, TSMs remains hygienic and composable.

% \paragraph{Syntax Extensions}
% Another fashion of extending a general purpose language is through syntax extensions.

% ProteaJ~\cite{Ichikawa:2014:CUO:2577080.2577092} describes the {\it ProteaJ} language, which allows users to define operators annotated with named types. And conflicts between {\it ProteaJ} operators require users to disambiguate them manually. By allowing different TSMs to share same return types, different DSL literals can be composed safely without syntax conflicts. 

% SugarJ~\cite{erdweg2011sugarjDONOTUSETHIS} supports direct syntactic extension of Java by adding sugar libraries. And CamlP4 is a preprocessor for OCaml that can be used to extend the concrete syntax of the language with parsers and extensible grammars. TSMs differs from these systems by associating parsing with macros, which avoids parsing conflicts at link time.

% \section{Conclusions}
% This paragraph will end the body of this sample document.
% Remember that you might still have Acknowledgments or
% Appendices; brief samples of these
% follow.  There is still the Bibliography to deal with; and
% we will make a disclaimer about that here: with the exception
% of the reference to the \LaTeX\ book, the citations in
% this paper are to articles which have nothing to
% do with the present subject and are used as
% examples only.
%\end{document}  % This is where a 'short' article might terminate

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{research}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
%\appendix

\end{document}