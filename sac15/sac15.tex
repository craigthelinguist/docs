\documentclass{sig-alternate}
  \pdfpagewidth=8.5truein
  \pdfpageheight=11truein

\usepackage{epstopdf}
\usepackage{bussproofs}
\usepackage[usenames,dvipsnames]{color} % Required for specifying custom colors and referring to colors by name
\usepackage{listings}
\usepackage{xcolor}
\usepackage{verbatim}
\usepackage{multirow}
\usepackage{array}
\usepackage{parcolumns}
\usepackage{stackengine}
\EnableBpAbbreviations
\input{macros.tex}

\newcommand\BeraMonottfamily{%
  \def\fvm@Scale{0.85}% scales the font down
  \fontfamily{fvm}\selectfont% selects the Bera Mono font
}

\lstdefinestyle{wyvern}{
%backgroundcolor=\color{highlight}, % Set the background color for the snippet - useful for highlighting
basicstyle=\scriptsize\BeraMonottfamily, % The default font size and style of the code
breakatwhitespace=false, % If true, only allows line breaks at white space
breaklines=true, % Automatic line breaking (prevents code from protruding outside the box)
captionpos=b, % Sets the caption position: b for bottom; t for top
morecomment=[s]{(*}{*)},
commentstyle=\fontshape{it}\color{Gray}\selectfont, % Style of comments within the code - dark green courier font
deletekeywords={}, % If you want to delete any keywords from the current language separate them by commas
%escapeinside={\%}, % This allows you to escape to LaTeX using the character in the bracket
firstnumber=1, % Line numbers begin at line 1
frame=lines, % Frame around the code box, value can be: none, leftline, topline, bottomline, lines, single, shadowbox
frameround=tttt, % Rounds the corners of the frame for the top left, top right, bottom left and bottom right positions
keywords=[1]{new, objtype, type, casetype, val, def, metadata, syntax, of, fn, typekw, with, let, tyfn},
keywordstyle={[1]\bfseries},
keywordstyle={[3]\color{red!80!orange}},
morekeywords={}, % Add any functions no included by default here separated by commas
numbers=left, % Location of line numbers, can take the values of: none, left, right
numbersep=8pt, % Distance of line numbers from the code box
numberstyle=\tiny\color{Gray}, % Style used for line numbers
rulecolor=\color{black}, % Frame border color
showstringspaces=false, % Don't put marks in string spaces
showtabs=false, % Display tabs in the code as lines
stepnumber=1, % The step distance between line numbers, i.e. how often will lines be numbered
tabsize=4, % Number of spaces per tab in the code
}

\lstdefinestyle{tempwyvern}{
basicstyle=\scriptsize\BeraMonottfamily, % The default font size and style of the code
breakatwhitespace=false, % If true, only allows line breaks at white space
breaklines=true, % Automatic line breaking (prevents code from protruding outside the box)
captionpos=b, % Sets the caption position: b for bottom; t for top
morecomment=[s]{(*}{*)},
commentstyle=\fontshape{it}\color{Gray}\selectfont, % Style of comments within the code - dark green courier font
deletekeywords={}, % If you want to delete any keywords from the current language separate them by commas
%escapeinside={\%}, % This allows you to escape to LaTeX using the character in the bracket
firstnumber=1, % Line numbers begin at line 1
frame=lines, % Frame around the code box, value can be: none, leftline, topline, bottomline, lines, single, shadowbox
frameround=tttt, % Rounds the corners of the frame for the top left, top right, bottom left and bottom right positions
keywords=[1]{new, objtype, type, casetype, val, def, metadata, expkw, of, fn, with, typekw, let},
keywordstyle={[1]\bfseries},
keywordstyle={[3]\color{red!80!orange}},
morekeywords={}, % Add any functions no included by default here separated by commas
numbers=left, % Location of line numbers, can take the values of: none, left, right
numbersep=8pt, % Distance of line numbers from the code box
numberstyle=\tiny\color{Gray}, % Style used for line numbers
rulecolor=\color{black}, % Frame border color
showstringspaces=false, % Don't put marks in string spaces
showtabs=false, % Display tabs in the code as lines
tabsize=4, % Number of spaces per tab in the code
}
\lstset{basicstyle=\footnotesize,breaklines=true}
\lstset{escapeinside={@}{@}}
\newcommand{\htmlcolor}[1]{\textcolor[HTML]{339933}{#1}}
\newcommand{\expkwparsercolor}[1]{\textcolor[HTML]{336699}{#1}}
\newcommand{\typekwparsercolor}[1]{\textcolor[HTML]{7C803E}{#1}}
\newcommand{\urlcolor}[1]{\textcolor[HTML]{FFCC33}{#1}}
\newcommand{\expcolor}[1]{\textcolor[HTML]{FF0033}{#1}}
\newcommand{\membercolor}[1]{\textcolor[HTML]{FF6600}{#1}}
\newcommand{\typecolor}[1]{\textcolor[HTML]{660066}{#1}}
\newcommand{\dbcolor}[1]{\textcolor[HTML]{FF47FF}{#1}}
\newcommand{\hastslcolor}[1]{\textcolor[HTML]{002FC9}{#1}}
\newcommand{\simpleHTMLcolor}[1]{\textcolor[HTML]{7D5100}{#1}}
\newcommand{\boolIfcolor}[1]{\textcolor[HTML]{5E0C0C}{#1}}
\newcommand{\dbshcemacolor}[1]{\textcolor[HTML]{5AC3D1}{#1}}

\newcommand{\flyingbox}[1]{\fbox{{#1}}}
\newcommand{\myvdash}{\vdash_{\Theta}^{\Psi}}
\newcommand{\textcd}[1]{\textbf{\scriptsize\BeraMonottfamily{#1}}}
\newcommand{\textsp}[1]{\text{\footnotesize\BeraMonottfamily{#1}}}
\newcommand{\mycaption}[1]{\vspace{-4px}\caption{#1}\vspace{-2px}}
\newcommand{\tabularspace}{~~}
\newcommand{\tsm}{s}

\setlength{\abovecaptionskip}{-5px}
\setlength{\belowcaptionskip}{-5px}

\begin{document}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{property}{Property}
%
% --- Author Metadata here ---
\conferenceinfo{XXX}{XXX}
\CopyrightYear{XXXX} % Allows default copyright year (2002) to be over-ridden - IF NEED BE.
\crdata{X-XXXXX-XX-X/XX/XX}  % Allows default copyright data (X-XXXXX-XX-X/XX/XX) to be over-ridden.
% --- End of Author Metadata ---

\title{Composable and Hygienic Typed Syntax Macros}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{1} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
%% 1st. author
%\alignauthor
%Cyrus Omar ~~~~~~~~ Chenglong Wang ~~~~~~~~ Jonathan Aldrich \\ Carnegie Mellon University \\ \email{%\{comar, stwong, aldrich\}@cs.cmu.edu}
% 2nd. author
}
%\and  % use '\and' if you need 'another row' of author names

% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
Syntax extension mechanisms are powerful, but ensuring that extensions are individually well-behaved and can be unambiguously composed is difficult. Recent work on \emph{type-specific languages (TSLs)} addressed these problems in the specific setting of literal forms. We supplement TSLs with \emph{typed syntax macros (TSMs)}, which are explicitly invoked to give meaning to  delimited segments of arbitrary syntax, at both the level of terms and types. To support conventional syntactic idioms, we supplement the set of delimiters with a new \emph{multipart} delimited form. To maintain a strong typing discipline, we describe two flavors of term-level TSMs: synthetic TSMs specify the type of term that they elaborate to, while analytic TSMs can elaborate to terms of arbitrary type, but can only be used in positions where the type is otherwise known, like TSLs. At the level of types, we describe a third flavor of TSM that can be used to generate both a type declaration of a specified kind and its corresponding TSL.  We formally specify these mechanisms by extending  the bidirectionally typed elaboration semantics previously given for TSLs, building on the same hygiene mechanism and internal language. Taken together, TSLs and TSMs provide significant expressive power without compromising composability, hygiene and the typing discipline of the language.
\end{abstract}

% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]
%\terms{Delphi theory}
%\keywords{ACM proceedings, \LaTeX, text tagging}

\section{Introduction}
\label{sec-intro}
One way programming languages evolve is by introducing \emph{syntactic sugar} that captures common idioms more concisely and naturally. In most contemporary languages, this is the  responsibility of the language designer. Unfortunately, the designers of general-purpose languages do not have strong incentives to capture idioms that arise only situationally, motivating research into mechanisms that allow the users of a language to extend it with new syntactic sugar themselves.%, freeing designers from this responsibility.%, to varying degrees. 

Designing a useful syntax extension mechanism is non-trivial because the designer can no longer  directly ensure that no parsing ambiguities are possible and that desugarings are semantically well-behaved. Instead, the mechanism is tasked with maintaining several key guarantees:


\textbf{Composability} The mechanism cannot simply allow the base language's syntax to  be modified arbitrarily due to the potential for parsing ambiguities, both due to conflicts with the base language and, critically, between extensions (e.g. extensions adding support for XML and HTML).% To avoid this issue, extensions must be kept delimited from the base language and from one another. 


\textbf{Hygiene} The newly introduced desugaring logic must be constrained to ensure that the meaning of a valid program cannot change simply because some of the variables have been uniformly renamed (manually, or by a refactoring tool). It should also be straightforward to identify the binding site of a variable, even with intervening uses of sugar. These two situations correspond to inadvertent variable capture and shadowing by the desugaring. 


\textbf{Typing Discipline} In a statically typed setting, which will be our focus in this work, a \emph{typing discipline} is also desirable: determining the type a term will have, and analagously the kind a type will have (discussed further below), should be possible without requiring the desugaring be performed, to aid both the programmer and tools like code editors. 

Most prior approaches to syntax extension, discussed in Sec. \ref{related}, fail to simultaneously provide all of these guarantees. Recent work on \emph{type-specific languages  (TSLs)} makes these guarantees, but only in a limited setting: library providers can define new syntax only for introducing values of a type (i.e. \emph{literal forms}), associating it as metadata with the type when it is declared \cite{TSLs}. Local type inference, specified as a bidirectional type system \cite{Pierce:2000:LTI:345099.345100}, controls which TSL is used to parse a delimited piece of syntax, so TSLs are composable and maintain the typing discipline. The semantics also guarantees hygiene. We review TSLs in Sec. \ref{background}. 

While many forms of syntactic sugar can be implemented as TSLs, there remain situations where TSLs do not suffice: 1) only a single TSL can be associated with a type, and only when it is declared, so alternative syntactic choices, or syntax for a type not under a user's control, cannot be defined; 2) idioms other than those that arise when introducing a value of a type (e.g. those related to control flow or API protocols) cannot be captured; and 3) types cannot themselves be declared using specialized syntax. In this paper, we introduce \emph{typed syntax macros (TSMs)}, which supplement TSLs to support these scenarios while maintaining the strong, and we believe crucial, guarantees above.% A TSM is invoked explicitly but otherwise benefits from the same mechanisms developed for TSLs. 

We introduce TSMs first at the term level in Sec. \ref{tsms-term}.  To maintain a typing discipline, there are two flavors of term-level TSMs: \emph{synthetic TSMs} can be used anywhere, while \emph{analytic TSMs} can only be used where the expected type of the term is otherwise known. Both TSLs and TSMs leverage a common set of  lightweight delimited forms to separate syntax extensions from the host language. To support ``multi-argument'' TSMs (and TSLs), we supplement those previously defined with \emph{multipart delimited forms}. 

We next turn to the level of type declarations  in Sec. \ref{tsms-type}. Type-level TSMs generate both a type of a specified \emph{kind}, maintaining the \emph{kinding discipline} that governs type parameter application, and also the TSL associated with it, so TSLs and TSMs can operate in concert. % as we will demonstrate. 

In Sec. \ref{theory}, we give a minimal type-theoretic account of these mechanisms by extending the bidirectionally typed elaboration semantics for TSLs given previously by Omar et al. \cite{TSLs}, leveraging the same underlying semantics and hygiene mechanism at the term level and introducing an analagous type-level mechanism.% (emphasizing the cohesion of these mechanisms). %   mechanism to support efforts to  decentralize control over the concrete syntax of a typed programming language. 

Taken together, TSLs and TSMs represent what we see as a new ``high water mark'' in expressive power, particularly within the space of systems providing the strong guarantees described above. We more specifically compare our work to related work in Sec. \ref{related}. 

\section{Background}\label{background}
\subsection{Wyvern}

\begin{figure}[t!]
\begin{lstlisting}[style=wyvern]
type @\htmlcolor{HTML}@ = casetype 
  Empty
  Seq of HTML * HTML 
  Text of String
  BodyElement of Attributes * HTML
  H1Element of Attributes * HTML
  StyleElement  of Attributes * CSS
  (* ... *)
  metadata = new : HasTSL
    val parser = ~
      @\expkwparsercolor{start <- '<body' attributes '>' start '</body>'}@
        fn atts, child => '@\expcolor{BodyElement((\$}@atts@\expcolor{, \$}@child@\expcolor{))}@'
      @\expkwparsercolor{start <- '<\{' EXP '\}>'}@
        fn e => e
      (* ... *)

let heading : HTML = H1Element({}, Text("My Heading"))
serve(~) (* serve : HTML -> Unit *)
  @\htmlcolor{<body id="doc1">}@
    @\htmlcolor{<\{}@heading@\htmlcolor{\}>}@
    @\htmlcolor{<p>My first paragraph.</p>}@
  @\htmlcolor{</body>}@
\end{lstlisting}
\mycaption{A case type with an associated TSL.}
\label{f-htmltype}
\end{figure}
We will present TSMs in the context of the simple variant of the Wyvern programming language introduced previously to describe TSLs  \cite{TSLs}, making only minor changes that we will note as they come up. Wyvern is a statically typed  language with features from both the functional and object-oriented traditions and has a layout-sensitive concrete syntax. 

An example of a type encoding the tree structure of HTML is declared in Figure \ref{f-htmltype}. The named type \verb|HTML| is a \emph{case type}, with cases for each HTML tag and additional cases for an empty document, a sequence of nodes and a text node. Case types are similar to datatypes in an ML-like language (in type-theoretic terms, recursive labeled sum types). 
We can introduce a value of type \verb|HTML| by naming a case and providing data of the type the case declares, seen on line 17.

Types declared in this way are distinguished by name (they are not simply type aliases). Wyvern supports named and unnamed case types, tuple types, e.g., \verb|HTML * HTML|, function types, e.g., \verb|HTML -> Unit|, and object types, which are structural (rather than class-based) and can declare fields via \texttt{val} and methods via \texttt{def}. Two object types are shown in Figure \ref{exp-prelude}, described further below. The introductory form for an object type is \verb|new|, which  serves as a syntactic \emph{forward reference}: it can appear once per line, at any term position. The next indented block gives values for the fields and implementations for   the methods of the object. %We will see an example below.

We also add parameterized types, written e.g. \verb|List(T)|, where \verb|T| is another type. Types have \emph{kind} \verb|*|, while type constructors that have not yet been applied have arrow kind, e.g. \verb|List| has kind \verb|* -> *|. 
We assume that the definitions of standard  types like strings, lists and options are ambiently available via the \emph{prelude}, a collection of type declarations loaded before all others. 

All named types and type constructors can be equipped with \emph{metadata}: a value constructed at compile time and available for use by the language itself (in particular, the TSL mechanism) as well as tools. Metadata is analagous to class annotations in Java, but it can be any Wyvern value. % Here, we will use metadata to associate a TSL with \verb|HTML|. 

\subsection{Type-Specific Languages (TSLs)}


\begin{figure}[t!]
\begin{lstlisting}[style=wyvern]
type HasTSL = objtype
  val parser : Parser(Exp)

type @\expkwparsercolor{Parser}@(T) = objtype
  def parse(ParseStream) : Result(T)
  metadata = new : HasTSL
    val parser = (* ... parser generator ... *)

type Result(T) = casetype
  OK of T
  Error of String * Location

type @\expcolor{Exp}@ = casetype
  Var of ID
  Lam of ID * Exp
  Ap of Exp * Exp
  Ascription of Exp * Type
  CaseIntro of ID * Exp
  (* ... *)
  Spliced of ParseStream
  metadata = new : HasTSL
    val parser = (* ... exp quasiquotes ... *)

type @\typecolor{Type}@ = casetype
  TVar of ID
  TLam of ID * Type
  TAp of Type * Type
  Named of ID
  Objtype of List(MemberDecl)
  Casetype of List(CaseDecl)
  Arrow of Type * Type
  Spliced of ParseStream (* see Sec. 5 *)
  metadata : HasTSL = new
    val parser = (* ... type quasiquotes ... *)
\end{lstlisting}
\mycaption{A portion of the Wyvern prelude relevant to TSLs and TSMs.}
\label{exp-prelude}
\end{figure}

Introducing a value of a type like \verb|HTML| using general-purpose syntax like that shown on line 17 of Figure \ref{f-htmltype} can be tedious. Moreover, there is standard concrete syntax for HTML that might be preferable for reasons of familiarity or compatibility. To allow for this, we associate a \emph{type-specific language} with the \verb|HTML| type by setting the metadata to a value of type \verb|HasTSL|, an object type with a field \verb|parser| of type \verb|Parser(Exp)|. 
 %We omit the implementation of the \verb|HTML| type's TSL \verb|parse| method here for concision. 

We see this TSL being used on lines 18-22 of Figure \ref{f-htmltype}. On line 18, we wish to call the function \verb|serve|, which we assume has type \verb|HTML -> Unit|. Rather than explicitly constructing a term of type \verb|HTML| as the argument, we use the \emph{forward referenced literal form} \lstinline[style=wyvern]{~}. The \emph{body} of the literal consists of the text in the indented block beginning on the next line, stripped of the leading indentation. In effect, whitespace is serving as a delimiter for the literal. We could equivalently have used other \emph{inline delimiters}, e.g. curly braces or single quotes, which restrict what can appear inside them, as described in Figure \ref{f-delimited}. For example, we could have written line 17 equivalently as:
\begin{lstlisting}[style=wyvern, numbers=none, frame=none]
  val heading : HTML = '@\htmlcolor{<h1>My Heading</h1>}@'
\end{lstlisting}

\begin{figure}[t]
\begin{lstlisting}[style=tempwyvern]
'@\htmlcolor{body here, '{}'inner single quotes'{}' must be doubled}@'
[@\htmlcolor{body here, [inner braces] must be balanced}@]
~ (* can appear at any expression position *)
  @\htmlcolor{forward referenced body here, leading indent stripped}@
{when body is a single base term, curly braces
can be useful because forward references propagate out}
[@\htmlcolor{adjacent}@] {@\htmlcolor{delimited forms}@} @\htmlcolor{or}@ [@\htmlcolor{those}@] @\htmlcolor{separated}@ ~ @\htmlcolor{form}@
  @\htmlcolor{by identifiers create a single multipart delimited}@
\end{lstlisting}
\mycaption{Available delimited forms. The curly brace delimited and multipart delimited forms are novel and are shown being used in Sec. \ref{tsms-term}. }
\label{f-delimited}
\end{figure}


When the type system encounters literal forms like this, it defers to the parser associated with the type the literal is being analyzed against, here \verb|HTML|. For clarity in this paper, we will color host language terms black. Portions of TSL (and TSM) bodies (that are not spliced host language terms, see below) will be colored a unique color corresponding to the TSL or TSM being used, identified when declared. 

As suggested by the declaration of \verb|Parser| in Figure \ref{exp-prelude}, the TSL is responsible for transforming a \verb|ParseStream| based on the body to a \verb|Result(Exp)|, which is either an \verb|Exp| or a parse error. The case type \verb|Exp| simply encodes the abstract syntax of Wyvern terms, so the TSL is performing a term elaboration.
Here, we make use of the fact that \verb|Parser| and \verb|Exp| themselves have TSLs associated with them providing a static \emph{grammar-based parser generator} and \emph{quasiquotation}, respectively. Each production in Figure \ref{f-htmltype} is followed by a Wyvern function taking in the elaborations of each constituent non-terminal and producing the final elaboration. The non-terminal \verb|start| serves as the top-level non-terminal. The TSL for \verb|Exp| allows elaborations to be constructed using Wyvern's concrete syntax, extended with an unquote form \verb|$x| that splices in the variable of type \verb|Exp|.  We refer the reader to \cite{TSLs} for further details on these two modes of use.

Splicing is possible because a parser can request that some portion of the parse stream be treated as a host language term, type or variable. For example, the TSL for \verb|HTML| uses the delimiters \verb|<{| and \verb|}>| to mean ``splice in the enclosed term  of type \verb|HTML| here''. The case type constructors \verb|Spliced| in \verb|Exp| and \verb|Type| are used to indicate such terms. The parser generator provides the non-terminals \verb|EXP|, \verb|ID| and \verb|TYPE|, which generate these spliced forms internally. The hygiene mechanism for TSLs ensures that only spliced terms can refer to variables in the surrounding scope. New variables cannot be introduced into their scope (functions must be used to communicate between TSLs and the host language), so that binding sites are easy to determine. We will return to splicing in Sec. \ref{theory}. 



\section{Term-Level TSM\lowercase{s}}\label{tsms-term}
In this section, we will give examples of term-level typed syntax macros in Wyvern to illustrate how they are defined and can be used in situations where TSLs are not suitable. %We follow up with a more formal treatment in Sec. \ref{theory}. 

%Term-level TSMs come in two flavors: \emph{synthetic TSMs} specify the type of term they will elaborate to, meaning they can be used anywhere, while \emph{analytic TSMs} can elaborate to a term of any type, but to maintain the typing discipline, they can only be used in positions where the type can otherwise be determined. 

\subsection{Synthetic TSMs}
TSMs are defined using the \verb|syntax| keyword. Figure \ref{f-simplehtml} shows a synthetic TSM, \verb|simpleHTML|, being defined and used. The annotation on the first line indicates that valid uses of the TSM will always elaborate to a term that synthesizes the type \verb|HTML|. Like defining a TSL, defining a TSM requires defining a parser, which is a statically-evaluated value of type \verb|Parser(Exp)| (for the purposes of exposition, we include type annotations that are not strictly necessary in comments throughout the paper). Invoking a TSL is similar to function invocation, but rather than using parenthesis, the name of the TSL is followed by a delimited form (Figure \ref{f-delimited}). The body of the delimited form is parsed according to the definition of the TSM. Note that we do not here address namespacing issues, as standard techniques can be used to ensure that different TSMs have globally unique names. 

We again define the parser for \verb|simpleHTML| by using the parser generator implemented as a TSL for \verb|Parser|. Here, we are defining an alternative layout-sensitive syntax for HTML that is more concise than the conventional one by way of an \emph{Adams grammar}, which supports declarative specifications of layout-sensitive grammars by using \emph{layout constraints} within productions \cite{Adams:2013:PPI:2429069.2429129}. Here, the suffix \verb|=| indicates that the left-most column (on any line) occupied by the annotated terminal or non-terminal must occur at the same column as the parent production and \verb|>| indicates that it must be further indented. More detail on Adams grammars and this syntax for HTML can be found in \cite{TSLs}. 

Notice here that on line 7, we do not need a type annotation on \verb|heading| because \verb|simpleHTML| is synthetic. On lines 8-11, we use the same forward referenced delimited form introduced in the work on TSLs to avoid syntactic clashes between explicit delimiters and the extended syntax. The only difference here is the addition of the \verb|simpleHTML| ``keyword'', which indicates to the type system that the TSM should be used rather than the TSL for \verb|HTML|. As a result, both variants of syntax can straightforwardly be used in the same program, so synthetic TSMs address the issue of defining more than one possible syntax for a type that either has a TSL  already, or a type which a user cannot modify.% (because it appears in an external library). 

%An expression keyword is a keyword associated with a parser to transform DSL literals into a Wyvern expression. Depending on whether a return type is provided in the keyword declaration, expression keywords can be further divided into black-box keyword and white-box keyword (This terminology is borrowed from Scala's macro system). 


\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
syntax @\simpleHTMLcolor{simpleHTML}@ => HTML = ~ (* : Parser(Exp) *)
  @\expkwparsercolor{start <- '>body'= attributes> start>}@
    fn atts, child => '@\expcolor{BodyElement((\$}@atts@\expcolor{, \$}@child@\expcolor{))}@'
  @\expkwparsercolor{start <- '<'= EXP>}@
    fn e => e
  (* ... *)
let heading = simpleHTML '@\simpleHTMLcolor{>h1 My Heading}@'
serve(simpleHTML ~)
  @\simpleHTMLcolor{>body[id="doc1"]}@
    @\simpleHTMLcolor{<}@ heading
    @\simpleHTMLcolor{>p My first paragraph}@
\end{lstlisting}
\mycaption{A synthetic TSM providing alternative syntax for the \texttt{HTML} type in Figure \ref{f-htmltype}. The programs are semantically identical.}
\label{f-simplehtml}
\end{figure}
\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
type Bool = casetype 
  True
  False
syntax @\boolIfcolor{if}@ = ~ (* : Parser(Exp) *)
  @\expkwparsercolor{EXP BOUNDARY EXP BOUNDARY `else' BOUNDARY EXP}@
    fn guard, branch1, branch2 => ~ (* : Exp *)
      @\expcolor{case \$}@guard
        @\expcolor{True => \$}@branch1
        @\expcolor{False => \$}@branch2
def testIf(ok : Bool) : HTML
  if [ok] {simpleHTML ~} @\boolIfcolor{else }@{simpleHTML '@\simpleHTMLcolor{>h1 Not OK!}@'}
    @\simpleHTMLcolor{>h1 Everything is OK!}@
\end{lstlisting}
\mycaption{An analytic TSM providing a conventional syntax for \texttt{if} based on case analysis. Lines 11-12 demonstrate multipart delimited forms.}
\label{if-example}
\end{figure}

\subsection{Analytic TSMs}
Some idioms may be valid at many types. As perhaps the simplest example, consider a case type encoding booleans, \verb|Bool|, shown in Figure \ref{if-example}. Using explicit case analysis on booleans is often unnecessarily verbose, so we wish to introduce the more idiomatic \verb|if| construct. Rather than having to build this in to the language, however, we can implement it as an analytic TSM. These are distinguished from synthetic TSMs by the absence of a type annotation, because the type of an \verb|if| expression is determined by its branches. 

We see \verb|if| being used on lines 10-12 of Figure \ref{if-example} with a \emph{multipart delimited form}. Each \emph{part} can be either a single delimited form (e.g. the guard and the two branches) or an intervening keyword (e.g. \verb|else|). There are implicit boundaries between each part which parse to  a special boundary character outside the normal character set. We call this character \verb|BOUNDARY| in our parser generator (line 5). 

For the branches in our example, we chose to use curly brace delimiters, which have evolved since our previous work on TSLs to be specialized for situations where the body consists of a single spliced term. Because the parser can assume this, forward references can be identified prior to typechecking and thus be allowed to escape, as we see in the ``then'' branch in our example: the body is on the next line. Wyvern programmers would be expected to be comfortable with forward references, so this is more idiomatic Wyvern code. Were, for example, square brackets used, then we would need to write the example as follows:

\begin{lstlisting}[style=wyvern]
def testIf2(ok : Bool) : HTML
  if [ok] [simpleHTML ~
    @\simpleHTMLcolor{>h1 Everything is OK!}@
  ] @\boolIfcolor{else}@ [simpleHTML '@\simpleHTMLcolor{>h1 Not OK!}@']
\end{lstlisting}

An analytic TSM can only be used in a position where the type is otherwise known, e.g. due to the return type annotation on line 10. This is to maintain the typing discipline: we do not need to expand the TSM to know what type it will have, as with synthetic TSMs and TSLs. 

Although we believe this trade-off is worthwhile, another point in the design space is to permit a special signifier that can be used to allow analytic TSMs to be used in synthetic positions. For example, we might permit a post-fix asterisk when invoking the TSM to indicate that the elaboration is expected to synthesize a type. The type the term will have then requires a deeper understanding of the TSM in question (e.g. by knowing how it elaborates, or based on a ``derived'' typing rule that the providers of \verb|if| assert or prove \cite{conf/icfp/LorenzenE13}):

\begin{lstlisting}[style=wyvern]
def testIf3(ok : Bool) (* no return type annotation *)
  if* [ok] {simpleHTML ~} @\boolIfcolor{else}@ {simpleHTML '@\simpleHTMLcolor{>h1 Not OK!}@'}
    @\simpleHTMLcolor{>h1 Everything is OK!}@
\end{lstlisting}

%The most permissive point in the design space is to simply allow such TSMs in synthetic positions without an explicit signifier. 
Note that this would be the syntax macro analog of \emph{white-box  macros} in Scala \cite{ScalaMacros2013}, which are disabled by default in the upcoming Scala 2.12. Synthetic TSMs are analagous to black-box macros. 

\section{Type-Level TSM\lowercase{s}}\label{tsms-type}
We now turn our attention to TSMs at the level of type declarations. Our example in this section is a simple object-relational mapping (ORM) syntax, shown being used in Figure \ref{f-tykwexample}. An ORM provides an object-oriented interface to a relational database, generated based on a database \emph{schema}. The schema in Figure \ref{f-tykwexample}, for example, specifies a table with two columns, \verb|ID| and \verb|Name|, holding values of the SQL data types \verb|int| and \verb|varchar|. The \verb|ID| column is marked with an asterisk as being a \emph{primary key}, meaning that it must be unique across the rows. 

ORMs typically rely on an external code generator, which can hinder code comprehension because the fully elaborated interface is exposed directly to the programmer, obscuring the simpler schema by moving it to an external resource. By instead using the type-level TSM \verb|schema|, the interface shown in Figure \ref{typekw-example-2} is generated based on the schema during compilation, using a language-integrated mechanism. 

More specifically, the type member \verb|Entry| contains an entry for each column in the schema, with its type generated based on a mapping from SQL types to Wyvern types (not shown). Moreover, for each column \verb|C|, a method named \verb|getByC| is also generated. The return type of this method is an option type if the column is a primary key (reflecting the uniqueness invariant) or a list otherwise. There are also fields for connection parameters. 

As discussed in Section \ref{background}, type declarations in Wyvern can also include metadata. A type-level TSM must thus generate not just a type but also its metadata. Because a TSL is defined using this metadata mechanism, this implies that type-level TSMs can themselves generate TSLs. Here, the TSL that \verb|schema| generates is shown being used on lines 5-10 of Figure \ref{typekw-example-1} to create a value of type \verb|EmployeesDB|, populating the fields and methods declared by the \verb|schema|. Only the per-database settings need to be provided. %Note that we deferrito the TSL for \verb|URL|, not shown, for that portion of the configuration, demonstrating again that composition is safe and straightforward).% The remaining details are filled in automatically.

\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
type @\dbcolor{EmployeesDB}@ = schema ~
  @\dbshcemacolor{*ID   int}@
  @\dbshcemacolor{Name  varchar}@

let db : EmployeesDB = ~
  @\dbcolor{connect to}@ ~
    @\urlcolor{mysql://localhost:3306}@
  @\dbcolor{table }@   "Employees"
  @\dbcolor{username }@"user1"
  @\dbcolor{password }@"001"
db.getByID(758) (* : Option(EmployeeDB.Entry) *)
\end{lstlisting}
\mycaption{The usage of a type-level TSM and the TSL it generates to enable a simple ORM scheme.}
\label{f-tykwexample}
\end{figure}

\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
type EmployeesDB = objtype
  type Entry = objtype
    val ID : Int
    val Name : String 
  val connection : URL
  val username : String
  val password : String
  (* ... *)
  def getByID(Int) : Option(Entry)
  def getByName(String) : List(Entry)
  metadata = new : HasTSL
    val parser = (* ... generated TSL, cf Figure 8 ... *)

let db : EmployeesDB = new
  val connection = new
    val domain = "localhost"
    (* ... *)
  val username = "user1"
  val password = "001"
  (* ... *)
  def getByID(x)
    (* send appropriate query *)
db.getByID(758)
\end{lstlisting}
\mycaption{The elaboration of Figure \ref{f-tykwexample}.}
\label{typekw-example-2}
\end{figure}

The definition of \verb|schema| is shown in Figure \ref{typekw-example-1}. For a \verb|syntax| declaration to define a type-level TSM, there must be a specification of the type of metadata that will be generated, here \verb|HasTSL|. The elaboration is then defined by a parser that produces a pair consisting of a reified type (\verb|Type| is analagous to \verb|Exp|, cf. Figure \ref{exp-prelude}) and the metadata value. 

Here, we generate the type by using type quasiquotation, unquoting using \verb|${...}| to generate  field and method declarations by mapping over the column specifications in the provided schema. We assume a mapping from SQL types to Wyvern types, \verb|ty_from_sqlty|, not shown. Starting on line 21, we then generate the metadata value, which defines a TSL as described in Section \ref{background}. Note  that the TSL implements the \verb|getByC| methods by mapping over the column specification provided to the type-level TSM. In other words, the implementation of the type generated on lines 4-20 is filled in by the TSL generated on lines 21-38.

The metadata mechanism in Wyvern supports more than just TSLs. For example, a documentation generator might look for a \verb|doc| field in the metadata. Our type-level TSM only generates the TSL definition. To support extending the metadata generated by a type-level TSM further after it is invoked, the mechanism supports a \emph{metadata transformation} when a type is declared using a type-level TSM:

\begin{lstlisting}[style=wyvern]
type EmployeesDB2 = (schema ~
  @\dbshcemacolor{...}@
) metadata fn original_md (* : HasTSL *) => new
  val parser = original_md.parser
  val doc = "ORM for Employees table in database."
\end{lstlisting}

The metadata type declared by the type-level TSM determines the input type of the transformation (here, \verb|HasTSL|).

%The definition of the type keyword \verb|DBSchema| can be referred to figure \ref{typekw-example-1}. A type keyword itself is a parser for DSL literals: it is a value of type \verb|TypeParser|, which takes in a parsestream and returns a parsing result (of type \verb|Result|, which is a casetype defined in figure \ref{exp-prelude}). When there is no parsing error, a tuple \verb|(t:Type, e:Exp, k:List(KwMember))| will be returned for type construction: the type structure stored in \verb|t|, metadata in \verb|e|, and expression keywords defined by \verb|k|. \verb|DBSchema| will construct an object type with fields specified in line 5-18, and it will provide a TSL metadata for value initialization (line 20-35). The type of the metadata is provided on the first line of keyword declaration with keyword \verb|with metadata|, which is used by the type checker to analyze the metadata type.

% \begin{figure}
% \begin{lstlisting}[style=wyvern]
% type @\typekwparsercolor{TypeParser}@ = objtype
%   def parse(ps : ParseStream) : Result(Type * Exp * List(KwMember))
%   metadata : HasTSL = new 
%     val parser = (* parser generator *)

% type @\typecolor{Type}@ = casetype
%   Named of ID
%   Objtype of List(MemberDecl)
%   Casetype of List(CaseDecl)
%   Arrow of Type * Type
%   metadata : HasTSL = new
%     val parser = (* type quasiquotes *)

% type KwMember = casetype
%   Whitebox of Label * ExpKw
%   Blackbox of Label * ExpKw * Type
% \end{lstlisting}
% \mycaption{Wyvern prelude for type keywords}
% \label{type-prelude}
% \end{figure}


\begin{figure}[t]
\begin{lstlisting}[style=wyvern]
syntax @\dbshcemacolor{schema}@ :: * with metadata : HasTSL = ~ (* : Parser(Type * HasTSL) *)
  @\expkwparsercolor{start <- columns}@
    fn cols (* : List(Bool*Label*Type), cf.40-46 *) =>
      let ty = ~ : Type
        @\typecolor{objtype}@
          @\typecolor{type Entry = objtype}@
            @\typecolor{\$\{}@(* the members of Entry are generated by mapping over the columns *)
              map(cols, fn (primary, lbl, ty) => ~)
                @\typecolor{val \$}@lbl @\typecolor{:  \$}@ty
            @\typecolor{\}}@
          @\typecolor{val connection : URL}@
          @\typecolor{val username : String}@
          @\typecolor{val password : String}@
          @\typecolor{(* ... *)}@
          @\typecolor{\$\{}@(* the getByC method signatures are also generated in this way *) 
            map(cols, fn (primary, lbl, ty) => 
              let rty : Type = if [primary] {
                '@\typecolor{Option(Entry)}@'} @\boolIfcolor{else}@ {'@\typecolor{List(Entry)}@'}
              ~)
                @\typecolor{def getBy\$}@lbl@\typecolor{(\$}@ty@\typecolor{) : \$}rty@
          @\typecolor{\}}@
      let md = new : HasTSL
        val parser = ~ (* : Parser(Exp) *)
          @\expkwparsercolor{start <- ("connect to"= EXP>}@
                    @\expkwparsercolor{"table"= EXP>}@
                    @\expkwparsercolor{"username"= EXP>}@
                    @\expkwparsercolor{"password"= EXP>)}@
            fn url, un, pw, table => ~
              @\expcolor{new}@ 
                @\expcolor{val connection = \$}@url
                @\expcolor{val username = \$}@un
                @\expcolor{val password = \$}@pw
                @\expcolor{(* ... *)}@
                @\expcolor{\$\{}@(* like their declarations above, the getByC method implementations also map over the columns *)
                  map(cols, fn (primary, lbl, ty) => ~)
                    @\expcolor{def getBy\$}@lbl@\expcolor{(x)}@ 
                      @\expcolor{(* send appropriate query *)}@
                @\expcolor{\}}@
      (ty, md)
  @\expkwparsercolor{column <- "*"? ID ID}@
    fn primary, lbl, sqlty => 
      (primary, lbl, ty_from_sqlty(sqlty))
  @\expkwparsercolor{columns <- column}@
    fn column => Cons(column, Nil)
  @\expkwparsercolor{columns <- column= columns=}@
    fn column, columns => Cons(column, columns)
\end{lstlisting}
\mycaption{The definition of a type-level TSM.}
\label{typekw-example-1}
\end{figure}

\section{Formal Syntax and Semantics}\label{theory}
We will now give a formal type theoretic treatment of the mechanisms described thusfar, building directly upon the calculus for TSLs in Wyvern presented previously by Omar et al. \cite{TSLs}. 
The abstract syntax corresponding to the concrete syntax we introduced above is shown in Figures \ref{formal-syntax} and \ref{syntax-types}. A \emph{program}, $\rho$, consists of a series of declarations, $ d$, followed by a single external term, $e$. In practice, the declarations would be imported from separate packages, but we omit details of the package system here for simplicity. The top-level judgement in the system is the program compilation judgement, which generates a \emph{named type context} $\Theta$, a \emph{TSM context} $\Psi$, an \emph{internal term} $i$, and a type $\tau$ from a program:
$$\AXC{$d\sim(\Psi;\Theta)$ ~~~~ $\emptyset;\emptyset\vdash_{\Theta_0\Theta}^{\Psi}e\rightsquigarrow i\Rightarrow \tau$}      \RightLabel{(Program)}
\UIC{$ d;e\sim(\Psi;\Theta)\rightsquigarrow i:\tau$}
\DP$$

%The syntax for the contexts used in these judgements is shown in Figure \ref{typechecking-environment}. The main rules defining these judgements  are shown in Figures \ref{typechecking-elaboration} through \ref{expkw-kwstatics}. %For simplicity, we do not formalize Wyvern's mechanisms for parameterized types and type members here. 

A series of declarations, $d$, can include TSM declarations and named type declarations. The judgement $d \sim (\Psi, \Theta)$, defined in Figure \ref{typechecking-elaboration}, generates a corresponding TSM context, $\Phi$, and named type context, $\Theta$, from $d$. The syntax for these contexts is given in Figure \ref{typechecking-environment}. We refer to the type declarations in the prelude, some of which were shown in Fig. \ref{exp-prelude}, by using the named type context $\Theta_0$ in our rules.


Judgements $\Delta; \Gamma \vdash_\Theta^\Phi e \leadsto i \Rightarrow \tau$ and  $\Delta; \Gamma \vdash_\Theta^\Phi e \leadsto i \Leftarrow \tau$ can be read ``under kinding context $\Delta$, typing context $\Gamma$, named type context $\Theta$ and TSM context $\Phi$, external term $e$ elaborates to internal term $i$ and (synthesizes / analyzes against) type $\tau$''. This is a \emph{bidirectionally typed elaboration semantics}, used to elaborate TSL literals and TSM applications to the internal language, which includes only the core operations in the language. Only the internal language defines a dynamic semantics. TSL literals, $\textbf{lit}[body]$, and TSM invocations, $\textbf{eaptsm}[s, body]$ appear only in the external language. The semantics follows the standard semantics given in \cite{TSLs}, so we do not repeat the rules. The rules for the only new form, $\textbf{eaptsm}[s, body]$, are given in Figure \ref{expkw-kwstatics} and will be described below.

\subsection{Term-Level TSMs}

\begin{figure}[t]
\hspace{-5px}$\begin{array}{ll}
      \textbf{Abstract Forms}   & \textbf{Concrete Forms}\\
      \textsf{Programs} ~ \rho~::=~ d;e\\
      \textsf{Declarations}~d~::= \\
      \tabularspace \emptyset\\
      \tabularspace d;\mathbf{syntsm}(\tsm,\tau,e)    & \textcd{syntax}~\tsm : \tau~\textcd{=}~e\\
      \tabularspace d;\mathbf{anatsm}(\tsm,e)          & \textcd{syntax}~\tsm~\textcd{=}~e\\
      \tabularspace d;\mathbf{tytsm}(\tsm,\kappa, \tau, e) & \textcd{syntax}~\tsm::\kappa~\textcd{with metadata:}\tau\,\textcd{=}\,e\\
      \tabularspace d; \mathbf{tydecl}(T, \tau, e)  & \textcd{type}~T~\textcd{=}~\tau\\
                                                            & ~~~\textcd{metadata = }e\\
      \tabularspace d; \mathbf{tyaptsm}(T, \tsm, body, e)   & \textcd{type}~T~\textcd{=}~\tsm~dform\\
                                                            & ~~~\textcd{metadata }e\\
%      \text{Object Fields}\\
%      \omega~::=~\emptyset                      \\
%      \tabularspace l[\mathbf{val},\tau];\omega                 & \textcd{val}~l : \tau\\
%      \tabularspace l[\mathbf{def},\tau];\omega                 & \textcd{def}~l : \tau\\
%      \text{Casetype Cases}\\
%      \chi~::=~\emptyset                      \\                 
%      \tabularspace C[\tau];\chi                   & C~\textcd{of}~\tau\\
      \textsf{External Terms}~ e~::= ...                              & \\
      \tabularspace\mathbf{lit}[body]             & dform\\
      \tabularspace\mathbf{eaptsm}[\tsm,body]       & \tsm~dform\\
      ~\\
      \multicolumn{2}{l}{\textsf{Translational Terms} ~ \hat{e}~::= ... ~|~ \mathbf{spliced}[e]} \\
      \multicolumn{2}{l}{\textsf{Internal Terms}~i~::= ...}
  \end{array}$
\mycaption{Abstract and concrete forms for declarations and terms. Metavariable $\tsm$ ranges over TSM names, $T$ over type names, $dform$ over delimited forms, per Figure \ref{f-delimited}, and $body$ over their bodies. Translational and internal terms are used in the semantics only. Elided forms are given in \cite{TSLs}.}
\label{formal-syntax}
\end{figure}

\begin{figure}[t]
\hspace{-5px}$\begin{array}{llcl}
      \mathsf{Kinds} &  \kappa &::= & \star  ~|~ \kappa \rightarrow \kappa\\
      \textsf{Types} & \tau & ::= & T ~|~ \tau \rightarrow \tau ~|~ \mathbf{objtype}[\omega] ~|~ \mathbf{casetype}[\chi] \\
      & & | & t ~|~ \lambda[\kappa](t.\tau) ~|~ \tau(\tau) \\
      \multicolumn{4}{l}{\textsf{Translational Types} ~ \hat{\tau} ~ ::= ... ~|~ \mathbf{spliced}[\tau]}
  \end{array}$
\mycaption{Syntax for types and kinds. Metavariable $t$ ranges over type variables. Object type and case type declarations $\omega$ and $\chi$ are taken from \cite{TSLs}.
%Metavariable $T$ ranges over type names, $l$ over member labels, $C$ over case names, $x$ over term variables, $X$ over type variables.
}\label{syntax-types}
\end{figure}
\begin{figure}[t]
$\begin{array}{l}
      \textsf{TSM Contexts}\\
      \Psi ::= \emptyset ~|~ \Psi, s[\mathbf{ty}(\kappa,\tau, i)] ~|~ \Psi, s[\mathbf{syn}(\tau,i)] ~|~ \Psi, s[\mathbf{ana}(i)]\\
      \textsf{Named Type Contexts} ~\Theta ::= \emptyset~|~\Theta, T[\tau :: \kappa,i : \tau]\\
      \textsf{Typing Contexts}~\Gamma ::= \emptyset ~|~ \Gamma, x : \tau\\
      \textsf{Kinding Contexts}
      ~~\Delta ::= \emptyset ~|~ \Delta,t::\kappa
\end{array}$
\mycaption{Syntax for contexts.}
\label{typechecking-environment}
\end{figure}
The rule (D-syntsm) shows how a synthetic TSM named $s$, synthesizing type $\tau$ and implemented by $e_{tsm}$ is declared. The rule first recursively checks the preceding declarations, then ensures that no other TSM named $s$ was declared  (we treat contexts as finite mappings and write, e.g., $\text{dom}(\Psi)$ to be the domain of $\Psi$). Then, it checks that $\tau$ is a closed type by checking that it's kind is $\star$ in an empty kinding context. Kinding contexts are simply mappings from type variables to kinds and the key kinding rules are shown in Figure \ref{kinding}. We will return to them when discussing type declarations below. Finally, $e_{tsm}$ is analyzed against  $Parser(Exp)$, defined in the prelude. It must be a closed term, so the kinding and typing contexts are empty (it can use the named types and TSMs declared previously, however). Once these checks are complete, the definition of $s$ is added to $\Psi$. The rule for analytic TSM declarations, (D-anatsm), is nearly identical, differing only in that no kind check is needed.

Term-level TSM application is captured by the abstract form $\textbf{eaptsm}[s, body]$, where $s$ is the name of the TSM and $body$ is the body of the (generalized) delimited form given, per the discussion in Section \ref{tsms-term}. The rule (T-syn) in Figure \ref{expkw-kwstatics} shows how typing and elaboration for a synthetic TSM proceeds. First, the definition of $s$ is extracted from $\Psi$. Then, a parse stream is constructed on the basis of $body$. We assume the relation $\textsf{parsestream}(body)=i_{ps}$ is defined such that $i_{ps}$ is a closed term of type $ParseStream$. Then, the $parse$ method of the TSM implementation is invoked with the parse stream. The judgement $i \Downarrow i'$ expresses evaluation to a value, $\i'$ (see \cite{TSLs}). As suggested by the declarations in Figure \ref{exp-prelude}, the result is either a parse error or a valid parse, written $OK(i_{exp})$, where $i_{exp}$ is a value of type $Exp$. Here, we simply leave the error case undefined -- the typing judgement cannot be derived if there is a parse error -- though in practice, the compiler would report errors that occurred. The \emph{dereification judgement} $i \uparrow \hat{e}$, defined in \cite{TSLs}, tales a value of type $Exp$ to a corresponding \emph{translational term}, $\hat{e}$. 

Translational terms mirror external terms but include an additional form, $\textbf{spliced}[e]$, which captures portions of the parsestream parsed as a spliced term. The case \verb|Spliced| of case type \verb|Exp|, which takes a (portion of) a parse stream, dereifies to this form. The reason for this is that it permits us to ensure that only spliced portions of parse streams can refer to variables in the surrounding scope (and only these), ensuring that hygiene is maintained. The judgements $\Delta_{out}; \Gamma_{out}; \Delta; \Gamma \vdash_{\Theta}^{\Psi} \hat{e} \leadsto i {\Rightarrow}{(\Leftarrow)} \tau$ can be read ``Under outer typing and kinding contexts $\Delta_{out}$ and $\Gamma_{out}$ and inner typing and kinding contexts $\Delta$ and $\Gamma$,  $\hat{e}$ elaborates to internal term $i$ and (synthesizes/analyzes against) type $\tau$''. These judgements behave identically to the corresponding judgements for external terms, using the inner typing and kinding contexts, until a term of the form $\textbf{spliced}[e]$ is encountered. The outer contexts are then used for $e$. 

In the rules for TSLs and TSMs, e.g. (T-syn) and (T-ana), the inner contexts begin empty so only variables inside spliced terms can refer to outer variables. A \verb|parse| function that inadvertently produced, for example, \verb|Var('x')|, would not typecheck, because it captures a variable that it cannot know exists. Because parsestreams can only be created by the semantics, only variables explicitly mentioned by the user of the TSL or TSM can appear in spliced terms, ensuring hygiene. The details of this mechanism at the term level are essentially identical (up to the orthogonal addition of parameterized types) to that in \cite{TSLs}, so we omit the rules.

In the rule (T-syn), the type that $\hat{e}$ is being analyzed against is determined by the definition of the TSM. The rule (T-ana) is essentially identical, but the type is determined by the type that the whole application is being analyzed against instead, consistent with the descriptions in Sec. \ref{tsms-term}. 


\subsection{Type Declarations}\label{declarations}
\input{kw-elaboration.tex}

\input{kw-statics.tex}

\begin{figure}[ht]
\flyingbox{$\Delta\vdash_{\Theta}\tau::\kappa$}
\begin{center}
\AXC{$t::\kappa\in\Delta$}
\UIC{$\Delta\vdash_{\Theta} t::\kappa$}
%%
\AXC{$\Delta\vdash_{\Theta}\tau_1::\kappa \rightarrow \kappa'$ ~~~~ $\Delta\vdash_{\Theta}\tau_2::\kappa$}
\UIC{$\Delta\vdash_{\Theta}\tau_1(\tau_2)::\kappa'$}
\noLine
\BIC{}
\DP
\end{center}

\begin{center}
\AXC{$\Delta,t::\kappa\vdash_{\Theta}\tau::\kappa'$}
\UIC{$\Delta\vdash_{\Theta}\lambda[\kappa](t.\tau)::\kappa\rightarrow \kappa'$}
%%
\AXC{$T[\tau :: \kappa, i_{md} : \tau_{md}]\in\Theta$}
\UIC{$\Delta\vdash_{\Theta} T::\kappa$}
\noLine
\BIC{}
\DP
\end{center}
\mycaption{Kinding. Rules for object and case types follow \cite{TSLs}.}
\label{kinding}
\end{figure}

\begin{figure*}[t]
\flyingbox{$\Delta;\Delta\vdash_{\Theta}\hat{\tau}\rightsquigarrow \tau::\kappa$}
\vspace{-6px}
\begin{center}
\AXC{$t::\kappa\in\Delta$}
\UIC{$\Delta_{out}; \Delta\vdash_{\Theta} t::\kappa$}
%%
\AXC{$\Delta_{out}; \Delta,t::\kappa\vdash_{\Theta}\tau::\kappa'$}
\UIC{$\Delta_{out}; \Delta\vdash_{\Theta}\lambda[\kappa](t.\tau)::\kappa\rightarrow \kappa'$}
%%
\AXC{$\Delta_{out}\vdash_{\Theta}^{\Psi} \tau ::\kappa$}
\UIC{$\Delta_{out};\Delta\vdash_{\Theta}\mathbf{spliced}[\tau]\rightsquigarrow \tau::\kappa$}
\noLine
\TIC{}
\DP
\end{center}
\mycaption{Translational Kinding. Remaining rules are directly analagous to those for $\tau$ in Figure \ref{kinding}.}
\label{tr-kinding}
\end{figure*}

The rule (D-tydecl) shows how explicit named type declarations (those which do not apply a type-level TSM) work. First, the preceding declarations are processed and we ensure that no other type named $T$ was declared. Then, we need that the type $\tau$ has arrow kind $\kappa \rightarrow \kappa$ where $\kappa$ is the kind of type being declared, e.g. $\kappa = \star \rightarrow \star$ for \verb|List|. The reason for this is to support recursive named types. For example:

\begin{lstlisting}[style=wyvern]
type List(T) = casetype
  Nil
  Cons of T * List(T)
\end{lstlisting}
\noindent
desugars to a type-level function taking in a self-reference and return a type-level function taking in the type parameter and then finally returning the case type being declared:

\begin{lstlisting}[style=wyvern]
type List = tyfn(List::* -> *) => tyfn(T::*) => casetype 
  Nil 
  Cons of T * List(T)
\end{lstlisting}

Before being added to the named type context, the named type $\textbf{named}[List]$ is substituted for the type variable $List$ via type-level function application, $\tau(\textbf{named}[T])$.\todo{fix named types} 

We do not formalize mutually recursive types here, though they follow the same pattern (taking $n$ arguments rather than just one). \todo{if we finish this in TR, cite it} Note that we do not explicitly check for cyclic type definitions. Standard syntactic constraints can be imposed to rule these out. 

The final premise of (D-tydecl) synthesizes a type for the metadata. Metadata can use  the type declaration, but not recursively refer to its own metadata yet so we write a dash for a dummy metadata value.

Figure \ref{kinding} shows that named types have the kind of their underlying unnamed type. Parameterized types can thus be applied to parameters like type-level functions.

\subsection{Type-Level TSMs}
Rule (D-tytsm) declares a type-level TSM $s$ that generates a type of kind $\kappa$ with metadata of type $\tau_{md}$ and an implementation $e_{tsm}$. The metadata type is checked to ensure that it is a type and the implementation is checked against type $Parser(Type \times \tau_{md})$, consistent with the explanation in Section \ref{tsms-type}. Note that we assume product types can be encoded as object types for simplicity in our calculus. This information is recorded in the TSM context, $\Psi$.

Rule (D-aptsm) shows how type-level TSMs are applied. If the result of the \verb|parse| method is $OK((i_{type}, i_{md}))$, then we dereify $i_{type}$ to a \emph{translational type}, $\hat{\tau}$. These are analagous to translational terms, $\hat{e}$, and serve to ensure hygiene at the level of types. The judgement $\Delta_{out}; \Delta \vdash_{\Theta} \hat{\tau} \leadsto \tau :: \kappa$ can be read ``under outer kinding context $\Delta_{out}$, inner kinding context $\Delta$ and named type context $\Theta$, translational type $\hat\tau$ elaborates to type $\tau$ at kind $\kappa$''. The syntax of translational types mirrors that of types, again with the addition of a form capturing spliced type-level terms arising from the parse stream, $\textbf{spliced}[\tau]$. The rules related to type variables and spliced forms are shown in Figure \ref{tr-kinding}. Only spliced types are checked under the outer context. As with type declarations, we need that $\hat{\tau}$ has kind $\kappa \rightarrow \kappa$ to support recursive types (non-recursive types can simply ignore the argument). \todo{fix example}. 

The remaining two premises of (D-aptsm) check that the metadata transformer is a function of the right type and invoke it to produce the final metadata (per Sec. \ref{tsms-type}). An identity function can be generated automatically when a metadata transformer is not explicitly provided by the user.

% \subsection{Bidirectional Typechecking and Elaboration of External Terms}\label{elaboration}


% \paragraph{Declarations}

% An element in the declaration section can be one of type-level TSM, term-level synthetic TSM, analytical TSM or named type. By allowing different kinds of declarations appearing in the same section, a declaration can refer to any kind of declarations appeared in the previous context, which enhance the flexibility of the TSM usage.

% For a type level TSM $s[\mathbf{tytsm}(e,\tau)]$, its declaration contains a term $e$ and a type $\tau$: the term $e$ is the parser for DSL literal parsing, and the type $\tau$ is the type of the generated metadata.

% Similar to type-level TSMs, a term-level TSM can be one of $s[\mathbf{syn}(\tau,e)]$ or $s[\mathbf{ana}(e)]$. As we presented in section \ref{tsms-term}, synthetic TSMs are defined with its return type $\tau$ while analytic TSMs are not. The expression ($e$) in both cases represents the parser, which is supposed to be of type $ExpParser$.

% Named type declarations are the type declarations associated with a name $T$. Depending on the its definition method, there are two kinds of type declarations: an explicit type declaration with its structure and metadata explicitly declared, or a type defined by applying a TSM to DSL literals, whose structure and metadata will be generated by the elaborated DSL literals presented in the keyword invocation body. An explicit type declaration ($T[\mathbf{explicit}(\tau,e)]$) consists of three parts: $T$ is the type name, $\tau$ is the type structure, which can be one of $\mathbf{objtype}$, $\mathbf{casetype}$, $\mathbf{arrowtype}$ or named type $\mathbf{named}[T']$,  and $e$ is the metadata associated with the type. And the second kind of type declaration ($T[\mathbf{aptsm}(k,body,e)]$) is a type declared using DSL syntax specified in a type TSM $k$. DSL literals are presented as $body$ in the declaration and the type metadata as $e$. Different from those in the first kind, metadata $e$ here serve as a metadata extender to extend the metadata generated by the keyword parser.

% \paragraph{External Terms}
% By naming terms in a Wyvern program ``external terms'' ($e$), we distinguish them from ``internal terms'' ($i$), which are pure Wyvern terms without DSL literals. 

% To support term-level TSMs, the syntax for external terms is extended with a TSM application term and several terms for run-time parser access (omitted here, can be referred to TR). The term-level TSM application term $\mathbf{eaptsm}[k,body]$ specifies the application of the TSM $k$ to DSLs presented in delimited forms as $body$. Its concrete form can be referred to figure \ref{formal-syntax}.

% An external term with DSL literals will elaborate to internal Wyvern terms with the help of the DSL parsers. During elaboration, translational expressions  
% are defined to support ``spliced terms'', allowing external terms co-exist with internal terms: its syntax mirrors that of external terms, except that literal forms are removed and and translational state $\mathbf{spliced}[e]$ is added, which represents an external term $e$ spliced into a literal body.

% \subsection{Bidirectional Typechecking and Elaboration}



% Bidirectional typechecking is used here as type can be clearly specified as input or output during typechecking process. In bidirectional type system, a type judgment is written as $\Gamma\vdash_{\Theta} e\Leftarrow(\Rightarrow)\tau$ instead of $\Gamma\vdash_{\Theta} e:\tau$ in a traditional type system, where $\Gamma$ is the typing context, $\Theta$ is the declaration context, and the type $\tau$ is specified as input ($\Leftarrow$) or output ($\Rightarrow$) according to the arrow direction. 

% A term-TSM application contains DSL literals in its body, so it belongs to external Wyvern language, and an elaboration phase is required to transform them into internal Wyvern terms before execution. The elaboration of external terms is part of type checking process, written as $\Gamma\vdash_{\Theta} e\rightsquigarrow i \Leftarrow(\Rightarrow) \tau$. It indicates that an external term elaborates to an internal term and synthesize to (or analyze against) the type $\tau$. The arrow $\rightsquigarrow$ is used to represent the elaboration process, including literal elimination and hygiene process.

% \subsection{Contexts}
% The program contexts (figure \ref{typechecking-environment}) contains TSM context $\Psi$, declaration context $\Theta$ and typing context $\Gamma$. 



% TSM context $\Psi$ is the environment for user defined TSMs. Type-level TSMs defined in a Wyvern program goes into context in the form of $s[\mathbf{ty}(i,\tau)]$: the macro $k$ is a type-level TSM with parser $i$ and metadata type $\tau$. Besides type-level TSMs, term-level TSMs are also defined in $\Psi$: synthetic TSMs goes into context in the form of $s[\mathbf{bk}(\tau,i)]$, representing a macro $k$ with parser $i$ and return type $\tau$, while an analytic TSM in the context is represented as $s[\mathbf{wk}(i)]$, which is a macro $k$ with parser $i$.

% Named typed context ($\Theta$) is the context to keep elaborated type declarations. A declared type (either explicitly declared or type keyword defined) has the form of $T[\delta,\mu]$, which is interpreted as a type of name $T$ with structure $\delta$ and metadata $\mu$. We wrap the type structure $\tau$ in $\delta$ and the metadata $i:\tau$ in $\mu$ in order to represent their ``unknown state'' using ``$?$'' in type checking.

% Besides, $\Gamma$ is the typing context, and elements in $\Gamma$ are bindings of variables and their types ($x:\tau$).

% \subsection{Checking rules for keywords}
% The rules ctx-tytsm, ctx-syntsm and ctx-anatsm in Fig~\ref{typechecking-elaboration} present the type checking process for TSMs.

% According to the rule ctx-tytsm, a type TSM declaration $s[\mathbf{ty}(e,\tau)]$ is well typed iff 1) the macro has no name conflicts with those defined in the previous context, 2) the parser $e$ elaborates to an internal term $i$ of type $\mathbf{named}[TypeKw]$ and 3) the metadata type $\tau$ is well formed within the given named type context $\Theta$.

% For term level TSMs, the checking rules are similar to that for the type TSM: it checks that no name conflicts exists in TSM declarations, the parser elaborate to an internal term $i$ of type $\mathbf{named}[ExpKw]$, and the type defined in a synthetic TSM is well formed under named type context $\Theta$.

% By allowing both TSMs and types declared in the same part of the program (i.e. $ d$), we allow the definition of a named type or a TSM referred to declarations appeared in its previous context, which provides a flexible way to define macros and types. For simplicity consideration, we only present rules to support recursive declaration here, and the rules for mutually recursive type and macro declarations can be referred to TR \todo{cite TR}.

% \subsection{External Type Literals}
% Declaring a type using a type-level TSM involves application of a macro parser to external DSL literals, and the rule ctx-aptsm-type is used to transform it into internal Wyvern type representations with concrete type structure and metadata.

% The elaboration process of a type $T[\mathbf{aptsm}(s,body,e_m)]$ under context $\Theta,\Psi$ contains the following steps:
% \begin{enumerate}\setlength{\itemsep}{0pt}
% \item Check that the Wyvern prelude is contained in the named type context, as parser types are defined in Wyvern preludes. ($\Theta_0\subset \Theta$)
% \item Elaborate previous declarations ($ d'\sim(\Theta';\Psi')$), and check that the type name $T$ has no name conflicts with those in previous context ($T\notin dom(\Theta\Theta')$).
% \item Look up the keyword $k$ in $\Psi\Psi'$. ($s[\mathbf{ty}(i_k,\tau_m)]\in\Psi\Psi'$)
% \item Read in the literals ($body$) as an expression $i$, and apply the parser $i_k$ to the DSL body. A tuple $(i_{type}, i_m)$ is return by the parser: $i_{type}$ is an expression of type $\mathbf{named}[Type]$ and $i_m$ is the generated metadata term. ($\mathbf{iap}(\mathbf{iprj}[parse](i_k);i_{ps})\Downarrow(i_{type},i_{m})$)
% \item Dereificate the term $i_{type}$ to an Wyvern type $\tau$, and check the formation of the type $\tau$ under the context $\Theta\Theta',T[?,?]$. ($i_{type}\uparrow\tau$ and $\vdash_{\Theta\Theta',T[?,?]}\tau$) Dereification rules for types can be referred to \todo{cite TR}.
% \item Elaborate the metadata $e_m$ defined in the type to an internal term $i'_m$ of type $\mathbf{arrow}[\tau_m,\tau'_m]$, which serves as an metadata extender to extend the metadata generated by the type keyword. ($\emptyset\vdash_{\Theta\Theta',T[\tau,?]}e_m\rightsquigarrow i_m' \Rightarrow \mathbf{arrow}[\tau_m, \tau'_m]$)
% \item Apply the keyword extender ($i'_m$) to the generated metadata ($i_m$) and generate the metadata of the type $T$. ($\mathbf{iap}(i'_m,i_m)\Downarrow i''_m$)  
% \end{enumerate}
% After these steps, the declaration $T[\mathbf{aptsm}(k,body,e_m)]$ elaborates to $T[\tau,i''_m:\tau'_m]$ and is added into environment for further reference.

% \subsection{Literals in TSM applications}
% DSL literals are used in a TSM application term $\mathbf{eaptsm}$ and these DSLs will be transformed to internal terms. Elaboration rules for both kinds of TSMs are presented in figure~\ref{expkw-kwstatics}.

% For analytic TSMs, we have the following steps to transform them into internal terms:
% \begin{enumerate}\setlength{\itemsep}{0pt}
% \item Check that the prelude is in the named type context. ($\Theta_0\subset\Theta$)
% \item Look up the TSM is defined in $\Psi$. ($s[\mathbf{ana}(i_k)]\in\Psi$)
% \item Read in the DSL literals into an expression $i_{ps}$ of type $\mathbf{named}[ParseStream]$ and parse them by invoking the parser $i_k$. The parsing result is a term of type $\mathbf{named}[Result]$, and an AST term $i_{ast}$ is provided. ($\mathbf{iap}(\mathbf{iprj}[parse](i_k); i_{ps});\Downarrow \mathbf{iinj}[OK]((i_{ast}, i'_{ps}))$)
% \item Dereificate the term $i_{ast}$ to an translational term $\hat{e}$ with spliced DSL body, then elaborate the translational term $\hat{e}$ to an internal Wyvern term and check it against the type $\tau$. ($i_{ast}\uparrow \hat{e}$ and $\Gamma;\emptyset\myvdash \hat{e} \rightsquigarrow i \Leftarrow \tau$)
% \end{enumerate}
% The term $\mathbf{ekey}[k,body]$ is then transformed into $i$ of type $\tau$, which is an internal term that can be used for evaluation. The process for synthetic TSMs is similar, except that the type of the elaborated expression comes from its definition. 


% \subsection{Hygiene}
% \todo{Where are we supposed to discuss Hygiene?}

\subsection{Metatheory}
\paragraph{Type Safety and Preservation}
Extending Wyvern semantics with TSMs still constitutes a type safe language. We will outline the key theorems here presenting the properties a type safe language has: 1) internal type sfaety and 2) type preservation. 
\begin{theorem}[Internal Type Safety]
If $\vdash\!\!\Delta$, $\Delta\!\!\vdash\!\!\Theta$, and $\emptyset;\emptyset\vdash_{\Theta}i\Leftarrow\tau$ or $\emptyset;\emptyset\vdash_{\Theta}i\Rightarrow\tau$, then either $i~\texttt{val}$ or $i\mapsto i'$ such that $\emptyset;\emptyset\vdash_{\Theta}i'\Leftarrow\tau$.
\end{theorem}

\begin{theorem}[External Type Preservation]
If $\vdash\!\!\Delta$ $\Delta\!\vdash\!\Theta$, $\Delta\!\vdash_{\Theta_0\Theta}\!\Psi$, $\Delta\!\vdash_{\Theta_0\Theta}\!\Gamma$, and $\Delta;\Gamma\vdash_{\Theta_0\Theta}^{\Psi} e\rightsquigarrow i\Leftarrow\tau$ or $\Delta;\Gamma\vdash_{\Theta_0\Theta}^{\Psi} e\rightsquigarrow i\Rightarrow\tau$ then $\Delta;\Gamma\vdash_{\Theta_0\Theta} i\Leftarrow\tau$.
\end{theorem}


\begin{theorem}[Compilation]
If ~$\rho\sim(\Theta;\Psi)\rightsquigarrow i:\tau$ then $\emptyset\vdash\Theta$, $\emptyset\vdash_{\Theta_0\Theta}\Psi$ and $\emptyset;\emptyset\vdash_{\Theta_0\Theta} i\Leftarrow\tau$.
\end{theorem}

%\input{kw-contextformation.tex}

% end the environment with {table*}, NOTE not {table}!
\section{Related Work}\label{related}
Existing mechanisms to support DSL language extension atop a general purpose language includes 1) extensible macro systems and 2) syntax libraries.
\paragraph{Macro Systems}
Macro systems are either lexical or syntactic. 

Lexical macro systems like CPP (C preprocessor) simply perform text substitution before compiling, which sometimes lead to ill-formed program structure after transformation. 

Syntactic macro systems in Scheme~\cite{Dybvig:1992:SAS:173617.173620}, Lisp, Dylan~\cite{Shalit:1996:DRM:236379} and Nemerle provide users the ability to extend the host language with syntax libraries. These macros are expanded after the parsing of the program, thus can guarantee a well structured program. However, Lisp macro system lacks hygiene mechanism to avoid identifier conflicts, while hygienic macros in Scheme and Dylan are limited in its way of pattern matching and substitution. Nemerle provides a relatively flexible way to define macro syntax rules, but its extension strictly limited to those which can be expressed as a single production extension to its grammar. And all of these macros system does not support type-level syntax sugar for the host language.

TSMs support language extension with arbitrary syntax forms with user defined parser, and limited them into term-level and type-level macros, TSM stay statically typed before literals elaboration. Besides, with hygiene mechanism and modular design specified, TSMs remains hygienic and composable.

\paragraph{Syntax Extensions}
Another fashion of extending a general purpose language is through syntax extensions.

ProteaJ~\cite{Ichikawa:2014:CUO:2577080.2577092} describes the {\it ProteaJ} language, which allows users to define operators annotated with named types. And conflicts between {\it ProteaJ} operators require users to disambiguate them manually. By allowing different TSMs to share same return types, different DSL literals can be composed safely without syntax conflicts. 

SugarJ~\cite{erdweg2011sugarjDONOTUSETHIS} supports direct syntactic extension of Java by adding sugar libraries. And CamlP4 is a preprocessor for OCaml that can be used to extend the concrete syntax of the language with parsers and extensible grammars. TSMs differs from these systems by associating parsing with macros, which avoids parsing conflicts at link time.

\section{Conclusions}
This paragraph will end the body of this sample document.
Remember that you might still have Acknowledgments or
Appendices; brief samples of these
follow.  There is still the Bibliography to deal with; and
we will make a disclaimer about that here: with the exception
of the reference to the \LaTeX\ book, the citations in
this paper are to articles which have nothing to
do with the present subject and are used as
examples only.
%\end{document}  % This is where a 'short' article might terminate

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{research}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
\end{document}