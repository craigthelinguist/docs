% !TEX root = ecoop14.tex
\section{Approach}
\label{s:approach}
Use a core language, TSL Wyvern, based on the statics we've developed...

\todo{If DSL's are now TSL's, what is GPL/Wyvern now called?}

\subsection{Concrete Syntax}

Wyvern is a whitespace-delimited programming language. We found it convenient to describe concrete grammar for it using Adams' formalism~\cite{Adams:2013:PPI:2429069.2429129}. Most of Wyvern's concrete syntax is shown in Figure~\ref{f-grammar}. The next paragraph gives an intuition behind the grammar formalism presented by Adams, and if the reader is already familiar with it, it is possible to skip to the subsequent paragraph.

For each production rule of a grammar, Adams proposed to use comparison operators, such as =, >, <, $\geq$, and $\leq$, in the superscript of the terms on the right-hand side roughly speaking to specify the indentation at which those terms need to be with respect to the term on the left-hand side. The meaning of the comparison operators is akin to their mathematical meaning: = means that the term on the right-hand side has to be at exactly the same indentation level as the term on the left-hand side; > (<) means that the term on the right-hand side has to be indented strictly further (less) to the left than the term on the left-hand side; $\geq$ ($\leq$) is like > (<), except the term on the right could also be at the same indentation level as the term on the left-hand side. For example, the production rule of the form \lstinline{A $\rightarrow$ B$^=$ '='$^\geq$ C$^>$} approximately reads as: ``Term \lstinline{B} must be at the same indentation level as term \lstinline{A}, term \lstinline{'='} may be at the same or a greater indentation level as term \lstinline{A}, and term \lstinline{C} must be at an indentation level greater than term \lstinline{A}'s.'' Now we can proceed to the discussion of the Wyvern concrete syntax depicted in Figure~\ref{f-grammar}.

\input{grammar}

At the top level of a program (the \lstinline{p} rules), there can be either a type declaration\textemdash an object type \lstinline{objtype} or a sum type \lstinline{casetype}\textemdash or a language expression. Each type declaration comprises associated declarations \lstinline{objdecls} and \lstinline{casedecls} (not shown on the figure) and their definitions in the \lstinline{metadatadecl}. \lstinline{p} rules end with the non-terminal \lstinline{p$^=$} which signifies that 1) there is a sequence of type declarations or at least one expression to follow and 2) all the succeeding \lstinline{p} terms must begin at the same level of indentation at the \lstinline{p} term on the left-hand side.

Wyvern expressions can be of two major types: those that do not contain forward references (\lstinline{$\overline{\texttt{e}}$}) and those that do (\lstinline{$\widetilde{\texttt{e}}$[fwd]}). Expressions that have a forward reference are either a tilde, saying that a TSL literal is to follow, a new object, or an introductory form of the sum type. Both of the major types of expressions can be a lambda, an application, a pair (for a product type), a \lstinline{let} expression, a field access, expressions for the sum type, a type ascription, or a special built-in operator (\lstinline{valAST()}). The difference between the major expression types is that \lstinline{$\overline{\texttt{e}}$} is not allowed to contain an expression with a forward reference and thus includes expressions for a variable, access to a type's \lstinline{metadata}, and an inline literal. On the other hand, \lstinline{$\widetilde{\texttt{e}}$[fwd]} must have a forward reference. It is important to note that, per line, there can be only one forward reference, which needs to be followed by the `announced' type of expression on the following line (\lstinline{NEWLINE$^>$ $NT^>$} at the end of expressions containing a forward reference).

Production rules for \lstinline{d} represent zero or more field and method definitions, where \lstinline{argsig} is a possibly empty list of typed arguments for the method (omitted from the figure). Production rules for \lstinline{c} represent cases of the sum type, and \lstinline{$\overline{\texttt{al}}$}, \lstinline{$\overline{\texttt{al}}_{\texttt{nonempty}}$}, and \lstinline{$\widetilde{\texttt{al}}$[fwd]} are argument lists without and with forward references. Finally, there are production rules for inline TSL literals, which were discussed in section~\ref{s:motivation} above. Next we are going to look at Wyvern's abstract syntax and the interplay between the concrete and abstract syntaxes.

\subsection{Abstract Syntax}
\subsubsection{Extraction to Abstract Delimited Form}
\todo{extraction - Darya}

\begin{figure}
\centering
\[
\begin{array}[t]{lll} 
\rho & \bnfdef & \keyw{objtype}~ t~ \{ \omega, \keyw{metadata}=e \}; \rho \\
     & \bnfalt & \keyw{casetype}~ t~ \{ \chi, \keyw{metadata}=e \}; \rho\\
     & \bnfalt & e
     \\[1ex]
e    & \bnfdef & x \\
     & \bnfalt & \boldsymbol\lambda x{:}\tau . e \\ %
     & \bnfalt & e(e) \\
     & \bnfalt & (e, e) \\
     & \bnfalt & \keyw{case}(e) \{(x, y) \Rightarrow e\}\\
     & \bnfalt & t.C(e) \\
     & \bnfalt & \keyw{case}(e)~\{ c \} \\
     & \bnfalt & \keyw{new}~ \{ d \}\\
     & \bnfalt & e.x \\
     & \bnfalt & e : \tau\\
     & \bnfalt & \keyw{valAST}(e) \\
     & \bnfalt & t.\keyw{metaobject}\\
     & \bnfalt & \lfloor literal \rfloor \\
     & \bnfalt & \keyw{fromTS}[\Gamma](e, e)
\\[1ex]	
c    & \bnfdef & C(x) \Rightarrow e\\
     & \bnfalt & c \bnfalt c
	 \\[1ex]
d   & \bnfdef & \varepsilon \\
     & \bnfalt & \keyw{val}~ f:\tau = e;~d \\
     & \bnfalt & \keyw{def}~ m:\tau = e;~d
\\[1ex] 
\end{array}
\begin{array}[t]{lll}
~~~
\end{array}
\begin{array}[t]{lll}


\hat\rho & \bnfdef & \keyw{objtype}~ t~ \{ \omega, \keyw{metadata}=\hat e \}; \hat\rho \\
     & \bnfalt & \keyw{casetype}~ t~ \{ \chi, \keyw{metadata}=\hat e \}; \hat\rho\\
     & \bnfalt & \hat e
     \\[1ex]
\hat{e}    & \bnfdef & x \\
     & \bnfalt & \boldsymbol\lambda x{:}\tau . \hat{e} \\ %
     & \bnfalt & \hat{e}(\hat{e}) \\
     & \bnfalt & \cdots \\
     & \bnfalt & t.\keyw{metaobject} 
\\[1ex]
\hat c    & \bnfdef & ...
	 \\[1ex]
\hat d   & \bnfdef & ... 
\\[1ex] 
\chi & \bnfdef & C~\keyw{of}~\tau\\
     & \bnfalt & \chi \bnfalt \chi 
\\[1ex]
\omega &\bnfdef & \varepsilon \\  
         & \bnfalt & \keyw{val}~ f:\tau;~\omega\\
         & \bnfalt & \keyw{def}~ m:\tau;~\omega 
\\[1ex]
\tau & \bnfdef & t\\
     & \bnfalt & \tau \rightarrow \tau \\
     & \bnfalt & \tau \times \tau 
\\[1ex]
\Gamma & \bnfdef & \emptyset \bnfalt \Gamma, x:\tau
\\[1ex]
\Delta & \bnfdef & \emptyset \bnfalt \Delta, t:\{\chi, e:\tau\} \bnfalt \Delta, t:\{\omega, e:\tau\}
\\[1ex]

\end{array}
\]
\caption{Abstract Syntax}
\label{fig:core2-syntax}
\end{figure}

We present the abstract syntax of our system in Figure \ref{fig:core2-syntax}. A program $\rho$ is composed of a series of object type \keyw{objtype} and sum type \keyw{casetype} declarations, followed by expressions $e$. An object type is made of declarations of values \keyw{val}, methods \keyw{def} and \keyw{metadata}. A sum type is made of an enumeration of cases of the form $C$ \keyw{of} $\tau$, where $C$ is the name of the constructor and $\tau$ is the type of the expression constructed in this case, followed by metadata.

The metadata of a type $t$ (either an \keyw{objtype} or a \keyw{casetype}) can contain arbitrary data, for eg. documentation, but it will necessarily contain a $parser$ field of type $Parser$. The $parser$ field has a $parse$ method that takes as argument a stream of tokens and generates an abstract syntax tree expression. This $parse$ method is used for parsing new TSLs of type $t$ defined by the user. 

We differentiate between expressions that might contain a TSL expression and those that definitely do not contain a TSL expression by superscripting the latter with the symbol $\hat{}$. Thus we have two versions (one without $\hat{}$ and one with $\hat{}$) for programs $\rho$,  expressions $e$, cases $c$ of the sum types, and declarations $d$ of fields and methods. 

An expression can be a variable, a function, an application of a function to an expression, a pair of expressions, a case analysis on pairs, the constructor of a case type, the destructor of a case type, a new expression declaring fields and methods, the invocation $e.x$ of a field or a method. We do not have $e.m$ and $e.f$ in the abstract syntax because the parser cannot differentiate between the two, only the type checker can do that. An expression can also be an expression with a type ascribed to it, the abstract syntax tree of an expression, a metaobject of a type, a TSL literal or an expression obtained from a token stream. Each expression has a corresponding static semantics rule in Figures \ref{fig:statics1} and \ref{fig:statics2}. 

The abstract syntax also presents the definition of types, which can be unary types, arrow types corresponding to functions and product types corresponding to pairs. The context $\Gamma$ contains variables and their types. The context $\Delta$ contains types and their signatures. In $\Delta$ we need to keep track not only of a metadata's type, but we need to carry the actual metadata. This is because in the rule $\textit{T-literal}$ in Figure \ref{fig:statics2} we execute the $parse$ method on $\hat{e}_p$ and for this we need to know what the body of the $parse$ method is.


\subsection{Types and Metavalues}
\todo{object types, case types, metavalues - Ligia}

\todo{perhaps the figures below could be used in this section with the reference to the motivating example (Darya)}


\begin{figure}
\begin{lstlisting}
objtype Parser = 
  def parse(s : TokenStream) : ExpAST
\end{lstlisting}
\caption{Wyvern objtype Parser}
\label{fig:typeParser}
\end{figure}

\begin{figure}
\begin{lstlisting}
casetype ExpAST = 
  Var of ID 
| Lam of Var * ExpAST | Ap of Exp * Exp 
| CaseIntro of TyAST * String * ExpAST | ...
\end{lstlisting}
\caption{Wyvern casetype ExpAST}
\label{fig:wyvExpAST}
\end{figure}

\subsection{Bidirectional Type System}
Our type-checking is syntax-directed and it requires terms to be fully annotated with types where necessary. A commonly used approach for making the syntax more compact is bidirectional type systems, as presented by Lovas and Pfenning \cite{Lovas08abidirectional}. They introduce two mutually recursive judgements: one for expressions that have enough information in the context to synthesize a type, and one for expressions for which we know what type to expect, thus only needing to check against that type. Unique types can be determined for synthesis expressions, while analytical expressions have to be verified to have the right types. We chose to use bidirectional type systems in our formalism because they leverage the simplicity of syntax-directed type-checking while not needing to carry much additional type information.

In conventional bidirectional type systems, for constructors of a type one can propagate the type information $\tau$
into the term $e$, which means it should be used in the analysis
judgment $e \Leftarrow \tau$. When constructing a type, we do not have information about it and it is intuitive to use the analysis judgement, which is weaker than the synthesis judgement. On the other hand, destructors generate a result of a smaller type from a component of larger type and can be used for synthesis, propagating type information away from the term as in the synthesis judgement $e \Rightarrow \tau$. Our static semantics rules follow this conventional way of reasoning about constructors and destructors.

\subsection{Procedural Parsing}

The parsing of a new TSL is done by procedural parsing: the metaobject of a type contains a $parser$ field of type $Parser$ that has a method (or `procedure', thus the name `procedural parsing') $parse$. The type $Parser$ is defined in Figure \ref{fig:typeParser}. The user can write an arbitrary $parse$ method, specific for his/her new TSL. Another way of defining the parsing of a newly introduced TSL is by giving the grammar of that TSL, as in Figure \ref{f-htmltype}. In this case, the user will have to give an LALR grammar that contains the productions necessary to parse the new type specific language. This grammar will then be compiled to a $parse$ method written in Wyvern code. The grammar thus becomes a TSL for objects of type $Parser$. 

One can think of elements in quotation marks as being TSLs for abstract syntax trees, such as $":body"$ in Figure \ref{f-htmltype}. The ASTs are written in Wyvern, while their nodes can contain elements written in arbitrary type specific languages, surrounded by quotation marks. The elements in quotations will be regarded as TSLs and translated into Wyvern, the language of the AST. C\# expression trees \cite{Csharp} are created in a similar way: code is represented in a tree-like data structure, where each node is an expression (for example, a method call). When creating a variable \lstinline{num} of type \lstinline{int} one would write

 \lstinline{ParameterExpression numParam = Expression.Parameter(typeof(int), "num")}.

 The variable \lstinline{num} is represented by a String, which would be considered a TSL in Wyvern (Wyvern does not have the built-in type String).

\todo{how Parser works - Ligia}
\subsubsection{Quotations as TSLs}
Related work: C\# expression trees (http://msdn.microsoft.com/en-us/library/bb397951.aspx) -- mention also/instead in the section on quotations as TSLs

\todo{Quotations are TSLs - Ligia}
\subsection{Safety}
\todo{type safety - Cyrus}
\todo{discussion on decidability - Cyrus}
\todo{ambiguity - Cyrus}
\subsection{Grammars as TSLs}
\subsubsection{Ambiguity Checking (related to van wyk's work?) - Cyrus}
