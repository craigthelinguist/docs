% !TEX root = ecoop14.tex
\section{Related Work}
\label{s:related}

Closely related to our approach of type-driven parsing is a concurrent paper by Ichikawa et al.~\cite{Ichikawa:2014:CUO:2584469.2577092} that presents \textit{protean operators}. The paper describes the \textit{ProteaJ} language, based on Java, which allows a programmer to define flexible
%(with any number of parameters or using any kind of pattern)
operators annotated with named types. Syntactic conflict is resolved by looking at the expected type. Conflicts may still arise when the expected type matches two protean operators; in this case ProteaJ allows the programmer to explicitly disambiguate, as in other systems.  In contrast, by associating parsers with types, our approach avoids all conflicts, achieving a stricter notion of modularity at the cost of some expressiveness (we only consider delimited literals -- these may define operators inside, but we cannot support custom  operator syntax directly at the top level). We also give a type theoretic foundation for our approach.
%Additionally, a programmer is allowed to define operator precedences to help guide the parser in resolving potential conflicts. The implementation of ProteaJ and a case study involving a combination of arithmetic operators and file path literals languages (with a number of obvious syntactic conflicts such as \lstinline{/}) are presented in great detail. Our paper concentrates on the formal aspects of type-specific languages including a formal system and how such approach can be made as general as possible --- providing a nice complement to the work of Ichikawa et al.

%\todo{http://confluence.jetbrains.com/display/Kotlin/Type-safe+Groovy-style+builders} NO?

%\todo{staging parsers}

%\todo{language boxes work discussed at Parsing workshop~\cite{Diekmann:2013}}

Another way to approach language extensibility is to go a level of abstraction above parsing, as is done via metaprogramming and macro facilities, with Scheme and other Lisp-style languages' hygienic macros being the 'gold standard' for hygiene. In those languages, macros are written in the language itself and use its simple syntax -- parentheses universally serve as expression delimiters (although proposals for whitespace as a substitute for parentheses have been made \cite{srfi-49}). Our work is inspired by this flexibility, but aims to support richer syntax as well as maintain a static type discipline. Wyvern's use of types to trigger parsing  avoids the overhead of invoking macros explicitly by name, and makes it easier to compose TSLs declaratively. Static macro systems also exist. For instance, OJ (previously, OpenJava)~\cite{Tatsubori00openjava:a} provides a macro system based on a meta-object protocol, and Backstage Java~\cite{Palmer:2011:BJM:2048066.2048137}, Template Haskell \cite{sheard2002template} and Converge~\cite{Tratt:2008:DSL:1391956.1391958} also employ compile-time meta-programming, the latter with some support for whitespace delimited blocks.  Each of these systems provide macro-style rewriting of source code, but they provide at most limited extension of language parsing. String literals can be reinterpreted, but splicing is not hygienic if this is done.

Other systems aim at providing forms of syntax extension that change the host language, as opposed to our whitespace-delimited approach.  For example, Camlp4 \cite{camlp4} is a preprocessor for OCaml that can be used to extend the concrete syntax of the language with parsers and extensible grammars.  SugarJ \cite{Erdweg:2011:SLL:2048147.2048199} supports syntactic extension of the Java language by adding libraries. Wyvern differs from these approach in that the core language is not extended directly, so conflicts cannot arise at link-time.

Scoping TSLs to expressions of a single type comes at the expense of some flexibility, but we believe that many uses of domain-specific languages are of this form already. A previous approach has considered type-based disambiguation of parse forests for supporting quotation and anti-quotation of arbitrary object languages~\cite{bravenboer2005generalized}. Our work is similar in spirit, but does not rely on generation of parse forests and associates grammars with types, rather than types with grammar productions.  This provides stronger modularity guarantees and is arguably simpler. 
 C\# expression trees \cite{Csharp} are similar in that, when the type of a term is, e.g., \li{Expression<T->T'>}, it is parsed as a quotation. However, like the work just mentioned, this is \emph{specifically} to support quotations. Our work supports quotations as one use case amongst many.
 
Many approaches to syntax extension, such as XJ~\cite{DBLP:conf/scam/ClarkSW08} are keyword-delimited in some form. We believe that a type-directed approach is more seamless and natural, coinciding with how one would build in language support directly. These approaches also differ in that they either do not support hygienic expansion, or have not specified it in the simple manner that we have.

In terms of work on safe language composition, Schwerdfeger and van Wyk~\cite{Schwerdfeger:2009:VCD:1542476.1542499} proposed a solution that make strong safety guarantees provided that the languages comply with certain grammar restrictions, concerning first and follow sets of the host language and the added new languages. It also relied on strongly named entry tokens, as with keyword delimited approaches. Our approach does not impose any such restrictions while still making safety guarantees.%Techniques that limit the kinds of syntax that can be introduced, to guarantee that ambiguities cannot occur, must introduce constraints that limit expressiveness and can be difficult to reason about, and still require disambiguation tokens (e.g. \cite{Schwerdfeger:2009:VCD:1542476.1542499}).


Domain-specific language frameworks and language workbenches, such as Spoofax \cite{KatsVisser2010}, Ens\={o}~\cite{enso} and others~\cite{van1992pregmatic}, also provide a possible solution for the language extension task. They provide support for generating new programming languages and tooling in a modular manner.  The Marco language \cite{lee:2012:marco} similarly provides macro definition at a level of abstraction that is largely independent of the target language. In these approaches, each TSL is \emph{external} relative to the host language; in contrast, Wyvern focuses on \emph{internal} extensibility, improving interoperability and composability.

Ongoing work on projectional editors (e.g., \cite{mps,Diekmann:2013}) uses a special graphical user interface to allow the developer to implicitly mark where the extensions are placed in the code, essentially directly specifying the underlying ASTs. This solution to the language extension problem is of considerable interest to us, but remains relatively understudied formally. It is likely that a type-oriented approach to projectional editing, inspired by that described herein, could be fruitful. 

We were informed by our previous work on Active Code Completion (ACC), which associates code completion palettes with types~\cite{omar2012active}, much as we associate parsers with types. ACC palettes could be used for defining a TSL syntax for types in a complementary manner. In ACC that syntax
is immediately translated to Java syntax at edit time, while this work
integrates with the language, so the syntax is retained with the code. ACC supports more general interaction modes than just textual syntax, situated between our approach and projectional editors.
