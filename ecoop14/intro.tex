% !TEX root = ecoop14.tex
\section{Motivation}
\label{s:intro}
By using a general-purpose abstraction mechanism to encode a data structure, one immediately benefits from a body of established reasoning principles and primitive operations. For example, inductive datatypes can be used to express data structures like lists: intuitively, a list can either be empty, or be broken down into a value (its \emph{head}) and another list (its \emph{tail}). In an ML-like language, this concept is conventionally written:
\begin{lstlisting}
datatype 'a list = Nil | Cons of 'a * 'a list
\end{lstlisting}
By encoding lists in this way, we can reason about them by structural induction, construct them by choosing the appropriate case and inspect them by pattern matching. In object-oriented languages, one can encode lists similarly as singly-linked cells, reason about them using a variety of program analysis techniques, construct them using \li{new} and inspect them by traversing the links iteratively. In each case, the programmer only needs to provide an encoding of the structure of lists; the semantics are inherited.

While inheriting semantics can be quite useful, inheriting associated general-purpose syntax can sometimes be a liability. For example, few would claim that writing a list of numbers as a sequence of \li{Cons} cells is convenient:
\begin{lstlisting}
Cons(1, Cons(2, Cons(3, Cons(4, Nil))))
\end{lstlisting}
General-purpose object-oriented notation is similarly inconvenient:
\begin{lstlisting}
new Cons<int>(1, new Cons<int>(2, new Cons<int>(3, new Cons<int>(4))))
\end{lstlisting}
Because lists are a common data structure, many languages provide specialized notation for constructing them, e.g. \li{[1, 2, 3, 4]}. This notation is semantically equivalent to the general-purpose notation shown above, but brings cognitive benefits by drawing attention to the content of the list, rather than the nature of the encoding. More specifically, it is more \emph{terse}, \emph{visible} and \emph{maps more closely} to the intuitive notion of a list, to use terminology from the literature on the cognitive dimensions of notations \cite{green1996usability}.

Although number, string and list literals are nearly ubiquitous features of modern languages, some languages also  provide specialized notation for other common data structures, like maps and sets, data formats, like XML and JSON, query languages, like regular expressions and SQL, and markup languages, like HTML. For example, a language with built-in syntax for HTML and SQL, with type-safe interpolation of host language terms via curly braces, might allow:
\begin{lstlisting}
val webpage : HTML = <html><body><h1>Results for {keyword}</h1>
  <ul id="results">{to_list_items(query(db, 
    SELECT title, snippet FROM products WHERE {keyword} in title)}
</ul></body></html>
\end{lstlisting}
to mean \todo{colors}:
\begin{lstlisting}
val webpage : HTML = new HTMLElement(new Dict(), [new BodyElement(new Dict(),
  [new H1Element(new Dict(), [new TextNode("Results for " + keyword)]), 
  new ULElement(new Dict().add("id", "results"), to_list_items(query(db, 
    new SelectStmt(["title", "snippet"], "products", [new WhereClause(
      new InPredicate(new StringLit(keyword), "title"))]))))]]]
\end{lstlisting}

When a specialized notation is not available, and equivalent general-purpose notation is too cognitively demanding for comfort, developers typically turn to run-time mechanisms to make constructing data structures more convenient. Among the most common strategies in these situations, as we will discuss in Sec. \ref{s:motivation}, is to simply use a string representation that is parsed at run-time. Developers are often  tempted to write the example above as:
\begin{lstlisting}
val webpage : HTML = parse_html("<html><body><h1>Results for "+keyword+"</h1>
  <ul id=\"results\">" + to_string(to_list_items(query(db, parse_sql(
  	"SELECT title, snippet FROM products WHERE '"+keyword+"' in title")))) + 
"</ul></body></html>")
\end{lstlisting}

Though recovering much of the notational convenience of the literal version, it is still more awkward to write, requiring explicit conversions to and from structured representations and escaping when the syntax of the language clashes with the syntax of string literals (line 2). But code like this also causes a number of more serious problems beyond cognitive load. Because parsing occurs at run-time, syntax errors will not be discovered statically, causing potential problems in production scenarios. Run-time parsing also incurs performance overhead, particularly relevant when code like this is executed often (as on a heavily-trafficked website, or in a loop). But the most serious issue with this code is that it is fundamentally insecure: it is vulnerable to cross-site scripting attacks (line 1) and SQL injection attacks (line 3). For example, if a user provided the keyword \li{'; DROP TABLE products --}, the entire product database could be erased. These attack vectors are considered to be two of the most serious security threats on the web today \cite{owasp2013}. Although developers are cautioned to sanitize their input, it can be difficult to verify that this was done correctly throughout a codebase. The most straightforward way to avoid these problems is to use structured representations throughout the codebase, aided by specialized notation like that above \cite{Bravenboer:2007:PIA:1289971.1289975}.

%For example, in languages without regular expression literals, it is quite tedious to write out a regular expression in a structured manner. A simple regular expression like \verb!(\d\d):(\d\d)\w?((am)|(pm))! representing times might be written:
%\begin{lstlisting}
%Seq(Group(Seq(Digit, Digit), Seq(Char(":"), Seq(Group(Seq(Digit, Digit)), 
%  Seq(Optional(Whitespace), Group(Or(Group(Seq(Char("a"), Char("m"))), 
%  Group(Seq(Char("p"), Char("m"))))))))))
%\end{lstlisting}
%Among the most common strategies in these situations, as we will discuss in Sec. \ref{s:motivation}, is to simply use a string representation that is parsed at run-time. 
%\begin{lstlisting}
%rx_from_str("(\\d\\d):(\\d\\d)\\w?((am)|(pm))")
%\end{lstlisting}
%
%For example, in languages without SQL literals, developers can implement a builder pattern:
%\begin{lstlisting}
%new SQLQuery().SELECT("*").FROM("table").WHERE("username").Eq(username)
%\end{lstlisting}
As we will discuss further in Sec. \ref{s:study}, situations like this, where specialized notation is  necessary to maintain strong correctness, performance and security guarantees while avoiding unacceptable cognitive overhead, are quite common. 
Today, implementing new notations within an existing programming language requires the cooperation of the language designer. The primary technical reason for this is that, with conventional parsing strategies, not all notations can safely coexist, so a designer is needed to make choices about which syntactic forms are available and what their semantics are. For example, conventional notations for sets and dictionaries are delimited by curly braces. When Python introduced set literals, it sought to use curly braces for both dictionaries and sets, distinguishing them based on whether the literal contained only values, or key-value pairs. But it faced a problem with the syntactic form \verb|{ }| -- should it mean an empty set or an empty dictionary? The designers of Python chose the latter, largely for backwards compatibility reasons.

Languages that allow users to introduce new syntax from within libraries hold promise, but because there is no longer a designer making decisions about such ambiguities, the burden of resolving them falls to the users of extensions. For example, SugarJ \cite{Erdweg:2011:SLL:2048147.2048199} and other extensible languages generated by Sugar* \cite{Erdweg:2013:FEL:2517208.2517210} allow users to extend the base syntax of the host language (e.g. Java) with new forms, like set and dictionary literals. New forms are imported transitively throughout a program. To resolve syntactic ambiguities that arise, users must manually augment the composed grammar with new rules that allow them to choose the correct interpretation explicitly. This is both difficult to do, requiring an understanding of the underlying parser technology (in Sugar*, GLR parsing using SDF) and increases the cognitive load of using the conflicting notations (e.g. both sets and dictionaries) in the same file. These kinds of conflicts occur in a variety of circumstances: HTML and XML, different variants of SQL, JSON literals and dictionaries, or simply different implementations (``desugarings'') of the same specialized syntax (e.g. two regular expression engines) cause problems.

In this paper, we describe an alternative parsing strategy that avoids these problems by shifting responsibility for parsing certain \emph{generic literal forms} into the typechecker. The typechecker, in turn, defers responsibility to user-defined types, by treating the body of the literal as a term of the   \emph{type-specific language (TSL)} associated with the type it is being checked against. The TSL rewrites these forms to use only general-purpose notation. TSLs can contain expressions in the host language. This strategy avoids the problem of ambiguous syntax, because the base syntax of the language is never extended directly and each TSL is monolithic. It also avoids ambiguous semantics -- the meaning of a form like \verb|{ }| can differ depending  on its type, so it is safe to use it for empty sets, dictionaries and other data structures, like JSON literals. This also frees notation from being tied to the variant of a  data structure built into the standard library, which sometimes does not provide the exact semantics that an application needs (for example, Python dictionaries do not preserve order, while JSON does):
\begin{lstlisting}
val empty_set : Set = { }
val empty_dict : Dict = { }
val empty_json : JSON = { }
\end{lstlisting}
We are developing our work as a variant of an emerging programming language called Wyvern \cite{Nistor:2013:WST:2489828.2489830}. To distill the essence of our proposal, the variant of Wyvern we develop here is simpler than the variant previously described: it is purely functional (there are no effects or mutable state) and it does not enforce a uniform access principle for objects (fields can be accessed directly). It also adds inductive datatypes, which we call \emph{case types}, similar to those found in ML. We will refer to our version of the language as \emph{TSL Wyvern}. Our work extends and makes concrete a mechanism sketched out in a short workshop paper by the Wyvern group \cite{Omar:2013:TWP:2489812.2489815}. We make the following novel contributions:
\begin{itemize}
\item We specify a more complete layout-sensitive concrete syntax and show how it can be written without the need for a context-sensitive lexer or parser. It now includes inline literal forms and provides a full specification for the proposed whitespace-delimited literal form introduced by a forward reference, \li{~}.
\item The previous work gave a vague sketch 
\item a formalization of the static semantics of TSL wyvern as a bidirectional type system, which distinguishes precisely which locations a generic literal can appear. adds additional logic for expanding TSLs hygienically, using a novel mechanism that allows capture of variables only in portions of the literal interpreted by the TSL as a host expression. soundness.
\item an interpretation of quasiquotes and grammars as TSLs for AST (abstract syntax tree) and Parser types, respectively, showing how TSLs can make it easier to write other TSLs.
\item corpus analysis
\end{itemize}

\todo{Talk about contributions of paper here.}
\todo{Mention that the examples above look like this in Wyvern?}
\begin{lstlisting}
val webpage : HTML = ~
  <html><body><h1>Results for {keyword}</h1><ul id="results">{
  	to_list_items(query(db, ~))
      SELECT title, snippet FROM products WHERE {keyword} in title
  }</ul></body></html>
\end{lstlisting}

%\begin{lstlisting}
%astOf(e) : ExpAST
%
%casetype ExpAST { 
%  Var of ID
%  Lam of ID * TypeAST * ExpAST
%| ...
%  ParseAsExp(ts, x)
%}
%
%casetype TyAST {
%  Var of ID
%  Arrow of TyAST * TyAST
%  ParseAsTy(ts, x)
%}
%\end{lstlisting}
%https://en.wikipedia.org/wiki/Cognitive_dimensions_of_notations
%Domain-specific languages (DSLs) \cite{fowler2010domain} % have been widely-studied because they 
%allow developers to work with   
%specialized abstractions in a natural manner, and allow for specialized 
%verification and compilation strategies that can improve verifiability and performance. However, for DSLs to reach their full
%potential, it must be simple to define a new DSL, invoke it when needed, and to use multiple
%DSLs within a host general-purpose language (GPL), such that pieces of DSL code
% can interoperate to form a complete application. These intuitions are captured by the following core design criteria that govern our work:
%
%\begin{itemize}
%
%\item \emph {Composability}: It should be possible to use multiple DSLs and a GPL
%%, in addition to a GPL,
%within a single program unit.  %Here 
%Within the file-based paradigm used by most contemporary languages, this 
%means including multiple DSLs within a single file.
% Moreover, it should be possible to embed code written in one DSL
%  within another DSL when appropriate, without requiring them to have specific knowledge of each other. This should be possible without interference between DSLs used in any combination: DSLs should be \emph{safely composable}.
%
%\item \emph{Interoperability}: It should be
%  possible to pass around and operate on values 
%%such as functions or data structures
%  that were defined in foreign DSLs in a reasonably natural manner (that is, without requiring large amounts of ``glue code''). Additional requirements, such as the ability to do so with the safety guarantees provided in the foreign DSL, may also be relevant in many settings. 
%  
%%Moreover,
%  %Minimally, DSLs should be able to define a function or data structure that satisfies an interface specified in
%  %a common interface description language (such as the type system of
%  %a host GPL), code written in another DSL should be able to use those
%  %values according to that interface, without requiring that the client DSL
%  %have knowledge of the details of the provider DSL or \emph{vice versa}.
%\end{itemize}
%
%
%%\item type system: one DSL depends on types defined by another DSL,
%%  can use objects of that type in special ways [this goes beyond the
%%    scope - save for a later paper]
%
%In addition to these fundamental criteria, we believe that to be most useful, a system supporting DSLs should satisfy the following related design criteria:
%
%\begin{itemize}
%\item \emph{Flexibility}: Support a variety of notations and new language mechanisms, with minimal bias;
%\item \emph{Modularity}: Support defining DSLs as combinations of reusable components distributed directly within  libraries;
%\item \emph{Identifiability}: Make it easy for programmers to identify which code is written in which DSL and what it means;
%%\item \emph{Consistency}: Encourage DSLs written in similar styles whenever possible in order to enhance readability and learnability of each DSL;
%\item \emph{Simplicity}: Keep the complexity and cost of both defining and invoking a DSL as low as possible.
%%\item Share conventions between DSLs and a host language, making each DSL easier for programmers to learn, helping programmers to identify which code is written in which DSL, and avoiding unintended conflicts between DSLs. \todo{Avoid conflicts (visual and real), enhance learnability}
%%\item Reuse low-level mechanisms and design decisions from a host language, thereby reducing the cost of defining DSLs.  \todo{Easy to define DSLs}
%\end{itemize}
%
%We are developing a comprehensive language design, \emph{Wyvern}, that we believe can satisfy these design criteria well, and that specifically considers language-internal extensibility from the start. In Wyvern, DSL developers define the run-time semantics of DSL constructs via translation
%into a common host language, as in many other DSL frameworks. The novelty of the proposed extensibility mechanism lies in the ways in which we delimit and determine the \emph{scope} of DSL code:
%\begin{itemize}
%%\item The host language and its DSLs share a tokenization and lexing 
%%  strategy, standardizing conventions for identifiers, operators,
%%  constants, and comments.  This avoids the cost of defining lexing
%%  within each DSL, avoids many kinds of low-level clashes between
%%  languages, and makes the composed language more readable. Note that this does not limit the ability of a DSL to define new keywords and other constructs.
%% 
%\item Wyvern is a \emph{whitespace-delimited} language. Source code that is governed by a DSL, rather than the GPL, occurs in whitespace-delimited blocks and must be indented further than the GPL line introducing it. A decrease in indentation relative to the baseline of the DSL block signals its end. This scheme delimits the scope of each DSL in a clear manner, both to 
%  the programmer and the top-level parser, supporting the principle of identifiability.  It also allows Wyvern to avoid restrictions on a DSL's use of delimiters internally. Because the GPL grammar is not extended in a global manner, it also guarantees that syntactic 
%  conflicts cannot arise at link-time.
%
%%There is also a flexible mechanism for explicit delimiters, for small DSLs, that we will discuss briefly later in the paper.
%
% % \emph{whitespace-delimited} at the top level, according to a particular strategy that we will describe.  Various forms of parentheses 
%  %can also serve as delimiters.  Thus, indentation levels or
%  %parenthesized expressions clearly delimit blocks that are governed by a particular 
%  %language.  This makes the boundaries of each DSL clear to
%  %the programmer and the compiler, enhancing usability and guaranteeing that 
%  %ubtle conflicts cannot arise.
%  
%%\end{itemize}
%
%\item Within this basic syntactic framework, we then propose a novel
%type-directed dispatch mechanism: the \emph{expected type} of an expression, rather than an explicit keyword, 
%%, rather than a keyword, 
%determines which DSL grammar should parse the delimited block that generates that expression. That is, \emph{grammars are associated with types}. We will show that the  more common keyword-directed strategy arises as a special case of this strategy. 
%\end{itemize}
%
%This mechanism allows us to satisfy many of the criteria above, including safe composability, while still being quite expressive, as we will show with examples in the next section. We will continue by describing our approach in more detail (\S\ref{s:approach}), discuss ongoing research directions (\S\ref{s:discussion}), and conclude with related work (\S\ref{s:related}).
%
%

% keep discussion of type-based parsing brief - active typing for parsing (only)
% avoids conflict with Cyrus' paper

%The rest of the paper is organized as follows.  The next section
%illustrates our approach by example, discussing the components of the
%solution in more detail. Section~\ref{s:approach} outlines our
%approach, shows a wider variety of examples and discusses variations
%of our approach.  Our in-progress implementation of the proposal is
%described in Section~\ref{s:implementation}.  Section~\ref{s:related}
%compares to related work, and Section~\ref{s:conclusion} concludes.

% with a discussion of future work.
