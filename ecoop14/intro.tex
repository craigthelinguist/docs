% !TEX root = ecoop14.tex
\section{Motivation}
\label{s:intro}
By using a general-purpose abstraction mechanism to encode a data structure, one immediately benefits from a body of established reasoning principles and primitive operations. For example, inductive datatypes can be used to express data structures like lists: intuitively, a list can either be empty, or be broken down into a value (its \emph{head}) and another list (its \emph{tail}). In an ML-like language, this concept is conventionally written:
\begin{lstlisting}
datatype 'a list = Nil | Cons of 'a * 'a list
\end{lstlisting}
By encoding lists in this way, we can reason about them by structural induction, construct them by choosing the appropriate case and inspect them by pattern matching. In object-oriented languages, one can encode lists similarly as singly-linked cells, reason about them using a variety of program analysis techniques, construct them using \li{new} and inspect them by traversing the links iteratively. In each case, the programmer only needs to provide an encoding of the structure of lists; the semantics are inherited.

While inheriting semantics can be quite useful, inheriting associated general-purpose syntax can sometimes be a liability. For example, few would claim that writing a list of numbers as a sequence of \li{Cons} cells is convenient:
\begin{lstlisting}
Cons(1, Cons(2, Cons(3, Cons(4, Nil))))
\end{lstlisting}
General-purpose object-oriented notation is similarly inconvenient:
\begin{lstlisting}
new Cons<int>(1, new Cons<int>(2, new Cons<int>(3, new Cons<int>(4))))
\end{lstlisting}
Because lists are a common data structure, many languages provide specialized notation for constructing them, e.g. \li{[1, 2, 3, 4]}. This notation is semantically equivalent to the general-purpose notation shown above, but brings cognitive benefits by drawing attention to the content of the list, rather than the nature of the encoding. More specifically, it is more \emph{terse}, \emph{visible} and \emph{maps more closely} to the intuitive notion of a list, to use terminology from the literature on the cognitive dimensions of notations \cite{green1996usability}.

Although number, string and list literals are nearly ubiquitous features of modern languages, some languages also  provide specialized notation for other common data structures, like maps and sets, data formats, like XML and JSON, query languages, like regular expressions and SQL, and markup languages, like HTML. For example, a language with built-in syntax for HTML and SQL, with type-safe interpolation of host language terms via curly braces, might allow:
\begin{lstlisting}
val webpage : HTML = <html><body><h1>Results for {keyword}</h1>
  <ul id="results">{to_list_items(query(db, 
    SELECT title, snippet FROM products WHERE {keyword} in title)}
</ul></body></html>
\end{lstlisting}
to mean \todo{colors}:
\begin{lstlisting}
val webpage : HTML = new HTMLElement(new Dict(), [new BodyElement(new Dict(),
  [new H1Element(new Dict(), [new TextNode("Results for " + keyword)]), 
  new ULElement(new Dict().add("id", "results"), to_list_items(query(db, 
    new SelectStmt(["title", "snippet"], "products", [new WhereClause(
      new InPredicate(new StringLit(keyword), "title"))]))))]]]
\end{lstlisting}

When a specialized notation is not available, and equivalent general-purpose notation is too cognitively demanding for comfort, developers typically turn to run-time mechanisms to make constructing data structures more convenient. Among the most common strategies in these situations, as we will discuss in Sec. \ref{s:motivation}, is to simply use a string representation that is parsed at run-time. Developers are often  tempted to write the example above as:
\begin{lstlisting}
val webpage : HTML = parse_html("<html><body><h1>Results for "+keyword+"</h1>
  <ul id=\"results\">" + to_string(to_list_items(query(db, parse_sql(
  	"SELECT title, snippet FROM products WHERE '"+keyword+"' in title")))) + 
"</ul></body></html>")
\end{lstlisting}

Though recovering much of the notational convenience of the literal version, it is still more awkward to write, requiring explicit conversions to and from structured representations and escaping when the syntax of the language clashes with the syntax of string literals (line 2). But code like this also causes a number of more serious problems beyond cognitive load. Because parsing occurs at run-time, syntax errors will not be discovered statically, causing potential problems in production scenarios. Run-time parsing also incurs performance overhead, particularly relevant when code like this is executed often (as on a heavily-trafficked website, or in a loop). But the most serious issue with this code is that it contains two security vulnerabilities: a cross-site scripting attack (line 1) and a SQL injection attack (line 3). For example, if a user provided the keyword \li{'; DROP TABLE products --}, the entire product database could be erased. These attack vectors are considered to be two of the most serious security threats on the web today \cite{owasp2013}. Although developers are cautioned to sanitize their input, it can be difficult to verify that this was done correctly throughout a codebase. The most straightforward way to avoid these problems is to use structured representations throughout the codebase, aided by specialized notation like that above \cite{Bravenboer:2007:PIA:1289971.1289975}.

%For example, in languages without regular expression literals, it is quite tedious to write out a regular expression in a structured manner. A simple regular expression like \verb!(\d\d):(\d\d)\w?((am)|(pm))! representing times might be written:
%\begin{lstlisting}
%Seq(Group(Seq(Digit, Digit), Seq(Char(":"), Seq(Group(Seq(Digit, Digit)), 
%  Seq(Optional(Whitespace), Group(Or(Group(Seq(Char("a"), Char("m"))), 
%  Group(Seq(Char("p"), Char("m"))))))))))
%\end{lstlisting}
%Among the most common strategies in these situations, as we will discuss in Sec. \ref{s:motivation}, is to simply use a string representation that is parsed at run-time. 
%\begin{lstlisting}
%rx_from_str("(\\d\\d):(\\d\\d)\\w?((am)|(pm))")
%\end{lstlisting}
%
%For example, in languages without SQL literals, developers can implement a builder pattern:
%\begin{lstlisting}
%new SQLQuery().SELECT("*").FROM("table").WHERE("username").Eq(username)
%\end{lstlisting}
As we will discuss further in Sec. \ref{s:study}, situations like this, where specialized notation is  necessary to maintain strong correctness, performance and security guarantees while avoiding unacceptable cognitive overhead, are quite common. 
Today, implementing new notations within an existing programming language requires the cooperation of the language designer. The primary technical reason for this is that, with conventional parsing strategies, not all notations can safely coexist, so a designer is needed to make choices about which syntactic forms are available and what their semantics are. For example, conventional notations for sets and dictionaries are delimited by curly braces. When Python introduced set literals, it sought to use curly braces for both dictionaries and sets, distinguishing them based on whether the literal contained only values, or key-value pairs. But it faced a problem with the syntactic form \verb|{ }| -- should it mean an empty set or an empty dictionary? The designers of Python chose the latter, largely for backwards compatibility reasons.

Languages that allow users to introduce new syntax from within libraries hold promise, but because there is no longer a designer making decisions about such ambiguities, the burden of resolving them falls to the users of extensions. For example, SugarJ \cite{Erdweg:2011:SLL:2048147.2048199} and other extensible languages generated by Sugar* \cite{Erdweg:2013:FEL:2517208.2517210} allow users to extend the base syntax of the host language (e.g. Java) with new forms, like set and dictionary literals. New forms are imported transitively throughout a program. To resolve syntactic ambiguities that arise, users must manually augment the composed grammar with new rules that allow them to choose the correct interpretation explicitly. This is both difficult to do, requiring an understanding of the underlying parser technology (in Sugar*, GLR parsing using SDF) and increases the cognitive load of using the conflicting notations (e.g. both sets and dictionaries) in the same file. These kinds of conflicts occur in a variety of circumstances: HTML and XML, different variants of SQL, JSON literals and dictionaries, or simply different implementations (``desugarings'') of the same specialized syntax (e.g. two regular expression engines) cause problems.

In this paper, we describe an alternative parsing strategy that avoids these problems by shifting responsibility for parsing certain \emph{generic literal forms} into the typechecker. The typechecker in turn defers responsibility to user-defined types, by deferring to a \emph{type-specific language (TSL)} associated with the type that the literal form is being checked against. The TSL ultimately rewrites these forms to use only general-purpose notation. By using this strategy, we can avoid the problem of ambiguous syntax, because the base syntax of the language is never extended directly, as well as ambiguous semantics -- the meaning of a form like \verb|{ }| can differ depending  on its type, so it is safe to use it for empty sets, dictionaries and other data structures, like JSON literals. This also frees notation from being tied to the variant of a  data structures built into the standard library, which sometimes do not provide the precise semantics that an application needs (for example, Python dictionaries do not preserve order, while JSON does):
\begin{lstlisting}
val empty_set : Set = { }
val empty_dict : Dict = { }
val empty_json : JSON = { }
\end{lstlisting}
We are developing our work as a variant of an emerging programming language called Wyvern \cite{maspeghi13}. To help us distill the essence of our proposal, the variant of Wyvern we present here is simpler than the variant previously described: it is purely functional (there are no effects or mutable state) and it does not enforce a uniform access principle for objects (fields can be accessed directly). It also adds inductive datatypes, which we call \emph{case types}, similar to those found in ML. We will refer to our version of the language as \emph{TSL Wyvern}. 
 
\todo{Talk about contributions of paper here.}
\todo{Mention that the examples above look like this in Wyvern?}
\begin{lstlisting}
val webpage : HTML = ~
  <html><body><h1>Results for {keyword}</h1><ul id="results">{
  	to_list_items(query(db, ~))
      SELECT title, snippet FROM products WHERE {keyword} in title
  }</ul></body></html>
\end{lstlisting}

\section{Corpus Analysis}
\label{s:study}
To further motivate our approach, we performed an empirical study that examined potential usage of the proposed language composition mechanism. For this purpose, we looked at the recent version (20130901r) of 107 Java projects in the Qualitas Corpus~\cite{QualitasCorpus:APSEC:2010} and performed two analyses to see how TSLs could be used directly and indirectly. Our analyses' methodology and the results are described below.

\subsubsection{Methodology}

To perform our analyses, we used command line tools, such as \lstinline{grep} and \lstinline{sed}, and a VI editor features, such as search and substitution. In a semi-manual procedure, we scanned though the Java code and picked out class constructors. After that, we chose constructors that take at least one \lstinline{String} as an argument, and looking at the names of the constructors and their arguments, we inferred the intended use of the classes associated with them. The summarized results of our analysis are shown in Table~\ref{t-summary}.

\begin{table}
   \centering
    \begin{tabular}{l | c | c}
    \bf Constructors & \bf Number & \bf \% of Total \\ \hline
    Total analyzed & 125,048 & 100 \\
    Have a String argument & 30,190 & 24 \\
    Could be substituted by a TSL & 19,317 & 15 \\
    Could use a TSL & 0 & 0 \\
    \end{tabular}
    \vspace{0.15in}
    \caption{Summary of the Analyses Results}
    \label{t-summary}
\end{table}

\subsubsection{Direct Substitution with TSLs}

As the first part of our analysis of the Java projects, we looked into how developers could directly benefit  from using TSLs. To do that, we looked though the Java constructors and found those that could be substituted by a type. What we were looking for is the constructors such as:

\begin{lstlisting}
Path(String path) {...}
\end{lstlisting}

That is the constructors that take in a single \lstinline{String} argument, which must be of a specific format and which serves as a basis for the underlying class. In the example above, if it was to be written in Wyvern, the \lstinline{Path} class could be represented as a type called \lstinline{Path} with a \lstinline{parse} method that would verify the adherence to the necessary format.

Looking through the Java constructors, we found that there is x \% (y out of z examined constructors) which comply with this pattern. Those constructors were used for classes that represent URLs and URIs, identification numbers, versions, directory paths, and various types of names (e.g., user name, database name, column name, etc.).

\subsubsection{Potential Use of TSLs}

In the second part of our analysis, we continued examining the identified Java constructors, but this time we looked at the constructors that could benefit from the substitution of classes with TSLs, which we talked about in the previous subsection. In particular, we again looked at the constructors that take at least one \lstinline{String} argument that has to conform to a specific format but the \lstinline{String} argument is not the basis for the underlying class. For instance, constructors such as:

\begin{lstlisting}
FileUpdatedEvent(Object source, String path) {...}
\end{lstlisting}

Here, the second argument \lstinline{path}, which is of type \lstinline{String}, could be represented using a Wyvern type \lstinline{Path} that would guarantee that the passed in argument is of the required format.

\begin{table}
   \centering
    \begin{tabular}{l | c | c}
    \bf Type of String & \bf Number & \bf \% of Total \\ \hline
    Name & 14,330 & 74.2 \\
    ID	& 1,336 & 6.9 \\
    Directory path& 823 & 4.3 \\
    Pattern & 495 & 2.6 \\
    URL/URI & 398 & 2.1 \\
    Other & 1,935 & 10.0 \\ \hline
    \bf Total: & \bf 19,317 & \bf 100.0
    \end{tabular}
    \vspace{0.15in}
    \caption{Types of \lstinline{String} Arguments in Java Constructors}
    \label{t-strs-in-constrs}
\end{table}

Our analysis found that there is x \% (y out of z constructors) of this kind of constructors (see Table~\ref{t-summary}). More details on the kinds of \lstinline{String} arguments that are passed into constructors can be found in Table~\ref{t-strs-in-constrs}. The ``Name'' category refers to the name of a file, a user, a class, etc. that do not have to be unique; the ``ID'' category comprises process IDs, user IDs, column or row IDs, etc. that must have the uniqueness property; the ``Pattern'' category includes regular expressions, prefixes and suffixes, delimiters, format templates, etc.; the ``Other'' category contains \lstinline{String}s used for ZIP codes, passwords, queries, IP addresses, versions, HTML and XML code, etc.; and the ``Directory path'' and ``URL/URI'' categories are self-explanatory.

Hence, our empirical study has shown that there is at least x \% of Java constructors that have a potential of directly or indirectly taking advantage of TSLs. It is important to keep in mind that our analyses were fairly narrow: they focused exclusively on the constructors and thus forwent many other types of programming constructs, such as methods, variable assignments, etc., that could possibly also benefit from our approach.


%\begin{lstlisting}
%astOf(e) : ExpAST
%
%casetype ExpAST { 
%  Var of ID
%  Lam of ID * TypeAST * ExpAST
%| ...
%  ParseAsExp(ts, x)
%}
%
%casetype TyAST {
%  Var of ID
%  Arrow of TyAST * TyAST
%  ParseAsTy(ts, x)
%}
%\end{lstlisting}
%https://en.wikipedia.org/wiki/Cognitive_dimensions_of_notations
%Domain-specific languages (DSLs) \cite{fowler2010domain} % have been widely-studied because they 
%allow developers to work with   
%specialized abstractions in a natural manner, and allow for specialized 
%verification and compilation strategies that can improve verifiability and performance. However, for DSLs to reach their full
%potential, it must be simple to define a new DSL, invoke it when needed, and to use multiple
%DSLs within a host general-purpose language (GPL), such that pieces of DSL code
% can interoperate to form a complete application. These intuitions are captured by the following core design criteria that govern our work:
%
%\begin{itemize}
%
%\item \emph {Composability}: It should be possible to use multiple DSLs and a GPL
%%, in addition to a GPL,
%within a single program unit.  %Here 
%Within the file-based paradigm used by most contemporary languages, this 
%means including multiple DSLs within a single file.
% Moreover, it should be possible to embed code written in one DSL
%  within another DSL when appropriate, without requiring them to have specific knowledge of each other. This should be possible without interference between DSLs used in any combination: DSLs should be \emph{safely composable}.
%
%\item \emph{Interoperability}: It should be
%  possible to pass around and operate on values 
%%such as functions or data structures
%  that were defined in foreign DSLs in a reasonably natural manner (that is, without requiring large amounts of ``glue code''). Additional requirements, such as the ability to do so with the safety guarantees provided in the foreign DSL, may also be relevant in many settings. 
%  
%%Moreover,
%  %Minimally, DSLs should be able to define a function or data structure that satisfies an interface specified in
%  %a common interface description language (such as the type system of
%  %a host GPL), code written in another DSL should be able to use those
%  %values according to that interface, without requiring that the client DSL
%  %have knowledge of the details of the provider DSL or \emph{vice versa}.
%\end{itemize}
%
%
%%\item type system: one DSL depends on types defined by another DSL,
%%  can use objects of that type in special ways [this goes beyond the
%%    scope - save for a later paper]
%
%In addition to these fundamental criteria, we believe that to be most useful, a system supporting DSLs should satisfy the following related design criteria:
%
%\begin{itemize}
%\item \emph{Flexibility}: Support a variety of notations and new language mechanisms, with minimal bias;
%\item \emph{Modularity}: Support defining DSLs as combinations of reusable components distributed directly within  libraries;
%\item \emph{Identifiability}: Make it easy for programmers to identify which code is written in which DSL and what it means;
%%\item \emph{Consistency}: Encourage DSLs written in similar styles whenever possible in order to enhance readability and learnability of each DSL;
%\item \emph{Simplicity}: Keep the complexity and cost of both defining and invoking a DSL as low as possible.
%%\item Share conventions between DSLs and a host language, making each DSL easier for programmers to learn, helping programmers to identify which code is written in which DSL, and avoiding unintended conflicts between DSLs. \todo{Avoid conflicts (visual and real), enhance learnability}
%%\item Reuse low-level mechanisms and design decisions from a host language, thereby reducing the cost of defining DSLs.  \todo{Easy to define DSLs}
%\end{itemize}
%
%We are developing a comprehensive language design, \emph{Wyvern}, that we believe can satisfy these design criteria well, and that specifically considers language-internal extensibility from the start. In Wyvern, DSL developers define the run-time semantics of DSL constructs via translation
%into a common host language, as in many other DSL frameworks. The novelty of the proposed extensibility mechanism lies in the ways in which we delimit and determine the \emph{scope} of DSL code:
%\begin{itemize}
%%\item The host language and its DSLs share a tokenization and lexing 
%%  strategy, standardizing conventions for identifiers, operators,
%%  constants, and comments.  This avoids the cost of defining lexing
%%  within each DSL, avoids many kinds of low-level clashes between
%%  languages, and makes the composed language more readable. Note that this does not limit the ability of a DSL to define new keywords and other constructs.
%% 
%\item Wyvern is a \emph{whitespace-delimited} language. Source code that is governed by a DSL, rather than the GPL, occurs in whitespace-delimited blocks and must be indented further than the GPL line introducing it. A decrease in indentation relative to the baseline of the DSL block signals its end. This scheme delimits the scope of each DSL in a clear manner, both to 
%  the programmer and the top-level parser, supporting the principle of identifiability.  It also allows Wyvern to avoid restrictions on a DSL's use of delimiters internally. Because the GPL grammar is not extended in a global manner, it also guarantees that syntactic 
%  conflicts cannot arise at link-time.
%
%%There is also a flexible mechanism for explicit delimiters, for small DSLs, that we will discuss briefly later in the paper.
%
% % \emph{whitespace-delimited} at the top level, according to a particular strategy that we will describe.  Various forms of parentheses 
%  %can also serve as delimiters.  Thus, indentation levels or
%  %parenthesized expressions clearly delimit blocks that are governed by a particular 
%  %language.  This makes the boundaries of each DSL clear to
%  %the programmer and the compiler, enhancing usability and guaranteeing that 
%  %ubtle conflicts cannot arise.
%  
%%\end{itemize}
%
%\item Within this basic syntactic framework, we then propose a novel
%type-directed dispatch mechanism: the \emph{expected type} of an expression, rather than an explicit keyword, 
%%, rather than a keyword, 
%determines which DSL grammar should parse the delimited block that generates that expression. That is, \emph{grammars are associated with types}. We will show that the  more common keyword-directed strategy arises as a special case of this strategy. 
%\end{itemize}
%
%This mechanism allows us to satisfy many of the criteria above, including safe composability, while still being quite expressive, as we will show with examples in the next section. We will continue by describing our approach in more detail (\S\ref{s:approach}), discuss ongoing research directions (\S\ref{s:discussion}), and conclude with related work (\S\ref{s:related}).
%
%

% keep discussion of type-based parsing brief - active typing for parsing (only)
% avoids conflict with Cyrus' paper

%The rest of the paper is organized as follows.  The next section
%illustrates our approach by example, discussing the components of the
%solution in more detail. Section~\ref{s:approach} outlines our
%approach, shows a wider variety of examples and discusses variations
%of our approach.  Our in-progress implementation of the proposal is
%described in Section~\ref{s:implementation}.  Section~\ref{s:related}
%compares to related work, and Section~\ref{s:conclusion} concludes.

% with a discussion of future work.
